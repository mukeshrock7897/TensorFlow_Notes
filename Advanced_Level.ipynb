{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMWdIyunn66FftowI+WY5F+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mukeshrock7897/TensorFlow_Notes/blob/main/Advanced_Level.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Transfer Learning**\n",
        "* Transfer learning involves using a pre-trained model on a new task, which saves training time and leverages learned features from large datasets.\n",
        "\n",
        "**Example:** Fine-tuning a pre-trained model on a new dataset\n",
        "\n"
      ],
      "metadata": {
        "id": "9Nhw34tGx1gP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "VHzp7x8PL-7U"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the pre-trained VGG16 model\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze the layers of the base model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add custom layers on top of the base model\n",
        "x = base_model.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "predictions = Dense(10, activation='softmax')(x)\n",
        "\n",
        "# Create the full model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "train_datagen = ImageDataGenerator(rescale=0.5)\n",
        "\n",
        "# **Update with the correct path to your training data**\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/content/train_data',  # Replace with the actual path\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_generator, epochs=10)\n",
        "\n",
        "# Plot accuracy and loss during training\n",
        "history = model.fit(train_generator, epochs=10)\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Generative Adversarial Networks (GANs)**\n",
        "* GANs consist of two networks, a generator and a discriminator, that compete against each other. The generator creates data, while the discriminator evaluates it. real or fake\n",
        "\n",
        "**Example:** Simple GAN for generating MNIST digits\n",
        "\n"
      ],
      "metadata": {
        "id": "yKaz3saTykmC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Reshape, Flatten, BatchNormalization, LeakyReLU\n",
        "from tensorflow.keras.models import Sequential\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Define the generator\n",
        "def build_generator():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(256, input_dim=100))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(Dense(512))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(Dense(1024))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(Dense(28 * 28 * 1, activation='tanh'))\n",
        "    model.add(Reshape((28, 28, 1)))\n",
        "    return model\n",
        "\n",
        "# Define the discriminator\n",
        "def build_discriminator():\n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape=(28, 28, 1)))\n",
        "    model.add(Dense(512))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dense(256))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    return model\n",
        "\n",
        "# Build and compile the discriminator\n",
        "discriminator = build_discriminator()\n",
        "discriminator.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Build the generator\n",
        "generator = build_generator()\n",
        "\n",
        "# Define the combined GAN model\n",
        "z = tf.keras.Input(shape=(100,))\n",
        "img = generator(z)\n",
        "discriminator.trainable = False\n",
        "valid = discriminator(img)\n",
        "combined = tf.keras.Model(z, valid)\n",
        "combined.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "\n",
        "# Training the GAN\n",
        "(X_train, _), (_, _) = tf.keras.datasets.mnist.load_data()\n",
        "X_train = X_train / 127.5 - 1.0\n",
        "X_train = np.expand_dims(X_train, axis=3)\n",
        "batch_size = 64\n",
        "epochs = 100\n",
        "half_batch = batch_size // 2\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    # Train Discriminator\n",
        "    idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
        "    imgs = X_train[idx]\n",
        "    noise = np.random.normal(0, 1, (half_batch, 100))\n",
        "    gen_imgs = generator.predict(noise)\n",
        "    d_loss_real = discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n",
        "    d_loss_fake = discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n",
        "    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "    # Train Generator\n",
        "    noise = np.random.normal(0, 1, (batch_size, 100))\n",
        "    valid_y = np.array([1] * batch_size)\n",
        "    g_loss = combined.train_on_batch(noise, valid_y)\n",
        "\n",
        "    if epoch % 1000 == 0:\n",
        "        print(f\"{epoch} [D loss: {d_loss[0]}] [G loss: {g_loss}]\")\n",
        "\n",
        "\n",
        "def plot_generated_images(epoch, generator, examples=10, dim=(1, 10), figsize=(10, 1)):\n",
        "    noise = np.random.normal(0, 1, (examples, 100))\n",
        "    generated_images = generator.predict(noise)\n",
        "    generated_images = generated_images.reshape(examples, 28, 28)\n",
        "    plt.figure(figsize=figsize)\n",
        "    for i in range(examples):\n",
        "        plt.subplot(dim[0], dim[1], i+1)\n",
        "        plt.imshow(generated_images[i], interpolation='nearest', cmap='gray')\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'gan_generated_image_epoch_{epoch}.png')\n",
        "    plt.show()\n",
        "\n",
        "plot_generated_images(epochs, generator)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8k0j7ubDyAJN",
        "outputId": "f71bea97-2912-45a8-9924-17ce172b9282"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 120ms/step\n",
            "0 [D loss: 1.1080616116523743] [G loss: 0.8168544769287109]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 107ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x100 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Autoencoders and Variational Autoencoders (VAEs)**\n",
        "* Autoencoders compress data into a latent space and reconstruct it. VAEs add a probabilistic approach, ensuring a continuous latent space.\n",
        "\n",
        "**Example:** Basic autoencoder for MNIST"
      ],
      "metadata": {
        "id": "ZhpBPMvzy2uN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Define the encoder\n",
        "input_img = Input(shape=(784,))\n",
        "encoded = Dense(128, activation='relu')(input_img)\n",
        "encoded = Dense(64, activation='relu')(encoded)\n",
        "encoded = Dense(32, activation='relu')(encoded)\n",
        "\n",
        "# Define the decoder\n",
        "decoded = Dense(64, activation='relu')(encoded)\n",
        "decoded = Dense(128, activation='relu')(decoded)\n",
        "decoded = Dense(784, activation='sigmoid')(decoded)\n",
        "\n",
        "# Combine encoder and decoder into an autoencoder model\n",
        "autoencoder = Model(input_img, decoded)\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "# Create the encoder model\n",
        "encoder = Model(input_img, encoded) # Create the encoder model\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "(X_train, _), (X_test, _) = tf.keras.datasets.mnist.load_data()\n",
        "X_train = X_train.astype('float32') / 255.0\n",
        "X_test = X_test.astype('float32') / 255.0\n",
        "X_train = X_train.reshape((len(X_train), np.prod(X_train.shape[1:])))\n",
        "X_test = X_test.reshape((len(X_test), np.prod(X_test.shape[1:])))\n",
        "\n",
        "# Train the autoencoder\n",
        "autoencoder.fit(X_train, X_train, epochs=50, batch_size=256, shuffle=True, validation_data=(X_test, X_test))\n",
        "\n",
        "encoded_imgs = encoder.predict(X_test) # Now you can use the encoder model\n",
        "decoded_imgs = autoencoder.predict(X_test)\n",
        "\n",
        "n = 10  # Number of digits to display\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "    # Display original\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(X_test[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.axis('off')\n",
        "\n",
        "    # Display reconstruction\n",
        "    ax = plt.subplot(2, n, i + 1 + n)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "De_AZUUvyxcN",
        "outputId": "06d688de-fb6b-42c0-b2d5-8e607ceb33ea"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "235/235 [==============================] - 3s 6ms/step - loss: 0.2437 - val_loss: 0.1669\n",
            "Epoch 2/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.1499 - val_loss: 0.1360\n",
            "Epoch 3/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.1313 - val_loss: 0.1253\n",
            "Epoch 4/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.1232 - val_loss: 0.1193\n",
            "Epoch 5/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.1173 - val_loss: 0.1132\n",
            "Epoch 6/50\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 0.1123 - val_loss: 0.1092\n",
            "Epoch 7/50\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 0.1088 - val_loss: 0.1061\n",
            "Epoch 8/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.1065 - val_loss: 0.1041\n",
            "Epoch 9/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.1047 - val_loss: 0.1025\n",
            "Epoch 10/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.1032 - val_loss: 0.1009\n",
            "Epoch 11/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.1015 - val_loss: 0.0999\n",
            "Epoch 12/50\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 0.1002 - val_loss: 0.0982\n",
            "Epoch 13/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0989 - val_loss: 0.0975\n",
            "Epoch 14/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0978 - val_loss: 0.0963\n",
            "Epoch 15/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0970 - val_loss: 0.0956\n",
            "Epoch 16/50\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 0.0960 - val_loss: 0.0947\n",
            "Epoch 17/50\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.0952 - val_loss: 0.0938\n",
            "Epoch 18/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0944 - val_loss: 0.0936\n",
            "Epoch 19/50\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 0.0938 - val_loss: 0.0927\n",
            "Epoch 20/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0931 - val_loss: 0.0921\n",
            "Epoch 21/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0927 - val_loss: 0.0918\n",
            "Epoch 22/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0922 - val_loss: 0.0916\n",
            "Epoch 23/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0917 - val_loss: 0.0913\n",
            "Epoch 24/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0913 - val_loss: 0.0902\n",
            "Epoch 25/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0909 - val_loss: 0.0900\n",
            "Epoch 26/50\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 0.0905 - val_loss: 0.0901\n",
            "Epoch 27/50\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 0.0902 - val_loss: 0.0894\n",
            "Epoch 28/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0898 - val_loss: 0.0889\n",
            "Epoch 29/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0895 - val_loss: 0.0887\n",
            "Epoch 30/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0893 - val_loss: 0.0885\n",
            "Epoch 31/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0890 - val_loss: 0.0884\n",
            "Epoch 32/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0888 - val_loss: 0.0880\n",
            "Epoch 33/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0885 - val_loss: 0.0876\n",
            "Epoch 34/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0883 - val_loss: 0.0880\n",
            "Epoch 35/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0881 - val_loss: 0.0875\n",
            "Epoch 36/50\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 0.0880 - val_loss: 0.0873\n",
            "Epoch 37/50\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 0.0878 - val_loss: 0.0872\n",
            "Epoch 38/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0876 - val_loss: 0.0868\n",
            "Epoch 39/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0874 - val_loss: 0.0869\n",
            "Epoch 40/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0873 - val_loss: 0.0868\n",
            "Epoch 41/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0871 - val_loss: 0.0869\n",
            "Epoch 42/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0870 - val_loss: 0.0871\n",
            "Epoch 43/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0869 - val_loss: 0.0864\n",
            "Epoch 44/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0867 - val_loss: 0.0861\n",
            "Epoch 45/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0866 - val_loss: 0.0862\n",
            "Epoch 46/50\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 0.0865 - val_loss: 0.0859\n",
            "Epoch 47/50\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 0.0863 - val_loss: 0.0859\n",
            "Epoch 48/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0862 - val_loss: 0.0857\n",
            "Epoch 49/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0860 - val_loss: 0.0854\n",
            "Epoch 50/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0858 - val_loss: 0.0853\n",
            "313/313 [==============================] - 0s 1ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x400 with 20 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Variational Autoencoder Example:**\n",
        "\n"
      ],
      "metadata": {
        "id": "OVqvRGeJzITu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Lambda\n",
        "from tensorflow.keras import backend as K\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Define the sampling function\n",
        "def sampling(args):\n",
        "    z_mean, z_log_var = args\n",
        "    batch = K.shape(z_mean)[0]\n",
        "    dim = K.int_shape(z_mean)[1]\n",
        "    epsilon = K.random_normal(shape=(batch, dim))\n",
        "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "# Define the encoder\n",
        "input_img = Input(shape=(784,))\n",
        "h = Dense(128, activation='relu')(input_img)\n",
        "z_mean = Dense(2)(h)\n",
        "z_log_var = Dense(2)(h)\n",
        "\n",
        "z = Lambda(sampling, output_shape=(2,))([z_mean, z_log_var])\n",
        "\n",
        "# Define the decoder\n",
        "decoder_h = Dense(128, activation='relu')\n",
        "decoder_mean = Dense(784, activation='sigmoid')\n",
        "h_decoded = decoder_h(z)\n",
        "x_decoded_mean = decoder_mean(h_decoded)\n",
        "\n",
        "# Define the VAE model\n",
        "vae = Model(input_img, x_decoded_mean)\n",
        "\n",
        "# Define the loss\n",
        "def vae_loss(x, x_decoded_mean):\n",
        "    xent_loss = tf.keras.backend.binary_crossentropy(x, x_decoded_mean) # Use tf.keras.backend.binary_crossentropy\n",
        "    kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
        "    return K.mean(xent_loss + kl_loss) # Calculate mean of the sum of losses\n",
        "\n",
        "vae.compile(optimizer='adam', loss=vae_loss)\n",
        "\n",
        "# Train the VAE\n",
        "# vae.fit(X_train, X_train, epochs=50, batch_size=256, shuffle=True, validation_data=(X_test, X_test))\n"
      ],
      "metadata": {
        "id": "jxJ8Y9yDzOf9"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Attention Mechanism**\n",
        "* Attention mechanisms allow models to focus on relevant parts of the input sequence, crucial in tasks like machine translation.\n",
        "\n",
        "**Example:** Attention in Seq2Seq model"
      ],
      "metadata": {
        "id": "HqSjCttJzSLS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Attention\n",
        "\n",
        "# Define the encoder\n",
        "encoder_inputs = Input(shape=(None, 128))\n",
        "encoder_lstm = LSTM(128, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
        "\n",
        "# Define the decoder with attention\n",
        "decoder_inputs = Input(shape=(None, 128))\n",
        "decoder_lstm = LSTM(128, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=[state_h, state_c])\n",
        "\n",
        "# Apply attention\n",
        "attention = Attention()([decoder_outputs, encoder_outputs])\n",
        "decoder_concat_input = tf.keras.layers.Concatenate(axis=-1)([decoder_outputs, attention])\n",
        "\n",
        "# Define the output layer\n",
        "decoder_dense = Dense(128, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_concat_input)\n",
        "\n",
        "# Define the full model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "# model.fit([encoder_input_data, decoder_input_data], decoder_target_data, epochs=100)\n"
      ],
      "metadata": {
        "id": "IhqXoWxjzYdL"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Transformer**\n",
        "* Transformers are a type of model architecture that relies entirely on self-attention mechanisms and is widely used in NLP tasks.\n",
        "\n",
        "**Example:** Transformer for text classification"
      ],
      "metadata": {
        "id": "Uxq-mmjZzdre"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Embedding, Dense, Dropout, LayerNormalization, MultiHeadAttention, GlobalAveragePooling1D\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Define the transformer block\n",
        "def transformer_block(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
        "    attn_output = MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(inputs, inputs)\n",
        "    attn_output = LayerNormalization(epsilon=1e-6)(attn_output + inputs)\n",
        "    ffn_output = Dense(ff_dim, activation='relu')(attn_output)\n",
        "    ffn_output = Dense(inputs.shape[-1])(ffn_output)\n",
        "    ffn_output = LayerNormalization(epsilon=1e-6)(ffn_output + attn_output)\n",
        "    return ffn_output\n",
        "\n",
        "# Define the transformer model\n",
        "inputs = Input(shape=(None,))\n",
        "x = Embedding(input_dim=20000, output_dim=128)(inputs)\n",
        "x = transformer_block(x, head_size=128, num_heads=4, ff_dim=128, dropout=0.1)\n",
        "x = GlobalAveragePooling1D()(x)\n",
        "x = Dropout(0.1)(x)\n",
        "outputs = Dense(20, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs, outputs)\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Create some dummy data for demonstration purposes\n",
        "import numpy as np\n",
        "x_train = np.random.randint(20000, size=(100, 10))  # Replace with your actual training data\n",
        "y_train = np.random.randint(20, size=(100,))  # Replace with your actual training labels\n",
        "x_val = np.random.randint(20000, size=(20, 10))    # Replace with your actual validation data\n",
        "y_val = np.random.randint(20, size=(20,))      # Replace with your actual validation labels\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_val, y_val))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming 'history' is obtained from model.fit()\n",
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0, 1])\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 822
        },
        "id": "nRTAdt4Qzi8R",
        "outputId": "b3051824-7b99-4ddf-dfc0-dc9867cf735a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "4/4 [==============================] - 6s 203ms/step - loss: 3.2088 - accuracy: 0.0700 - val_loss: 3.3486 - val_accuracy: 0.0500\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 2.0984 - accuracy: 0.3800 - val_loss: 3.2762 - val_accuracy: 0.1000\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 1.3016 - accuracy: 0.8800 - val_loss: 3.3743 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.7105 - accuracy: 1.0000 - val_loss: 3.4198 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.3351 - accuracy: 1.0000 - val_loss: 3.3805 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.1404 - accuracy: 1.0000 - val_loss: 3.3309 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 0.0705 - accuracy: 1.0000 - val_loss: 3.3001 - val_accuracy: 0.0500\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 0.0383 - accuracy: 1.0000 - val_loss: 3.2902 - val_accuracy: 0.0500\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0264 - accuracy: 1.0000 - val_loss: 3.2836 - val_accuracy: 0.1000\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 3.2816 - val_accuracy: 0.1000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAG2CAYAAACDLKdOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABPYklEQVR4nO3dd3TT9f7H8WfSkQ666GKVtuy9oRRwAYqiXAFRQa8guMWBXK+CCuhVQLkXRC+OHyjgYClXkSuIV+tgKggWQfYsCC0thU66kvz+CC1WhhTSfpP09Tgn59hPvknebYp59TNNdrvdjoiIiIiHMBtdgIiIiIgzKdyIiIiIR1G4EREREY+icCMiIiIeReFGREREPIrCjYiIiHgUhRsRERHxKAo3IiIi4lEUbkRERMSjKNyIiIiIRzE03KxcuZJ+/fpRp04dTCYTS5Ys+dPHfPfdd3To0AGLxUKjRo2YO3dupdcpIiIi7sPQcJOXl0fbtm154403Lur6/fv3c+ONN3LNNdeQnJzMqFGjuPfee/nyyy8ruVIRERFxFyZXOTjTZDLx6aef0r9///Ne8/TTT7Ns2TK2bt1a1jZ48GBOnjzJihUrqqBKERERcXXeRhdQEevWraN3797l2vr06cOoUaPO+5jCwkIKCwvLvrbZbGRmZhIeHo7JZKqsUkVERMSJ7HY7OTk51KlTB7P5wgNPbhVuUlNTiY6OLtcWHR1NdnY2p06dwt/f/6zHTJ48mRdeeKGqShQREZFKdOjQIerVq3fBa9wq3FyKsWPHMnr06LKvs7KyqF+/PocOHSI4ONjAykTOb39GLg99uInDJ04R6u/NpFvaUDfEz+iyREQuisXbi3o1A5z6nNnZ2cTExBAUFPSn17pVuKlVqxZpaWnl2tLS0ggODj5nrw2AxWLBYrGc1R4cHKxwIy5pU8oJ7vlwKyfyTcTWDue94V1oEFnD6LJERFzCxUwpcatwk5iYyPLly8u1ffXVVyQmJhpUkYhzfbUtjUcXbKKg2EabeiG8O6wzkUFnh3MRETk/Q5eC5+bmkpycTHJyMuBY6p2cnExKSgrgGFIaOnRo2fUPPvgg+/bt46mnnmLHjh28+eabfPTRRzzxxBNGlC/iVB/8cJAHPviJgmIb1zSNZOH9XRVsREQugaE9Nz/99BPXXHNN2delc2OGDRvG3LlzOXr0aFnQAYiPj2fZsmU88cQTvPbaa9SrV4933nmHPn36VHntIs5it9v555c7efO7vQAM7hzDS/1b4e2lDcRFRC6Fy+xzU1Wys7MJCQkhKytLc27EcEUlNsb85xc++fk3AJ7o3YTHejXSNgUiIn9Qkc9vt5pzI+JJcgqKeejDTazek4GX2cTkga25rVOM0WWJiLg9hRsRA6RlFzBs9np2pOYQ4OvFm3d24OqmUUaXJSLiERRuRKrY7rQchs1ez5GsAiJqWJhzd2da1wsxuiwREY+hcCNShX7cd5z73v+J7IISGkQG8t7wLsQ4eaMrEZHqTuFGpIos++UoTyxKpshqo2NsGO8M7URYoK/RZYmIeByFG5Eq8M6qfUxcvh27Hfq0jOa1we3x8/EyuiwREY+kcCNSiWw2Oy8t287sNfsBGJYYy/h+LfEya6m3iEhlUbgRqSQFxVb+9tFmlm05CsDYG5px/5UNtIeNiEglU7gRqQRZ+cXc98FPrN+fiY+XiX/d2pab29U1uiwRkWpB4UbEyX47eYphs9ez51guQRZv/m9oR7o1jDC6LBGRakPhRsSJth3J5u456zmWU0itYD/mjuhMs1o65kNEpCop3Ig4yerdGTz44UZyC0toEl2DucO7UCfU3+iyRESqHYUbESf4ZNNhnlr8CyU2O10b1OT/7upEiL+P0WWJiFRLCjcil8Fut/Pmd3v555c7AejXtg7/urUNFm/tYSMiYhSFG5FLZLXZmbB0Kx/+kALAA1c24Onrm2HWHjYiIoZSuBG5BKeKrDy64Ge+3p6GyQQTbmrB3d3jjS5LRERQuBGpsMy8Iu55bwM/p5zE19vMa7e344bWtY0uS0RETlO4EamAg8fzuHvOBvZn5BHi78O7wzrRKa6m0WWJiMjvKNyIXKTNh04yYu4GjucVUTfUn/dGdKFRVA2jyxIRkT9QuBG5CN/sSGPkvJ85VWylZZ1g5gzvTFSQn9FliYjIOSjciPyJhetTeHbJVqw2O1c2ieTNOztQw6J/OiIirkr/hxY5D7vdzqtf7+b1pN0ADOpYj8kDW+PjZTa4MhERuRCFG5FzKLbaeOaTLXy88TAAj/VsxBPXNsFk0h42IiKuTuFG5A9yC0t4eN4mVu5Kx2yCl/q35o6E+kaXJSIiF0nhRuR3juUUMGLuBrb+lo2/jxcz7mhPr+bRRpclIiIVoHAjctre9FyGzV7P4ROnCA/0ZfbdnWkbE2p0WSIiUkEKNyLATwcyuff9nziZX0xceADvjehCbHig0WWJiMglULiRam/F1lQeX/gzhSU22sWE8u6wToTXsBhdloiIXCKFG6nW3lt7gOf/+yt2O/RuHsW/h3TA39fL6LJEROQyKNxItWSz2Xnlyx383/f7ALgzoT4v/KUl3trDRkTE7SncSLVTWGLlqcW/8FnyEQD+3qcpD1/dUHvYiIh4CIUbqVayThXz4AcbWbfvON5mE1MGtWFgh3pGlyUiIk6kcCPVxtGsU9w9ewM703KoYfHmrb924IrGkUaXJSIiTqZwI9XCztQc7p6znqNZBUQFWZgzvDMt64QYXZaIiFQChRvxeGv3ZvDABxvJKSihUVQN5g7vTL2wAKPLEhGRSqJwIx5t6eYjPPnRZoqsNrrE1WTm0I6EBvgaXZaIiFQihRvxWHPW7OeF/24D4MbWtZl6W1v8fLSHjYiIp1O4EY90Iq+Il5ZtB2BE93ieu7E5ZrOWeouIVAcKN+KR1uzNwGqz0yS6BuP7tTC6HBERqULajlU80urdGQBa6i0iUg0p3IjHsdvtrDodbno0jjC4GhERqWoKN+Jx9mfk8dvJU/h6mUmIr2l0OSIiUsUUbsTjrN7j6LXpGBtGgK+mlYmIVDcKN+JxVu46Pd+miYakRESqI4Ub8SjFVhs/7DsOwBWNNJlYRKQ6UrgRj5J86CS5hSWEBfjQsk6w0eWIiIgBFG7Eo5SukureKEKb9omIVFMKN+JRVu9OB+AKLQEXEam2FG7EY2SdKib50EkAemjzPhGRakvhRjzGur3HsdmhQWQgdUP9jS5HREQMonAjHmNV6ZBUIw1JiYhUZwo34jFKN+/TeVIiItWbwo14hJTj+Rw8no+32UTXhuFGlyMiIgZSuBGPsGqPY0iqQ/0walh05IKISHWmcCMeYbVOARcRkdMUbsTtWW121pTNt1G4ERGp7hRuxO39cvgk2QUlBPt506ZeqNHliIiIwRRuxO2VHrnQrWEEXjpyQUSk2lO4EbdXOt/miiYakhIREYUbcXO5hSVsSjkBwBWNtL+NiIgo3Iib+2HvcUpsdmLDA6gfHmB0OSIi4gIUbsStle5K3ENHLoiIyGkKN+LWVpaeJ6Ul4CIicprh4eaNN94gLi4OPz8/EhISWL9+/QWvnz59Ok2bNsXf35+YmBieeOIJCgoKqqhacSVHTp5iX3oeZhMkNlS4ERERB0PDzaJFixg9ejQTJkxg06ZNtG3blj59+nDs2LFzXj9//nzGjBnDhAkT2L59O++++y6LFi3imWeeqeLKxRWUrpJqGxNKiL+PwdWIiIirMDTcTJs2jfvuu4/hw4fTokUL3n77bQICApg9e/Y5r1+7di3du3fnjjvuIC4ujuuuu44hQ4b8aW+PeKYzQ1JaJSUiImcYFm6KiorYuHEjvXv3PlOM2Uzv3r1Zt27dOR/TrVs3Nm7cWBZm9u3bx/Lly+nbt+95X6ewsJDs7OxyN3F/Nh25ICIi52HY8ckZGRlYrVaio6PLtUdHR7Njx45zPuaOO+4gIyODHj16YLfbKSkp4cEHH7zgsNTkyZN54YUXnFq7GO/XI9mcyC+mhsWbdjGhRpcjIiIuxPAJxRXx3XffMWnSJN588002bdrEJ598wrJly3jxxRfP+5ixY8eSlZVVdjt06FAVViyVZdUex5BU1wbh+Hi51a+xiIhUMsN6biIiIvDy8iItLa1ce1paGrVq1TrnY8aNG8ddd93FvffeC0Dr1q3Jy8vj/vvv59lnn8VsPvtDzmKxYLFYnP8NiKHKjlzQkJSIiPyBYX/y+vr60rFjR5KSksrabDYbSUlJJCYmnvMx+fn5ZwUYLy8vAOx2e+UVKy7lVJGVnw6cPnJB4UZERP7AsJ4bgNGjRzNs2DA6depEly5dmD59Onl5eQwfPhyAoUOHUrduXSZPngxAv379mDZtGu3btychIYE9e/Ywbtw4+vXrVxZyxPP9uP84RVYbdUP9iY8INLocERFxMYaGm9tvv5309HTGjx9Pamoq7dq1Y8WKFWWTjFNSUsr11Dz33HOYTCaee+45fvvtNyIjI+nXrx8TJ0406lsQA6zafebIBZPJZHA1IiLiakz2ajaek52dTUhICFlZWQQHBxtdjlyCPq+uZGdaDjPuaM9NbeoYXY6IiFSBinx+a5mJuJVj2QXsTMvBZILuOnJBRETOQeFG3ErpkFTruiGEBfoaXI2IiLgihRtxK6v3nJlvIyIici4KN+I27Hb7mcnEWgIuIiLnoXAjbmNHag4ZuYX4+3jRMTbM6HJERMRFKdyI2yjdlTihQU0s3trXSEREzk3hRtzGyt2O86SuaBxpcCUiIuLKFG7ELRQUW1m/PxPQkQsiInJhCjfiFn46cILCEhvRwRYaR9UwuhwREXFhCjfiFlbtcQxJ9WgUqSMXRETkghRuxC2s2uWYTKwhKRER+TMKN+LyMnIL2XY0G4Du2rxPRET+hMKNuLw1p3clbl47mMggi8HViIiIq1O4EZdXuiuxhqRERORiKNyIS7Pb7WWb9ynciIjIxVC4EZe251guqdkF+Hqb6RxX0+hyRETEDSjciEsrHZJKiK+Jn4+OXBARkT+ncCMubfXpycQ9tEpKREQuksKNuKyiEhs/7DsOQA/NtxERkYukcCMua1PKCfKLrETU8KV5rWCjyxERETehcCMua9XpU8C7N4rAbNaRCyIicnEUbsRlnVkCHmlwJSIi4k4UbsQlncwv4pffsgBNJhYRkYpRuBGXtGbPcex2aBxVg1ohfkaXIyIibkThRlzS6j2O+TYakhIRkYpSuBGXY7fbWblLRy6IiMilUbgRl3PgeD6/nTyFj5eJhAY6ckFERCpG4UZczurTS8A7xoYR4OttcDUiIuJuFG7E5azUEnAREbkMCjfiUoqtNn7Y6zhyQfNtRETkUijciEvZfOgkOYUlhAb40LJOiNHliIiIG1K4EZey6vSQVPdGEXjpyAUREbkECjfiUlbvOT3fRrsSi4jIJVK4EZeRXVBM8qGTAPTQfBsREblECjfiMtbtPY7VZqdBRCD1wgKMLkdERNyUwo24jFWn97dRr42IiFwOhRtxGau1v42IiDiBwo24hEOZ+Rw4no+X2URXHbkgIiKXQeFGXELpEvAO9UMJ8vMxuBoREXFnCjfiElbvOT3fppGGpERE5PIo3IjhrDY7a/Y4jlzQZGIREblcCjdiuC2/ZZF1qpggP2/a1tORCyIicnkUbsRwq3Y5hqS6NQzH20u/kiIicnn0SSKGW7VHS8BFRMR5FG7EULmFJfyccgKAKzTfRkREnEDhRgz1477jFFvtxNT0JzY80OhyRETEAyjciKFWaVdiERFxMoUbMVTpeVJXNNKQlIiIOIfCjRjmaNYp9qbnYTZBt4YKNyIi4hwKN2KY0iGpNvVCCQnQkQsiIuIcCjdimDPzbdRrIyIizqNwI4aw2eys0f42IiJSCRRuxBDbjmaTmVdEoK8X7euHGl2OiIh4EIUbMUTpkFRiw3B8dOSCiIg4kT5VxBCr9ziWgPfQEnAREXEyhRupcqeKrGzY7zhyoYfm24iIiJMp3EiVW38gkyKrjTohfjSM1JELIiLiXAo3UuVW7To9JNU4ApPJZHA1IiLiaRRupMqt1hJwERGpRAo3UqWOZRewIzUHkwm6azKxiIhUAoUbqVKlvTYt6wRTM9DX4GpERMQTKdxIlVq9W0NSIiJSuRRupMrY7XZWlc630ZCUiIhUEsPDzRtvvEFcXBx+fn4kJCSwfv36C15/8uRJRo4cSe3atbFYLDRp0oTly5dXUbVyOXam5ZCeU4ifj5mOcWFGlyMiIh7K28gXX7RoEaNHj+btt98mISGB6dOn06dPH3bu3ElUVNRZ1xcVFXHttdcSFRXF4sWLqVu3LgcPHiQ0NLTqi5cKKx2SSogPx+LtZXA1IiLiqQwNN9OmTeO+++5j+PDhALz99tssW7aM2bNnM2bMmLOunz17NpmZmaxduxYfHx8A4uLiqrJkuQwry+bbaEhKREQqj2HDUkVFRWzcuJHevXufKcZspnfv3qxbt+6cj1m6dCmJiYmMHDmS6OhoWrVqxaRJk7Bared9ncLCQrKzs8vdpOoVFFtZv/84oMnEIiJSuQwLNxkZGVitVqKjo8u1R0dHk5qaes7H7Nu3j8WLF2O1Wlm+fDnjxo1j6tSpvPTSS+d9ncmTJxMSElJ2i4mJcer3IRdn48ETFBTbiAqy0CS6htHliIiIBzN8QnFF2Gw2oqKimDlzJh07duT222/n2Wef5e233z7vY8aOHUtWVlbZ7dChQ1VYsZRadXpISkcuiIhIZTNszk1ERAReXl6kpaWVa09LS6NWrVrnfEzt2rXx8fHBy+vMZNTmzZuTmppKUVERvr5nbwpnsViwWCzOLV4qbNVux3lSmm8jIiKVzbCeG19fXzp27EhSUlJZm81mIykpicTExHM+pnv37uzZswebzVbWtmvXLmrXrn3OYCOu4XhuIb8eccx10pELIiJS2Qwdlho9ejSzZs3ivffeY/v27Tz00EPk5eWVrZ4aOnQoY8eOLbv+oYceIjMzk8cff5xdu3axbNkyJk2axMiRI436FuQirNnrmEjcrFYQUUF+BlcjIiKeztCl4Lfffjvp6emMHz+e1NRU2rVrx4oVK8omGaekpGA2n8lfMTExfPnllzzxxBO0adOGunXr8vjjj/P0008b9S3IRVi1S0NSIiJSdUx2u91udBFVKTs7m5CQELKysggODja6HI9nt9vp9vI3HM0q4P0RXbiyiZaBi4hIxVXk89utVkuJ+9mbnsvRrAJ8vc10ia9pdDkiIlINVDjcxMXF8Y9//IOUlJTKqEc8TOkS8M5xYfj56MgFERGpfBUON6NGjeKTTz6hQYMGXHvttSxcuJDCwsLKqE08wOqyIxc0HCUiIlXjksJNcnIy69evp3nz5jz66KPUrl2bRx55hE2bNlVGjeKmikpsrNvnWCnVQ0vARUSkilzynJsOHTrw+uuvc+TIESZMmMA777xD586dadeuHbNnz6aazVOWc/g55QT5RVbCA31pUVuTt0VEpGpc8lLw4uJiPv30U+bMmcNXX31F165dueeeezh8+DDPPPMMX3/9NfPnz3dmreJmSufbdG8UgdmsIxdERKRqVDjcbNq0iTlz5rBgwQLMZjNDhw7l1VdfpVmzZmXXDBgwgM6dOzu1UHE/q/acOU9KRESkqlQ43HTu3Jlrr72Wt956i/79++Pj43PWNfHx8QwePNgpBYp7OplfxJbDJwFt3iciIlWrwuFm3759xMbGXvCawMBA5syZc8lFiftbu/c4Njs0iqpB7RB/o8sREZFqpMITio8dO8aPP/54VvuPP/7ITz/95JSixP2tKlsCrl4bERGpWhUONyNHjuTQoUNntf/22286wFIAx5ELq3brPCkRETFGhcPNtm3b6NChw1nt7du3Z9u2bU4pStzbweP5HD5xCh8vEwnx4UaXIyIi1UyFw43FYiEtLe2s9qNHj+Ltbegh4+IiSldJdagfRqBFvxMiIlK1KhxurrvuOsaOHUtWVlZZ28mTJ3nmmWe49tprnVqcuKdVuzQkJSIixqnwn9X/+te/uPLKK4mNjaV9+/YAJCcnEx0dzQcffOD0AsW9lFhtrNvrOHJB50mJiIgRKhxu6tatyy+//MK8efPYvHkz/v7+DB8+nCFDhpxzzxupXjYfPklOYQkh/j60qhtidDkiIlINXdKEiMDAQO6//35n1yIeoHQJeI9GEXjpyAURETHAJc/23LZtGykpKRQVFZVr/8tf/nLZRYn7Wr1bRy6IiIixLmmH4gEDBrBlyxZMJlPZ6d8mk+OvdKvV6twKxW1kFxTz86GTgKPnRkRExAgVXi31+OOPEx8fz7FjxwgICODXX39l5cqVdOrUie+++64SShR38cPe41htduIjAompGWB0OSIiUk1VuOdm3bp1fPPNN0RERGA2mzGbzfTo0YPJkyfz2GOP8fPPP1dGneIGfj/fRkRExCgV7rmxWq0EBQUBEBERwZEjRwCIjY1l586dzq1O3MrqPTpPSkREjFfhnptWrVqxefNm4uPjSUhIYMqUKfj6+jJz5kwaNGhQGTWKGziUmc/+jDy8zCa6NtSRCyIiYpwKh5vnnnuOvLw8AP7xj39w0003ccUVVxAeHs6iRYucXqC4h9Jem3YxoQT7ab8jERExToXDTZ8+fcr+u1GjRuzYsYPMzEzCwsLKVkxJ9VO6BFxDUiIiYrQKzbkpLi7G29ubrVu3lmuvWbOmgk01ZrXZNd9GRERcRoXCjY+PD/Xr19deNlLO1t+yyDpVTJDFm7b1Qo0uR0REqrkKr5Z69tlneeaZZ8jMzKyMesQNrdrtOAU8sWE43l4V/pUSERFxqgrPuZkxYwZ79uyhTp06xMbGEhgYWO7+TZs2Oa04cQ+rNN9GRERcSIXDTf/+/SuhDHFXeYUlbEo5AcAVjSMNrkZEROQSws2ECRMqow5xUz/uP06x1U69MH9iw3XkgoiIGE8TJOSynBmSitSKORERcQkV7rkxm80X/BDTSqrqRfNtRETE1VQ43Hz66aflvi4uLubnn3/mvffe44UXXnBaYeL6jmadYs+xXEwm6KYjF0RExEVUONzcfPPNZ7UNGjSIli1bsmjRIu655x6nFCaur3RX4jb1QgkN8DW4GhEREQenzbnp2rUrSUlJzno6cQNlQ1KNNCQlIiKuwynh5tSpU7z++uvUrVvXGU8nbsBms7NGRy6IiIgLqvCw1B8PyLTb7eTk5BAQEMCHH37o1OLEdW07ms3xvCICfL1oXz/M6HJERETKVDjcvPrqq+XCjdlsJjIykoSEBMLC9CFXXZQelNm1QTi+3tpRQEREXEeFw83dd99dCWWIu1mtJeAiIuKiKvwn95w5c/j444/Pav/444957733nFKUuLaCYivrDzgOTlW4ERERV1PhcDN58mQiIs7+QIuKimLSpElOKUpc2/r9mRSV2Kgd4kfDyBpGlyMiIlJOhcNNSkoK8fHxZ7XHxsaSkpLilKLEta3anQ5Aj0YROnJBRERcToXDTVRUFL/88stZ7Zs3byY8XLvUVgel+9v00JCUiIi4oAqHmyFDhvDYY4/x7bffYrVasVqtfPPNNzz++OMMHjy4MmoUF3Isp4AdqTmAo+dGRETE1VR4tdSLL77IgQMH6NWrF97ejofbbDaGDh2qOTfVQOnGfS3rBBNew2JwNSIiImercLjx9fVl0aJFvPTSSyQnJ+Pv70/r1q2JjY2tjPrExZw5BTzS4EpERETOrcLhplTjxo1p3LixM2sRF2e327W/jYiIuLwKz7m55ZZbeOWVV85qnzJlCrfeeqtTihLXtCstl2M5hVi8zXSM1W7UIiLimiocblauXEnfvn3Par/hhhtYuXKlU4oS11S6BDyhQTh+Pl4GVyMiInJuFQ43ubm5+Pr6ntXu4+NDdna2U4oS11Q230arpERExIVVONy0bt2aRYsWndW+cOFCWrRo4ZSixPUUllj5cf9xAK5oonAjIiKuq8ITiseNG8fAgQPZu3cvPXv2BCApKYn58+ezePFipxcormHjgRMUFNuIDLLQNDrI6HJERETOq8Lhpl+/fixZsoRJkyaxePFi/P39adu2Ld988w01a9asjBrFBaw6vb+NjlwQERFXd0lLwW+88UZuvPFGALKzs1mwYAFPPvkkGzduxGq1OrVAcQ2lk4m1BFxERFxdhefclFq5ciXDhg2jTp06TJ06lZ49e/LDDz84szZxEZl5Rfx6xDFZXEcuiIiIq6tQz01qaipz587l3XffJTs7m9tuu43CwkKWLFmiycQebM2eDOx2aFYriKhgP6PLERERuaCL7rnp168fTZs25ZdffmH69OkcOXKEf//735VZm7iI0iEp9dqIiIg7uOiemy+++ILHHnuMhx56SMcuVCO/P3Khh+bbiIiIG7jonpvVq1eTk5NDx44dSUhIYMaMGWRkZFRmbeIC9qbncSSrAF8vMwnx4UaXIyIi8qcuOtx07dqVWbNmcfToUR544AEWLlxInTp1sNlsfPXVV+Tk5FRmnWKQ1aeHpDrFheHvqyMXRETE9VV4tVRgYCAjRoxg9erVbNmyhb/97W+8/PLLREVF8Ze//KUyahQDrd5Tegp4pMGViIiIXJxLXgoO0LRpU6ZMmcLhw4dZsGCBs2oSF1FstbFu7+kjFzTfRkRE3MRlhZtSXl5e9O/fn6VLl17S49944w3i4uLw8/MjISGB9evXX9TjFi5ciMlkon///pf0unJhP6ecJK/ISs1AX1rUDja6HBERkYvilHBzORYtWsTo0aOZMGECmzZtom3btvTp04djx45d8HEHDhzgySef5IorrqiiSquf0iXg3RtFYDbryAUREXEPhoebadOmcd999zF8+HBatGjB22+/TUBAALNnzz7vY6xWK3feeScvvPACDRo0qMJqq5dVp5eAX6H9bURExI0YGm6KiorYuHEjvXv3Lmszm8307t2bdevWnfdx//jHP4iKiuKee+7509coLCwkOzu73E3+XFZ+Mb8cPglofxsREXEvhoabjIwMrFYr0dHR5dqjo6NJTU0952NWr17Nu+++y6xZsy7qNSZPnkxISEjZLSYm5rLrrg7W7s3AZoeGkYHUCfU3uhwREZGLZviwVEXk5ORw1113MWvWLCIiLq43YezYsWRlZZXdDh06VMlVeoZVWgIuIiJuqkIHZzpbREQEXl5epKWllWtPS0ujVq1aZ12/d+9eDhw4QL9+/crabDYbAN7e3uzcuZOGDRuWe4zFYsFisVRC9Z6tdDKxloCLiIi7MbTnxtfXl44dO5KUlFTWZrPZSEpKIjEx8azrmzVrxpYtW0hOTi67/eUvf+Gaa64hOTlZQ05OcvB4HocyT+FtNpHQQEcuiIiIezG05wZg9OjRDBs2jE6dOtGlSxemT59OXl4ew4cPB2Do0KHUrVuXyZMn4+fnR6tWrco9PjQ0FOCsdrl0paukOsSGUcNi+K+IiIhIhRj+yXX77beTnp7O+PHjSU1NpV27dqxYsaJsknFKSgpms1tNDXJ7ZUNSWgIuIiJuyGS32+1GF1GVsrOzCQkJISsri+Bg7br7RyVWG+1f/IqcghKWjOxOu5hQo0sSERGp0Oe3ukSknK+3HyOnoISwAB9a1w0xuhwREZEKU7iRcmav2Q/AkC718dKRCyIi4oYUbqTM1t+yWL8/E2+zibsSY40uR0RE5JIo3EiZ0l6bvq1rUztEuxKLiIh7UrgRAI7lFPDfzUcAGNEj3uBqRERELp3CjQAw74cUiq12OtQP1QopERFxawo3QkGxlXk/HgTUayMiIu5P4Ub47+YjZOQWUSfEj+tbnn2ml4iIiDtRuKnm7HY7s9ccAGBotzi8vfQrISIi7k2fZNXcD/sy2X40G38fLwZ31sGjIiLi/hRuqrnS5d8DO9QlNMDX4GpEREQun8JNNXbweB5fb08DYHj3OGOLERERcRKFm2ps7toD2O1wVZNIGkUFGV2OiIiIUyjcVFM5BcV8/NNhQMu/RUTEsyjcVFMf/XSY3MISGkXV4MrGEUaXIyIi4jQKN9WQ1WZn7lrHROLh3eMwmXT6t4iIeA6Fm2ro6+1pHMo8RYi/DwPb1zO6HBEREadSuKmGZq929NrckVAff18vg6sRERFxLoWbambrb1n8uD8TL7OJoYmxRpcjIiLidAo31cyc00ct9G1dm9oh/sYWIyIiUgkUbqqR9JxC/rv5CAAjtGmfiIh4KIWbamTejwcpstpoXz+U9vXDjC5HRESkUijcVBOFJVY+/OEgACO6a9M+ERHxXAo31cR/Nx8lI7eI2iF+XN+qltHliIiIVBqFm2rAbreXLf8emhiHj5fedhER8Vz6lKsGftyfybaj2fj5mBnSJcbockRERCqVwk01UNprc0uHeoQG+BpcjYiISOVSuPFwKcfz+Wp7GuA4R0pERMTTKdx4uLlrD2C3w5VNImkUFWR0OSIiIpVO4caD5RQU89FPhwBt2iciItWHwo0H+/inw+QWltAwMpArG0caXY6IiEiVULjxUFabnblrDwAwvHs8ZrPJ2IJERESqiMKNh0rankZKZj4h/j4M7FDX6HJERESqjMKNh5q9xrH8e0iX+gT4ehtcjYiISNVRuPFAvx7J4od9mXiZTQxNjDW6HBERkSqlcOOB5q45AMANrWpRJ9Tf2GJERESqmMKNh8nILeSz5CMAjOih079FRKT6UbjxMPN+SKHIaqNdTCgd6ocZXY6IiEiVU7jxIIUlVj744SCgXhsREam+FG48yOebj5KRW0itYD9uaFXL6HJEREQMoXDjIex2e9ny76HdYvHx0lsrIiLVkz4BPcT6/Zn8eiQbPx8zQzrXN7ocERERwyjceIjSXpuBHeoRFuhrcDUiIiLGUbjxACnH8/nftjQAhneLM7YYERERgynceID31h3Abocrm0TSODrI6HJEREQMpXDj5nIKilm04RAAI7rHGVuMiIiIC1C4cXOLNx4mt7CEBpGBXNk40uhyREREDKdw48asNjtz1x4AYHj3eMxmk7EFiYiIuACFGzf2zY5jHDyeT7CfN7d0qGt0OSIiIi5B4caNzV7tWP49JKE+Ab7eBlcjIiLiGhRu3NT2o9ms23ccL7OJoYlxRpcjIiLiMhRu3NSc05v2Xd+qFnVD/Q2uRkRExHUo3LihjNxCliQfAWBEd53+LSIi8nsKN25o/o8pFJXYaBsTSof6oUaXIyIi4lIUbtxMYYmVD344CDg27TOZtPxbRETk9xRu3MyyX46SnlNIdLCFvq1rG12OiIiIy1G4cSN2u513Ty//HpoYh4+X3j4REZE/0qejG9lw4AS/HsnG4m3mji71jS5HRETEJSncuJHSTfsGdqhHWKCvwdWIiIi4JoUbN3EoM5//bUsFdPq3iIjIhSjcuIn31h7AZocrGkfQODrI6HJERERclsKNG8gtLGHRhkMAjOihTftEREQuROHGDSz+6RA5hSU0iAzkqsaRRpcjIiLi0lwi3LzxxhvExcXh5+dHQkIC69evP++1s2bN4oorriAsLIywsDB69+59wevdnc1mZ87aAwAM7x6P2axN+0RERC7E8HCzaNEiRo8ezYQJE9i0aRNt27alT58+HDt27JzXf/fddwwZMoRvv/2WdevWERMTw3XXXcdvv/1WxZVXjW92HOPg8XyC/by5pUNdo8sRERFxeSa73W43soCEhAQ6d+7MjBkzALDZbMTExPDoo48yZsyYP3281WolLCyMGTNmMHTo0D+9Pjs7m5CQELKysggODr7s+ivbHbN+YO3e4zxwZQPG9m1udDkiIiKGqMjnt6E9N0VFRWzcuJHevXuXtZnNZnr37s26desu6jny8/MpLi6mZs2a57y/sLCQ7Ozscjd3sSM1m7V7j+NlNjG0W5zR5YiIiLgFQ8NNRkYGVquV6Ojocu3R0dGkpqZe1HM8/fTT1KlTp1xA+r3JkycTEhJSdouJibnsuqvKnNUHALi+ZS3qhvobW4yIiIibMHzOzeV4+eWXWbhwIZ9++il+fn7nvGbs2LFkZWWV3Q4dOlTFVV6a47mFfJrsmEc0okecscWIiIi4EW8jXzwiIgIvLy/S0tLKtaelpVGrVq0LPvZf//oXL7/8Ml9//TVt2rQ573UWiwWLxeKUeqvS/B9TKCqx0bZeCB3qhxldjoiIiNswtOfG19eXjh07kpSUVNZms9lISkoiMTHxvI+bMmUKL774IitWrKBTp05VUWqVKiqx8f4PBwHHpn0mk5Z/i4iIXCxDe24ARo8ezbBhw+jUqRNdunRh+vTp5OXlMXz4cACGDh1K3bp1mTx5MgCvvPIK48ePZ/78+cTFxZXNzalRowY1atQw7PtwpmVbjpCeU0h0sIUbWtU2uhwRERG3Yni4uf3220lPT2f8+PGkpqbSrl07VqxYUTbJOCUlBbP5TAfTW2+9RVFREYMGDSr3PBMmTOD555+vytIrhd1u593Tp38PTYzD19utp0WJiIhUOcP3ualqrr7PzYYDmdz69jos3mbWje1FzUBfo0sSERExnNvscyNnm32612Zgh7oKNiIiIpdA4caFHMrM58tfHXOIhnfX6d8iIiKXQuHGhby/7gA2O1zROIIm0UFGlyMiIuKWFG5cRG5hCQs3ODYYHKFeGxERkUumcOMi/rPxMDkFJTSICOSqJpFGlyMiIuK2FG5cgM1mZ84ax0Ti4d3jMJu1aZ+IiMilUrhxAd/uPMaB4/kE+3kzsEM9o8sRERFxawo3LmDOmgMADO5Sn0CL4fsqioiIuDWFG4PtTM1h9Z4MzCYYmhhrdDkiIiJuT+HGYKVzba5vVYt6YQEGVyMiIuL+FG4MdDy3kE9+/g3Q8m8RERFnUbgx0IL1KRSV2GhTL4SOsWFGlyMiIuIRFG4MUlRi4/11BwFHr43JpOXfIiIizqClOQZZvuUox3IKiQqy0Ld1baPLERGpVFarleLiYqPLEBfn4+ODl5fXZT+Pwo0B7HY7s09PJB6aGIuvtzrQRMRz5ebmcvjwYex2u9GliIszmUzUq1ePGjVqXNbzKNwYYOPBE/xyOAuLt5khXeobXY6ISKWxWq0cPnyYgIAAIiMjNQQv52W320lPT+fw4cM0btz4snpwFG4MUNprM6B9XcJrWAyuRkSk8hQXF2O324mMjMTf39/ocsTFRUZGcuDAAYqLiy8r3Gg8pIodPpHPiq2pAAzX8m8RqSbUYyMXw1m/Jwo3Vez9dQex2aFHowia1goyuhwRERGPo3BThfIKS1iwPgWAET3ijC1GRETEQyncVKH/bDpMTkEJ8RGBXN0kyuhyREREPJLCTRWx2exlp38P7x6H2azxZxERkcqgcFNFvt+Vzv6MPIL8vLmlQz2jyxERETejTRAvnsJNFSld/j2kS30CLVqBLyLVk91uJ7+oxJBbRTcRXLFiBT169CA0NJTw8HBuuukm9u7dW3b/4cOHGTJkCDVr1iQwMJBOnTrx448/lt3/3//+l86dO+Pn50dERAQDBgwou89kMrFkyZJyrxcaGsrcuXMBOHDgACaTiUWLFnHVVVfh5+fHvHnzOH78OEOGDKFu3boEBATQunVrFixYUO55bDYbU6ZMoVGjRlgsFurXr8/EiRMB6NmzJ4888ki569PT0/H19SUpKalCPx9Xpk/ZKrArLYdVuzMwmxw7EouIVFeniq20GP+lIa+97R99CPC9+I+9vLw8Ro8eTZs2bcjNzWX8+PEMGDCA5ORk8vPzueqqq6hbty5Lly6lVq1abNq0CZvNBsCyZcsYMGAAzz77LO+//z5FRUUsX768wjWPGTOGqVOn0r59e/z8/CgoKKBjx448/fTTBAcHs2zZMu666y4aNmxIly5dABg7diyzZs3i1VdfpUePHhw9epQdO3YAcO+99/LII48wdepULBbHPmsffvghdevWpWfPnhWuz1Up3FSBOad7bfq0rEW9sACDqxERkYtxyy23lPt69uzZREZGsm3bNtauXUt6ejobNmygZs2aADRq1Kjs2okTJzJ48GBeeOGFsra2bdtWuIZRo0YxcODAcm1PPvlk2X8/+uijfPnll3z00Ud06dKFnJwcXnvtNWbMmMGwYcMAaNiwIT169ABg4MCBPPLII3z22WfcdtttAMydO5e7777bo/YiUripZJl5RXyy6TcARvTQpn0iUr35+3ix7R99DHvtiti9ezfjx4/nxx9/JCMjo6xXJiUlheTkZNq3b18WbP4oOTmZ++6777Jr7tSpU7mvrVYrkyZN4qOPPuK3336jqKiIwsJCAgIcfzhv376dwsJCevXqdc7n8/Pz46677mL27NncdtttbNq0ia1bt7J06dLLrtWVKNxUsgXrUygssdG6bgidYsOMLkdExFAmk6lCQ0NG6tevH7GxscyaNYs6depgs9lo1aoVRUVFf3qUxJ/dbzKZzpoDdK4Jw4GBgeW+/uc//8lrr73G9OnTad26NYGBgYwaNYqioqKLel1wDE21a9eOw4cPM2fOHHr27ElsrGdNmdCE4kpUVGLj/XUHAMemfW7R5We3Q9o2yD5idCUiIoY5fvw4O3fu5LnnnqNXr140b96cEydOlN3fpk0bkpOTyczMPOfj27Rpc8EJupGRkRw9erTs6927dpKfnw/Fp6AgGwpzHHcU5jq+Pn1bs+p7br7pBv466C+0bRpPgzoR7Nq5A6wlUJBN45ho/P39SVrxebnH/f7WunEsnTq0Z9ZbM5g/fx4j/jrkvNde8q0ozzlvxCVyj/jspr7YepS07EIigyzc2LqO0eVcWPZR2PIRJC+A9O3gEwg3/gva3WF0ZSIiVS4sLIzw8HBmzpxJ7dq1SUlJYcyYMWX3DxkyhEmTJtG/f38mT55M7dq1+fnnn6lTpw6JiYlMmDCBXr160bBhQwYPHkxJSQnLly/n6aefBhyrlmbMmEFip3ZY80/w9Lh/4OPjDbnHIHMvnDz9B2bWYcg803vTuG44i5d9zdovPyEsNIhpM+eRlpZGi4YxkLkXP+Dph4fy1DPP4Vt0ku6d25J+/AS/7trHPUP6lz3PvbfdwCPPvUJggD8DrmjheE1n8gmEyCbOfc4KUM9NJbHb7by72jGReGjXWHy9XfBHXZQPv3wMHwyEV1vAV+MdwQYTFOfBkofgkwccfzmIiFQjZrOZhQsXsnHjRlq1asUTTzzBP//5z7L7fX19+d///kdUVBR9+/aldevWvPzyy2UnWV999dV8/PHHLF26lHbt2tGzZ0/Wr1/veLC1iKkvjCEmuiZXXNObO0Y8zJMP3EWAvz94+YK3P3j5Oa71tji+Pn177m+P0KFNS/rcOZKrBz1Areho+t/QC0xeZdeMe/Ix/vbgcMZPfZvmVw/i9ofHciwzp9zzDBnUH28vb4YMuBG/GqHl7nPOzVLF71h5JntFF/67uezsbEJCQsjKyiI4OLjSXmfjwUxueWsdvt5m1o3pSXgNY9/oMjYbpKyFzQvg18+gKOfMfTFdod0QaP4X+Old+HYS2G0Q3ggGzYHabYyrW0TcUkFBAfv37yc+Ph4/Pz+jyzGOzQoFWXAq88yQEwAm8AuBgJpgCYYqmr5w4MABGjZsyIYNG+jQoUOVvObFuNDvS0U+vzUsVUlmrz4AwIB2dV0j2BzfC5sXwi8L4WTKmfbQWGg7BNreDjUbnGm/8u8Q2wP+cw8c3wPv9IY+E6HzvVX2j09ExK3Z7VCU6wg0p046/lgs5RPoCDT+oWCuuo/i4uJijh8/znPPPUfXrl1dKtg4k8JNJTh8Ip8vtjomig038vTvUyfh108coebQmV0z8Q2Clv0d82liuoL5PENmsYnw4Gr4bCTsXA7Ln4R938HNM8BfK79ERM6ppADyTzhCjbXoTLuXL/jXdIQag4Zt1qxZwzXXXEOTJk1YvHixITVUBYWbSvDBuoPY7NC9UTjNalXe0Nc5WYth7zeQPB92fgHWQke7yQwNezp6aZr2Bd+L3EwwoCYMng8/vg3/Gwc7Poejm2HQbIjpUnnfh4iIO7GVOP6gzM90zFksZTI7/hj0rwm+gYb3fF999dUVPobCHSncOFleYQkL1juGfUZ0r8JN+47+4uih2fIR5KWfaY9q4Qg0bW6DoFqX9twmE3R9COp3hcUjIHMfzL4eej4H3Uedv+dHRMST2W2O+TP5mY75NPwuNFiCHIHGLwTMFds8UC6fwo2TfbLpMNkFJcSFB3BN06jKfbGcVNjysSPUpG090x4Q4QgzbQdDrTbO+0uhTnu4/3tYNtrxukkvwP6VMHAm1Kjk71VExBXY7Y69aE5lwqkTjh6bUt5+p+fR1AQvH+NqFIUbZ7LZ7MxZewCA4d3jMZsrofux+BTsWOYINHuTzkxQ8/KFpjdA2zugUa/K+4flFwwDZ0H8VbD877DvW3iruyPgNLymcl5TRMRo1mJHoMnPdMypKWX2PjPs5ONv+LCTOCjcONH3u9PZl55HkJ83gzrWc94T2+2Q8gNsng+/LoHC7DP31eviWL7dckDVTfI1maDDXVCvMyweDse2wQcD4IrRcPUz4KVfKxHxADYbFJz8k+XbQY55NeJS9CnkRLNPb9o3uHMMgRYn/Ggz959Zvn3iwJn2kPqOpdtth0B4w8t/nUsV1Qzu+wZWjIGNc2HVVDiwBm55B0JjjKtLRORS2e2OowPKlm9bz9xn0PJtqTi9O06yKy2HVbszMJtgaGLcpT9RQZajd2bzAkhZd6bdtwa06O/opanfzXUm8fr4Q7/XHMNU/30cDv0Ab/eA/m9CsxuNrk5E5OKUFDqGnM67fDvMMadG3ILCjZNk5hXRIDKQptFBxNS8yGXWpawljrkrmxc45tOUjueazNDgasc8mmY3XvzybSO0GuiYcLx4BBzZBAvvgC4PwHUvGr4Nt4jIOZUu3z6VWf6gR5MZ/EIdvTS+NS55Hk1cXByjRo1i1KhRzqhWKkDhxkm6Ngjn6yeuIqew5M8vLpW61RFotnwMuWln2iObnVm+HeziB27+Xs14GPGlYxXVuhmw/v8cvU+3zjV2+ExEpJTd7pi3qOXbHk3hxonMZhMh/n+ySin32Onl2wsgdcuZ9oBwaH2rY/l27XbuO+Pe29dxTEP8lfDpg5D6C/zflXDTq46wJiJihOJTZ4ad/rh8u3TYycvXuPpcjNVqxWQyYXaVKRAV5J5Vu5viAtj6Ccy7DaY2gy+fcQQbL1/HIZWDF8DfdsINrziGdtw12Pxekz7w0BrH+VRFufDJfbBkZPmuXxGpfkon7FbF7dRJyDwAv/0MR3529JDbShyTgQMjIaKpo6c8KPqsYDNz5kzq1KmDzWYr137zzTczYsQI9u7dy80330x0dDQ1atSgc+fOfP3115f8Y5k2bRqtW7cmMDCQmJgYHn74YXJzc8tds2bNGq6++moCAgIICwujT58+nDhxAgCbzcaUKVNo1KgRFouF+vXrM3HiRAC+++47TCYTJ0+eLHuu5ORkTCYTBw4cAGDu3LmEhoaydOlSWrRogcViISUlhQ0bNnDttdcSERFBSEgIV111FZs2bSpX18mTJ3nggQeIjo7Gz8+PVq1a8fnnn5OXl0dwcPBZxzwsWbKEwMBAcnJyqCzquaksdrvjPKfNC2Drp1CYdea+up1OL98e6BjT9VTBdWDYUvh+CqycAskfwuENcOsciG5pdHUiYoTifJhk0HD7Q2shuB74/fny7VtvvZVHH32Ub7/9ll69egGQmZnJihUrWL58Obm5ufTt25eJEydisVh4//336devHzt37qR+/foVLs1sNvP6668THx/Pvn37ePjhh3nqqad48803AUcY6dWrFyNGjOC1117D29ubb7/9FqvVsZpr7NixzJo1i1dffZUePXpw9OhRduzYUaEa8vPzeeWVV3jnnXcIDw8nKiqKffv2MWzYMP79739jt9uZOnUqffv2Zffu3QQFBWGz2bjhhhvIycnhww8/pGHDhmzbtg0vLy8CAwMZPHgwc+bMYdCgQWWvU/p1UFBQhX9OF0vhxtlOHIDNixyh5sT+M+3B9c4s345obFh5Vc7sBdeMhbgejt6bjJ0wqydcPxk6DveMXioRcQ9hcY7znS7m0rAwbrjhBubPn18WbhYvXkxERATXXHMNZrOZtm3bll3/4osv8umnn7J06VIeeeSRCpf2+0nHcXFxvPTSSzz44INl4WbKlCl06tSp7GuAli0dfyTm5OTw2muvMWPGDIYNGwZAw4YN6dGjR4VqKC4u5s033yz3ffXs2bPcNTNnziQ0NJTvv/+em266ia+//pr169ezfft2mjRpAkCDBg3Krr/33nvp1q0bR48epXbt2hw7dozly5dfVi/XxVC4cZZDG+DrCXBwzZk2n0BocbOjlya2h+ss3zZC/BWOE8aXPAS7/wefPwH7vncsI/cPNbo6keolfafjD7D9K8vPP6kMflHQfCRk2sHH7OjVvv87576GzXqO5duh4BcGPr9bvu1TsRWnd955J/fddx9vvvkmFouFefPmMXjwYMxmM7m5uTz//PMsW7aMo0ePUlJSwqlTp0hJSbmkb+Hrr79m8uTJ7Nixg+zsbEpKSigoKCA/P5+AgACSk5O59dZbz/nY7du3U1hYWBbCLpWvry9t2rQp15aWlsZzzz3Hd999x7Fjx7BareTn55d9n8nJydSrV68s2PxRly5daNmyJe+99x5jxozhww8/JDY2liuvvPKyav0zCjfO4uVzOtiYoMFVjh6a5v0u+q+EaiEwAoYsgh/egK+fh21LHMvGB82Feh0NLk7Ew+VnwpbFjlBzZNOfX+8sNWKgSdHpLS4qqafW7AVegU5Zvv17/fr1w263s2zZMjp37syqVat49dVXAXjyySf56quv+Ne//kWjRo3w9/dn0KBBFBUV/cmznu3AgQPcdNNNPPTQQ0ycOJGaNWuyevVq7rnnHoqKiggICMDf3/+8j7/QfUDZpODfnwZeXFx8zucx/eHnNmzYMI4fP85rr71GbGwsFouFxMTEsu/zz14bHL03b7zxBmPGjGHOnDkMHz78rNdxNoUbZ6ndFm6c5phIG+LEoxc8jdkM3R51bES4eDicPAizr4NeEyDxkerduyXibCVFsPtLx07nu74E2+kPNLM3NLrWsT9VZR/bYjVDUZhjZ3VLJa5G8g10+vJtPz8/Bg4cyLx589izZw9NmzalQ4cOgGNy7913382AAQMAyM3NLZucW1EbN27EZrMxderUsiDy0UcflbumTZs2JCUl8cILL5z1+MaNG+Pv709SUhL33nvvWfdHRkYCcPToUcLCHO93cnLyRdW2Zs0a3nzzTfr27QvAoUOHyMjIKFfX4cOH2bVr13l7b/7617/y1FNP8frrr7Nt27ayobPKpHDjLCYTdL7H6CrcR72O8OAqWPqYowfnq3GOLvIBbzt6eETk0tjtjp6Z5AWwdbHj5OpStds6epVbDYIakVVTT0EB7N8Plhrg5347/N55553cdNNN/Prrr/z1r38ta2/cuDGffPIJ/fr1w2QyMW7cuLNWVl2sRo0aUVxczL///W/69evHmjVrePvtt8tdM3bsWFq3bs3DDz/Mgw8+iK+vL99++y233norERERPP300zz11FP4+vrSvXt30tPT+fXXX7nnnnto1KgRMTExPP/880ycOJFdu3YxderUi6qtcePGfPDBB3Tq1Ins7Gz+/ve/l+utueqqq7jyyiu55ZZbmDZtGo0aNWLHjh2YTCauv/56wDF/aeDAgfz973/nuuuuo169yu8A0J/JYhy/EMcGfzdNd+w1secrx9EN+1cZXZmI+8k67Djf7Y0ujkn7G2Y5gk2NWtDtMXhoHTywEro+VHXBxgP07NmTmjVrsnPnTu64446y9mnTphEWFka3bt3o168fffr0KevVqai2bdsybdo0XnnlFVq1asW8efOYPHlyuWuaNGnC//73PzZv3kyXLl1ITEzks88+w9vb0Ucxbtw4/va3vzF+/HiaN2/O7bffzrFjxwDw8fFhwYIF7NixgzZt2vDKK6/w0ksvXVRt7777LidOnKBDhw7cddddPPbYY0RFRZW75j//+Q+dO3dmyJAhtGjRgqeeeqpsFVep0iG2ESNGXNLPqKJM9t8PwlUD2dnZhISEkJWVRXBwsNHlSKm0X+Hj4Y7VVJjgqqfgqqe1S6jIhRTmwo7PIXm+o+ezdLddb39ofpNjU9AG1xj676igoID9+/cTHx+Pnxv23IhzfPDBBzzxxBMcOXIEX9/zD09e6PelIp/fGpYS1xDdEu7/Fr54Cn7+EL5/BQ6sdpww7k5HUIhUNpsNDqxyzKPZ9hkU/25jzNjujmGnFjeDn/54E+Pl5+dz9OhRXn75ZR544IELBhtn0rCUuA7fQLj5DRj4jmO1w8E18FZ3x0RIkeouYzck/QOmt4b3/wKb5zuCTVg8XP0MPL4Zhi+HDncp2LiYefPmUaNGjXPeSveq8VRTpkyhWbNm1KpVi7Fjx1bZ62pYSlzT8b2O1VRHNzu+TnzEsaLKW2e/SDWSnwlb/+PopfntpzPtlhBoNQDa3gExXVx6M0wNSzk22UtLSzvnfT4+PsTGxlZxRa5Lw1Li2cIbwj1fwVfj4ce3HaeMH1wLg2Y7Th8X8VQlRY7J9ZsXwM4VZ5Zvm7ygUW/HPJqmfctvTicuLSgoqFKPGpCzKdyI6/K2OA4Tjb/KsbPxkU2OE8b7TYdWtxhdnYjz2O2Ogx03L3Qs384/fua+Wq0d82ha3wo1os7/HC6umg0SyCVy1u+Jwo24vmZ9HSeML74HDv0Ai0c4jm64/mXwrdh26iIuJfsI/LLIEWrSf3fIYY1oR5hpOwRqtTKuPifw8nKs1CoqKrqo3Wyleivd+bj09+ZSKdyIewipB3cvg+8mO/by2PQeHFrv2CcnqpnR1YlcvKI82LHMsXx733ecWb7tB81udASaBteAl2f879nb25uAgADS09Px8fEp24FX5I9sNhvp6ekEBASU7d9zqTShWNzP3m/hk/sh75hjP4++U6D9XS49qVKqOZvNsfpv8wLH8u2i3DP31e/mmEfTsr9jY0sPVFRUxP79+y95B1+pPsxmM/Hx8edcMl6Rz2+FG3FPucfg0wdg7zeOr1sNgpte1RJYcS0Ze+CXhbB5EWT97rTosDhHD02b26BmA8PKq0o2m+2SDpWU6sXX1/e8vXsKNxegcONBbDZY+xokvQh2q2O/j0Gzoe6lbYEu4hSnTsDWTxzzaA6vP9NuCXb0zrS9A+p3VU+jSAVV5PPbJQY/33jjDeLi4vDz8yMhIYH169df8PqPP/6YZs2a4efnR+vWrVm+fHkVVSouxWyGHk/AiBUQEgMn9sO718G6Nx2rT0SqirUYdn4BHw2FfzWBZaMdwcZkdpy+fcu78OQu+Mu/ITZRwUakkhkebhYtWsTo0aOZMGECmzZtom3btvTp06fswK8/Wrt2LUOGDOGee+7h559/pn///vTv35+tW7dWceXiMmK6OE4Yb3aTY0+QL8fCgsGODdBEKovdDkeS4YsxMLWZ43du22dgLYKolnDdSzB6O/x1MbQeBD5aKSRSVQwflkpISKBz587MmDEDcIzLxsTE8OijjzJmzJizrr/99tvJy8vj888/L2vr2rUr7dq1O+uI+HPRsJQHs9thwzvw5TOOD5igOtBrnOMoBxFnytznWMJ9bNuZtsBIaH2bY3Jw7TbG1Sbiodxmh+KioiI2btxY7rwJs9lM7969Wbdu3Tkfs27dOkaPHl2urU+fPixZsuSc1xcWFlJYWFj2dVZWFuD4IYkHanY7hLaEJQ9Dxj5Y9KDRFYknM/tCk+scPTPxV4GXj6Nd/38RcbrSz+2L6ZMxNNxkZGRgtVqJjo4u1x4dHc2OHTvO+ZjU1NRzXp+amnrO6ydPnswLL7xwVntMTMwlVi0i8nsLTt9EpCrk5OQQEnLhbRM8Y5eoCxg7dmy5nh6bzUZmZibh4eGYnDypLzs7m5iYGA4dOqQhLxeg98O16P1wLXo/XI/ekwuz2+3k5ORQp06dP73W0HATERGBl5fXWaelpqWlUatWrXM+platWhW63mKxYLFYyrWFhoZeetEXITg4WL+YLkTvh2vR++Fa9H64Hr0n5/dnPTalDF0t5evrS8eOHUlKSiprs9lsJCUlkZiYeM7HJCYmlrse4Kuvvjrv9SIiIlK9GD4sNXr0aIYNG0anTp3o0qUL06dPJy8vj+HDhwMwdOhQ6taty+TJkwF4/PHHueqqq5g6dSo33ngjCxcu5KeffmLmzJlGfhsiIiLiIgwPN7fffjvp6emMHz+e1NRU2rVrx4oVK8omDaekpJTbirlbt27Mnz+f5557jmeeeYbGjRuzZMkSWrUy/uRci8XChAkTzhoGE2Po/XAtej9ci94P16P3xHkM3+dGRERExJkM36FYRERExJkUbkRERMSjKNyIiIiIR1G4EREREY+icOMkb7zxBnFxcfj5+ZGQkMD69euNLqnamjx5Mp07dyYoKIioqCj69+/Pzp07jS5LTnv55ZcxmUyMGjXK6FKqrd9++42//vWvhIeH4+/vT+vWrfnpp5+MLqtaslqtjBs3jvj4ePz9/WnYsCEvvvjiRZ2fJOencOMEixYtYvTo0UyYMIFNmzbRtm1b+vTpw7Fjx4wurVr6/vvvGTlyJD/88ANfffUVxcXFXHfddeTl5RldWrW3YcMG/u///o82bXRqtlFOnDhB9+7d8fHx4YsvvmDbtm1MnTqVsLAwo0urll555RXeeustZsyYwfbt23nllVeYMmUK//73v40uza1pKbgTJCQk0LlzZ2bMmAE4dlmOiYnh0UcfZcyYMQZXJ+np6URFRfH9999z5ZVXGl1OtZWbm0uHDh148803eemll2jXrh3Tp083uqxqZ8yYMaxZs4ZVq1YZXYoAN910E9HR0bz77rtlbbfccgv+/v58+OGHBlbm3tRzc5mKiorYuHEjvXv3Lmszm8307t2bdevWGViZlMrKygKgZs2aBldSvY0cOZIbb7yx3L8VqXpLly6lU6dO3HrrrURFRdG+fXtmzZpldFnVVrdu3UhKSmLXrl0AbN68mdWrV3PDDTcYXJl7M3yHYneXkZGB1Wot21G5VHR0NDt27DCoKills9kYNWoU3bt3d4ldrKurhQsXsmnTJjZs2GB0KdXevn37eOuttxg9ejTPPPMMGzZs4LHHHsPX15dhw4YZXV61M2bMGLKzs2nWrBleXl5YrVYmTpzInXfeaXRpbk3hRjzayJEj2bp1K6tXrza6lGrr0KFDPP7443z11Vf4+fkZXU61Z7PZ6NSpE5MmTQKgffv2bN26lbffflvhxgAfffQR8+bNY/78+bRs2ZLk5GRGjRpFnTp19H5cBoWbyxQREYGXlxdpaWnl2tPS0qhVq5ZBVQnAI488wueff87KlSupV6+e0eVUWxs3buTYsWN06NChrM1qtbJy5UpmzJhBYWEhXl5eBlZYvdSuXZsWLVqUa2vevDn/+c9/DKqoevv73//OmDFjGDx4MACtW7fm4MGDTJ48WeHmMmjOzWXy9fWlY8eOJCUllbXZbDaSkpJITEw0sLLqy26388gjj/Dpp5/yzTffEB8fb3RJ1VqvXr3YsmULycnJZbdOnTpx5513kpycrGBTxbp3737W1gi7du0iNjbWoIqqt/z8/HKHQwN4eXlhs9kMqsgzqOfGCUaPHs2wYcPo1KkTXbp0Yfr06eTl5TF8+HCjS6uWRo4cyfz58/nss88ICgoiNTUVgJCQEPz9/Q2urvoJCgo6a75TYGAg4eHhmgdlgCeeeIJu3boxadIkbrvtNtavX8/MmTOZOXOm0aVVS/369WPixInUr1+fli1b8vPPPzNt2jRGjBhhdGluTUvBnWTGjBn885//JDU1lXbt2vH666+TkJBgdFnVkslkOmf7nDlzuPvuu6u2GDmnq6++WkvBDfT5558zduxYdu/eTXx8PKNHj+a+++4zuqxqKScnh3HjxvHpp59y7Ngx6tSpw5AhQxg/fjy+vr5Gl+e2FG5ERETEo2jOjYiIiHgUhRsRERHxKAo3IiIi4lEUbkRERMSjKNyIiIiIR1G4EREREY+icCMiIiIeReFGRKo9k8nEkiVLjC5DRJxE4UZEDHX33XdjMpnOul1//fVGlyYibkpnS4mI4a6//nrmzJlTrs1isRhUjYi4O/XciIjhLBYLtWrVKncLCwsDHENGb731FjfccAP+/v40aNCAxYsXl3v8li1b6NmzJ/7+/oSHh3P//feTm5tb7prZs2fTsmVLLBYLtWvX5pFHHil3f0ZGBgMGDCAgIIDGjRuzdOnSyv2mRaTSKNyIiMsbN24ct9xyC5s3b+bOO+9k8ODBbN++HYC8vDz69OlDWFgYGzZs4OOPP+brr78uF17eeustRo4cyf3338+WLVtYunQpjRo1KvcaL7zwArfddhu//PILffv25c477yQzM7NKv08RcRK7iIiBhg0bZvfy8rIHBgaWu02cONFut9vtgP3BBx8s95iEhAT7Qw89ZLfb7faZM2faw8LC7Lm5uWX3L1u2zG42m+2pqal2u91ur1Onjv3ZZ589bw2A/bnnniv7Ojc31w7Yv/jiC6d9nyJSdTTnRkQMd8011/DWW2+Va6tZs2bZfycmJpa7LzExkeTkZAC2b99O27ZtCQwMLLu/e/fu2Gw2du7ciclk4siRI/Tq1euCNbRp06bsvwMDAwkODubYsWOX+i2JiIEUbkTEcIGBgWcNEzmLv7//RV3n4+NT7muTyYTNZquMkkSkkmnOjYi4vB9++OGsr5s3bw5A8+bN2bx5M3l5eWX3r1mzBrPZTNOmTQkKCiIuLo6kpKQqrVlEjKOeGxExXGFhIampqeXavL29iYiIAODjjz+mU6dO9OjRg3nz5rF+/XreffddAO68804mTJjAsGHDeP7550lPT+fRRx/lrrvuIjo6GoDnn3+eBx98kKioKG644QZycnJYs2YNjz76aNV+oyJSJRRuRMRwK1asoHbt2uXamjZtyo4dOwDHSqaFCxfy8MMPU7t2bRYsWECLFi0ACAgI4Msvv+Txxx+nc+fOBAQEcMsttzBt2rSy5xo2bBgFBQW8+uqrPPnkk0RERDBo0KCq+wZFpEqZ7Ha73egiRETOx2Qy8emnn9K/f3+jSxERN6E5NyIiIuJRFG5ERETEo2jOjYi4NI2ci0hFqedGREREPIrCjYiIiHgUhRsRERHxKAo3IiIi4lEUbkRERMSjKNyIiIiIR1G4EREREY+icCMiIiIeReFGREREPMr/A+qD0K3z0CZ/AAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Distributed Training**\n",
        "* Distributed training refers to training deep learning models across multiple devices (GPUs, TPUs) or machines. This approach helps in reducing training time by distributing the computation load.\n",
        "\n",
        "**Key Points:**\n",
        "\n",
        "* Enhances training efficiency and scalability.\n",
        "* Two main strategies: Data Parallelism and Model Parallelism.\n",
        "* TensorFlow 2.0 provides tf.distribute API to simplify distributed training.\n",
        "\n",
        "# **Using TensorFlow tf.distribute API**\n",
        "* The tf.distribute API in TensorFlow 2.0 provides a high-level interface for distributed training, making it easier to distribute models and training across multiple devices and machines.\n",
        "\n",
        "\n",
        "**Key Points:**\n",
        "\n",
        "* tf.distribute.Strategy is the main class.\n",
        "* Common strategies include MirroredStrategy, TPUStrategy, MultiWorkerMirroredStrategy, and CentralStorageStrategy.\n",
        "* Simplifies the implementation of both data and model parallelism.\n",
        "\n",
        "\n",
        "# **Data Parallelism**\n",
        "* Data parallelism involves splitting the training data across multiple devices and each device trains a copy of the model on a subset of the data. Gradients are then averaged and updated synchronously.\n",
        "\n",
        "**Key Points:**\n",
        "\n",
        "* Each device processes a different portion of the data.\n",
        "* Common approach for multi-GPU training.\n",
        "* Synchronization of gradients is crucial to ensure model consistency.\n",
        "\n",
        "\n",
        "**Example: Using tf.distribute.MirroredStrategy for data parallelism**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XskxblYc_Dlt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Create a MirroredStrategy\n",
        "strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "# Define the model inside the strategy scope\n",
        "with strategy.scope():\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Dense(128, activation='relu', input_shape=(784,)),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Load dataset\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Create a distributed dataset\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(64)\n",
        "train_dist_dataset = strategy.experimental_distribute_dataset(train_dataset)\n",
        "\n",
        "# Define the training step function\n",
        "@tf.function\n",
        "def train_step(inputs):\n",
        "    def step_fn(inputs):\n",
        "        images, labels = inputs\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = model(images, training=True)\n",
        "            loss = tf.keras.losses.sparse_categorical_crossentropy(labels, predictions)\n",
        "        gradients = tape.gradient(loss, model.trainable_variables)\n",
        "        model.optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "        return loss\n",
        "    per_replica_losses = strategy.run(step_fn, args=(inputs,))\n",
        "    return strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses, axis=None)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(10):\n",
        "    total_loss = 0.0\n",
        "    num_batches = 0\n",
        "    for batch in train_dist_dataset:\n",
        "        total_loss += train_step(batch)\n",
        "        num_batches += 1\n",
        "    train_loss = total_loss / num_batches\n",
        "    print(f'Epoch {epoch + 1}, Loss: {train_loss}')\n"
      ],
      "metadata": {
        "id": "mYKEXEyy4CwI"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Parallelism**\n",
        "* Model parallelism involves splitting the model itself across multiple devices, where different layers or operations run on different devices. This is beneficial for very large models that cannot fit into the memory of a single device.\n",
        "\n",
        "**Key Points:**\n",
        "\n",
        "* Useful for very large models.\n",
        "* Requires careful design to manage dependencies between model parts.\n",
        "* Can be more complex to implement compared to data parallelism.\n",
        "\n",
        "**Example: Manual model parallelism**"
      ],
      "metadata": {
        "id": "7yaKofnHAmaw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Manually assign different parts of the model to different devices\n",
        "with tf.device('/GPU:0'):\n",
        "    input_layer = tf.keras.layers.Input(shape=(28,28)) # Change input shape to (28,28)\n",
        "    flatten = tf.keras.layers.Flatten()(input_layer) # Add a Flatten layer\n",
        "    dense_1 = tf.keras.layers.Dense(128, activation='relu')(flatten)\n",
        "\n",
        "with tf.device('/GPU:1'):\n",
        "    dense_2 = tf.keras.layers.Dense(64, activation='relu')(dense_1)\n",
        "    output_layer = tf.keras.layers.Dense(10, activation='softmax')(dense_2)\n",
        "\n",
        "model = tf.keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Load dataset\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rO8f-38AEIX",
        "outputId": "d0c262c4-bf62-4c26-f22e-4e70ff9cecfa"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "938/938 [==============================] - 5s 3ms/step - loss: 0.2793 - accuracy: 0.9179\n",
            "Epoch 2/10\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 0.1147 - accuracy: 0.9658\n",
            "Epoch 3/10\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 0.0801 - accuracy: 0.9751\n",
            "Epoch 4/10\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 0.0597 - accuracy: 0.9814\n",
            "Epoch 5/10\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 0.0470 - accuracy: 0.9850\n",
            "Epoch 6/10\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 0.0388 - accuracy: 0.9875\n",
            "Epoch 7/10\n",
            "938/938 [==============================] - 3s 4ms/step - loss: 0.0320 - accuracy: 0.9900\n",
            "Epoch 8/10\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 0.0258 - accuracy: 0.9918\n",
            "Epoch 9/10\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 0.0221 - accuracy: 0.9926\n",
            "Epoch 10/10\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 0.0174 - accuracy: 0.9943\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d160073f430>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Optimization and Deployment in TensorFlow 2.0**\n",
        "\n",
        "**Model Optimization:**\n",
        "* Model optimization refers to techniques used to enhance the performance of a machine learning model, making it more efficient in terms of speed, memory usage, and power consumption.\n",
        "\n",
        "**Deployment:**\n",
        "* Model deployment is the process of making a trained machine learning model available for use in a production environment."
      ],
      "metadata": {
        "id": "pe4W5jxNV-lC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Optimization and Deployment Techniques**\n",
        "\n",
        "**Key Techniques:**\n",
        "\n",
        "* **Quantization:** Reducing the precision of the model's weights and activations.\n",
        "* **Pruning:** Removing unnecessary weights from the model.\n",
        "* **Mixed Precision Training:** Using both 16-bit and 32-bit floating-point types during training.\n",
        "* **Weight Clustering:** Grouping weights into clusters to reduce the number of unique weight values."
      ],
      "metadata": {
        "id": "nJChi_iHWNr8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example: Combining techniques**"
      ],
      "metadata": {
        "id": "s99f0quoW5aF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_model_optimization\n",
        "import tensorflow as tf\n",
        "from tensorflow_model_optimization.sparsity import keras as sparsity\n",
        "\n",
        "# Define a model\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(128, activation='relu', input_shape=(784,)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Quantization-aware training\n",
        "quant_aware_model = tf.keras.models.clone_model(model)\n",
        "quant_aware_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Pruning parameters\n",
        "pruning_params = {\n",
        "    'pruning_schedule': sparsity.PolynomialDecay(initial_sparsity=0.50, final_sparsity=0.90, begin_step=0, end_step=1000)\n",
        "}\n",
        "pruned_model = sparsity.prune_low_magnitude(model, **pruning_params)\n",
        "pruned_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Load dataset  # Load the MNIST dataset here\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train = x_train.reshape(-1, 784).astype('float32') / 255.0  # Reshape and normalize\n",
        "x_test = x_test.reshape(-1, 784).astype('float32') / 255.0    # Reshape and normalize\n",
        "\n",
        "# Train and save pruned model\n",
        "callbacks = [sparsity.UpdatePruningStep()]\n",
        "pruned_model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test), callbacks=callbacks)\n",
        "model_stripped = sparsity.strip_pruning(pruned_model)\n",
        "model_stripped.save('optimized_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7JQZpHYA1Xb",
        "outputId": "838b043a-4b93-46b4-a805-a680bec62376"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow_model_optimization in /usr/local/lib/python3.10/dist-packages (0.8.0)\n",
            "Requirement already satisfied: absl-py~=1.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow_model_optimization) (1.4.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow_model_optimization) (0.1.8)\n",
            "Requirement already satisfied: numpy~=1.23 in /usr/local/lib/python3.10/dist-packages (from tensorflow_model_optimization) (1.25.2)\n",
            "Requirement already satisfied: six~=1.14 in /usr/local/lib/python3.10/dist-packages (from tensorflow_model_optimization) (1.16.0)\n",
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 17s 7ms/step - loss: 0.3940 - accuracy: 0.8904 - val_loss: 0.2296 - val_accuracy: 0.9330\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.2097 - accuracy: 0.9385 - val_loss: 0.1796 - val_accuracy: 0.9437\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 13s 7ms/step - loss: 0.1703 - accuracy: 0.9498 - val_loss: 0.1545 - val_accuracy: 0.9517\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 13s 7ms/step - loss: 0.1453 - accuracy: 0.9572 - val_loss: 0.1412 - val_accuracy: 0.9573\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 18s 10ms/step - loss: 0.1272 - accuracy: 0.9618 - val_loss: 0.1284 - val_accuracy: 0.9616\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.1133 - accuracy: 0.9653 - val_loss: 0.1220 - val_accuracy: 0.9620\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 13s 7ms/step - loss: 0.1022 - accuracy: 0.9690 - val_loss: 0.1145 - val_accuracy: 0.9640\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0937 - accuracy: 0.9718 - val_loss: 0.1108 - val_accuracy: 0.9677\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0864 - accuracy: 0.9739 - val_loss: 0.1079 - val_accuracy: 0.9665\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0800 - accuracy: 0.9757 - val_loss: 0.1055 - val_accuracy: 0.9686\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py:3098: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Pruning**\n",
        "\n",
        "* Pruning involves removing less important weights from a neural network, reducing the model's complexity without significantly impacting accuracy.\n",
        "\n",
        "**Example: Pruning with TensorFlow Model Optimization Toolkit**"
      ],
      "metadata": {
        "id": "lxrtZQL4inMb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_model_optimization\n",
        "import tensorflow as tf\n",
        "from tensorflow_model_optimization.sparsity import keras as sparsity\n",
        "\n",
        "# Define a model\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(128, activation='relu', input_shape=(784,)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Define pruning parameters\n",
        "pruning_params = {\n",
        "    'pruning_schedule': sparsity.PolynomialDecay(initial_sparsity=0.30, final_sparsity=0.70, begin_step=2000, end_step=6000)\n",
        "}\n",
        "\n",
        "# Apply pruning\n",
        "pruned_model = sparsity.prune_low_magnitude(model, **pruning_params)\n",
        "pruned_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Load dataset  # Load the MNIST dataset here\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train = x_train.reshape(-1, 784).astype('float32') / 255.0  # Reshape and normalize\n",
        "x_test = x_test.reshape(-1, 784).astype('float32') / 255.0    # Reshape and normalize\n",
        "\n",
        "# Train and save the pruned model\n",
        "callbacks = [sparsity.UpdatePruningStep()]  # Add the callback here\n",
        "pruned_model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test), callbacks=callbacks)\n",
        "model_stripped = sparsity.strip_pruning(pruned_model)\n",
        "model_stripped.save('pruned_model.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQ_Hv2pYX8sF",
        "outputId": "2fb02972-4db5-4b20-ccaf-eb2b901f51a1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow_model_optimization in /usr/local/lib/python3.10/dist-packages (0.8.0)\n",
            "Requirement already satisfied: absl-py~=1.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow_model_optimization) (1.4.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow_model_optimization) (0.1.8)\n",
            "Requirement already satisfied: numpy~=1.23 in /usr/local/lib/python3.10/dist-packages (from tensorflow_model_optimization) (1.25.2)\n",
            "Requirement already satisfied: six~=1.14 in /usr/local/lib/python3.10/dist-packages (from tensorflow_model_optimization) (1.16.0)\n",
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 12s 5ms/step - loss: 0.2325 - accuracy: 0.9316 - val_loss: 0.1141 - val_accuracy: 0.9640\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0933 - accuracy: 0.9720 - val_loss: 0.0821 - val_accuracy: 0.9752\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0640 - accuracy: 0.9806 - val_loss: 0.0666 - val_accuracy: 0.9793\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0453 - accuracy: 0.9863 - val_loss: 0.0645 - val_accuracy: 0.9805\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0366 - accuracy: 0.9883 - val_loss: 0.0682 - val_accuracy: 0.9795\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0301 - accuracy: 0.9911 - val_loss: 0.0662 - val_accuracy: 0.9801\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0253 - accuracy: 0.9922 - val_loss: 0.0685 - val_accuracy: 0.9801\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0213 - accuracy: 0.9938 - val_loss: 0.0720 - val_accuracy: 0.9796\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0180 - accuracy: 0.9945 - val_loss: 0.0714 - val_accuracy: 0.9798\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0150 - accuracy: 0.9957 - val_loss: 0.0767 - val_accuracy: 0.9790\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py:3098: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Mixed Precision Training**\n",
        "* Mixed precision training uses both 16-bit (half precision) and 32-bit (single precision) floating-point types during model training. This can significantly speed up training and reduce memory usage on compatible hardware (like NVIDIA GPUs with Tensor Cores).\n",
        "\n",
        "**Example: Mixed precision training with TensorFlow**"
      ],
      "metadata": {
        "id": "-ZFNPIdU_HAm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Enable mixed precision\n",
        "policy = tf.keras.mixed_precision.Policy('mixed_float16')\n",
        "tf.keras.mixed_precision.set_global_policy(policy)\n",
        "\n",
        "# Define a model\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(128, activation='relu', input_shape=(784,)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax', dtype='float32')  # Use float32 for final layer\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyXxoC6d_Dtv",
        "outputId": "e190a3b4-7dfb-4255-c1ce-3753b0053870"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Mixed precision compatibility check (mixed_float16): WARNING\n",
            "The dtype policy mixed_float16 may run slowly because this machine does not have a GPU. Only Nvidia GPUs with compute capability of at least 7.0 run quickly with mixed_float16.\n",
            "If you will use compatible GPU(s) not attached to this host, e.g. by running a multi-worker model, you can ignore this warning. This message will only be logged once\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function create_autocast_variable at 0x7d5e777f9e10> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: <gast.gast.Expr object at 0x7d5e67a3ca90>\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function create_autocast_variable at 0x7d5e777f9e10> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: <gast.gast.Expr object at 0x7d5e67a3ca90>\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "1875/1875 [==============================] - 112s 55ms/step - loss: 0.2451 - accuracy: 0.9284 - val_loss: 0.1237 - val_accuracy: 0.9613\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 98s 52ms/step - loss: 0.1043 - accuracy: 0.9687 - val_loss: 0.0958 - val_accuracy: 0.9699\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 93s 49ms/step - loss: 0.0740 - accuracy: 0.9770 - val_loss: 0.0833 - val_accuracy: 0.9732\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 94s 50ms/step - loss: 0.0537 - accuracy: 0.9836 - val_loss: 0.0961 - val_accuracy: 0.9717\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 95s 51ms/step - loss: 0.0438 - accuracy: 0.9857 - val_loss: 0.0762 - val_accuracy: 0.9768\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 97s 52ms/step - loss: 0.0365 - accuracy: 0.9874 - val_loss: 0.0882 - val_accuracy: 0.9757\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 96s 51ms/step - loss: 0.0296 - accuracy: 0.9903 - val_loss: 0.1003 - val_accuracy: 0.9735\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 92s 49ms/step - loss: 0.0253 - accuracy: 0.9918 - val_loss: 0.0802 - val_accuracy: 0.9783\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 96s 51ms/step - loss: 0.0229 - accuracy: 0.9924 - val_loss: 0.0862 - val_accuracy: 0.9770\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 112s 60ms/step - loss: 0.0201 - accuracy: 0.9934 - val_loss: 0.0873 - val_accuracy: 0.9786\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf_keras.src.callbacks.History at 0x7d5e67e7a740>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TensorFlow Serving for Model Deployment**\n",
        "* TensorFlow Serving is a flexible, high-performance serving system for machine learning models designed for production environments.\n",
        "\n"
      ],
      "metadata": {
        "id": "Jx0D1lru_bJl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example: Serving a TensorFlow model**"
      ],
      "metadata": {
        "id": "xxOCF7SOA7mI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1-Save the model in the SavedModel format:**"
      ],
      "metadata": {
        "id": "EIj0LLeyA_df"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('saved_model/1/')"
      ],
      "metadata": {
        "id": "eAMlhT2r_fCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2-Start TensorFlow Serving:**"
      ],
      "metadata": {
        "id": "zDFLenmHBD7L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "docker pull tensorflow/serving\n",
        "docker run -p 8501:8501 --name=tf_serving --mount type=bind,source=$(pwd)/saved_model,target=/models/my_model -e MODEL_NAME=my_model -t tensorflow/serving"
      ],
      "metadata": {
        "id": "DuvQsDjiBHHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3-Make predictions using the REST API:**"
      ],
      "metadata": {
        "id": "U0uNidU5BJLI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "import numpy as np\n",
        "\n",
        "data = json.dumps({\"signature_name\": \"serving_default\", \"instances\": x_test[:5].tolist()})\n",
        "headers = {\"content-type\": \"application/json\"}\n",
        "json_response = requests.post('http://localhost:8501/v1/models/my_model:predict', data=data, headers=headers)\n",
        "predictions = np.array(json.loads(json_response.text)[\"predictions\"])\n",
        "print(predictions)\n"
      ],
      "metadata": {
        "id": "rwNSzJR2BL_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. What is a Custom Layer?**\n",
        "\n",
        "* A custom layer in TensorFlow is a user-defined layer that extends the base functionality provided by TensorFlow's existing layers. Custom layers allow you to implement and encapsulate specific operations or logic that are not available in the standard library.\n",
        "\n",
        "# **2. Writing Custom Layers**\n",
        "* To write a custom layer in TensorFlow, you need to subclass the tf.keras.layers.Layer class and implement the build and call methods.\n",
        "\n",
        "**Example: Creating a Custom Layer**\n",
        "\n",
        "* This example demonstrates creating a custom dense layer with a custom activation function."
      ],
      "metadata": {
        "id": "IJQuKwV3eNve"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class CustomDenseLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, units=32, activation=None):\n",
        "        super(CustomDenseLayer, self).__init__()\n",
        "        self.units = units\n",
        "        self.activation = tf.keras.activations.get(activation)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.w = self.add_weight(shape=(input_shape[-1], self.units),\n",
        "                                 initializer='random_normal',\n",
        "                                 trainable=True)\n",
        "        self.b = self.add_weight(shape=(self.units,),\n",
        "                                 initializer='zeros',\n",
        "                                 trainable=True)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        z = tf.matmul(inputs, self.w) + self.b\n",
        "        if self.activation is not None:\n",
        "            return self.activation(z)\n",
        "        return z\n",
        "\n",
        "# Usage example\n",
        "model = tf.keras.Sequential([\n",
        "    CustomDenseLayer(64, activation='relu'),\n",
        "    CustomDenseLayer(10)\n",
        "])\n",
        "\n",
        "# Compile and train the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "ZL4yIdMnebNw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Writing Custom Models**\n",
        "* To create a custom model, you need to subclass the tf.keras.Model class and define the __init__ and call methods.\n",
        "\n",
        "**Example: Creating a Custom Model**\n",
        "\n",
        "* This example demonstrates creating a custom model that uses the custom dense layer defined above.\n",
        "\n"
      ],
      "metadata": {
        "id": "zLNBQB2tecL7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomModel(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(CustomModel, self).__init__()\n",
        "        self.layer1 = CustomDenseLayer(64, activation='relu')\n",
        "        self.layer2 = CustomDenseLayer(10)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.layer1(inputs)\n",
        "        return self.layer2(x)\n",
        "\n",
        "# Usage example\n",
        "model = CustomModel()\n",
        "\n",
        "# Compile and train the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "LNpwYtD0ekl5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Custom Training Loops with tf.GradientTape**\n",
        "* TensorFlow 2.0 provides the tf.GradientTape API for more control over the training loop, allowing for custom training workflows.\n",
        "\n",
        "**Example: Custom Training Loop**\n",
        "\n",
        "* This example demonstrates a custom training loop using tf.GradientTape."
      ],
      "metadata": {
        "id": "kSS-YmDtelsm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class CustomDenseLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, units=32, activation=None):\n",
        "        super(CustomDenseLayer, self).__init__()\n",
        "        self.units = units\n",
        "        self.activation = tf.keras.activations.get(activation)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.w = self.add_weight(shape=(input_shape[-1], self.units),\n",
        "                                 initializer='random_normal',\n",
        "                                 trainable=True)\n",
        "        self.b = self.add_weight(shape=(self.units,),\n",
        "                                 initializer='zeros',\n",
        "                                 trainable=True)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        z = tf.matmul(inputs, self.w) + self.b\n",
        "        if self.activation is not None:\n",
        "            return self.activation(z)\n",
        "        return z\n",
        "\n",
        "class CustomModel(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(CustomModel, self).__init__()\n",
        "        self.layer1 = CustomDenseLayer(64, activation='relu')\n",
        "        self.layer2 = CustomDenseLayer(10)\n",
        "        # Add a flattening layer to reshape the input\n",
        "        self.flatten = tf.keras.layers.Flatten()\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.flatten(inputs) # Flatten the input before passing to dense layers\n",
        "        x = self.layer1(x)\n",
        "        return self.layer2(x)\n",
        "\n",
        "# Usage example\n",
        "model = CustomModel()\n",
        "\n",
        "# Compile and train the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "# Define metrics to track loss and accuracy\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
        "\n",
        "@tf.function\n",
        "def train_step(inputs, labels):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(inputs, training=True)\n",
        "        loss = loss_object(labels, predictions)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "    train_loss(loss)\n",
        "    train_accuracy(labels, predictions)\n",
        "\n",
        "# Load and preprocess data\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(60000).batch(32)\n",
        "\n",
        "# Training loop\n",
        "EPOCHS = 5\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    for images, labels in train_dataset:\n",
        "        train_step(images, labels)\n",
        "\n",
        "    print(f'Epoch {epoch + 1}, Loss: {train_loss.result()}, Accuracy: {train_accuracy.result() * 100}')\n",
        "    train_loss.reset_states()\n",
        "    train_accuracy.reset_states()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9M8nl_DeuTr",
        "outputId": "9c7d13cb-2aa3-4581-fcce-acc5ce5a2649"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: nan, Accuracy: 10.336666107177734\n",
            "Epoch 2, Loss: nan, Accuracy: 9.87166690826416\n",
            "Epoch 3, Loss: nan, Accuracy: 9.87166690826416\n",
            "Epoch 4, Loss: nan, Accuracy: 9.87166690826416\n",
            "Epoch 5, Loss: nan, Accuracy: 9.87166690826416\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Introduction to TFX (TensorFlow Extended)**\n",
        "\n",
        "* TensorFlow Extended (TFX) is an end-to-end platform for deploying production machine learning (ML) pipelines. It provides a comprehensive set of components and libraries to integrate all the steps in the ML lifecycle, from data ingestion, data validation, and model training to model evaluation, model analysis, and model serving.\n",
        "\n",
        "**Components of TFX:**\n",
        "\n",
        "* **TensorFlow Data Validation (TFDV):** For data validation.\n",
        "* **TensorFlow Transform (TFT):** For data preprocessing.\n",
        "* **TensorFlow Model Analysis (TFMA):** For model evaluation.\n",
        "* **TensorFlow Serving:** For model deployment.\n",
        "\n",
        "# **2. Data Validation**\n",
        "* **TensorFlow Data Validation (TFDV):**\n",
        "* TFDV is a library for exploring and validating machine learning data. It allows you to understand the characteristics of your data and ensure it meets the requirements of your ML pipeline.\n",
        "\n",
        "**Example: Using TFDV for Data Validation**"
      ],
      "metadata": {
        "id": "XhM__zLQgLB7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_data_validation\n",
        "import tensorflow_data_validation as tfdv\n",
        "\n",
        "!pip install tensorflow_data_validation\n",
        "import tensorflow_data_validation as tfdv\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Load the iris dataset as a pandas DataFrame\n",
        "iris = load_iris()\n",
        "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
        "df['target'] = iris.target\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "df.to_csv('iris_data.csv', index=False)\n",
        "\n",
        "# Generate statistics from the CSV file\n",
        "stats = tfdv.generate_statistics_from_csv(data_location='iris_data.csv')\n",
        "\n",
        "# Infer schema from statistics\n",
        "schema = tfdv.infer_schema(stats)\n",
        "\n",
        "# Display the schema\n",
        "tfdv.display_schema(schema)\n",
        "\n",
        "# Generate statistics from data\n",
        "stats = tfdv.generate_statistics_from_csv(data_location='iris_data.csv')\n",
        "\n",
        "# Infer schema from statistics\n",
        "schema = tfdv.infer_schema(stats)\n",
        "\n",
        "# Display the schema\n",
        "tfdv.display_schema(schema)\n",
        "\n",
        "# Validate statistics against the schema\n",
        "anomalies = tfdv.validate_statistics(stats, schema)\n",
        "\n",
        "# Display anomalies\n",
        "tfdv.display_anomalies(anomalies)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UtZ5Ekyje9J-",
        "outputId": "bc1f4881-ef9e-4c1c-b25e-67a531291537"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow_data_validation in /usr/local/lib/python3.10/dist-packages (1.15.1)\n",
            "Requirement already satisfied: absl-py<2.0.0,>=0.9 in /usr/local/lib/python3.10/dist-packages (from tensorflow_data_validation) (1.4.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_data_validation) (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_data_validation) (1.25.2)\n",
            "Requirement already satisfied: pandas<2,>=1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_data_validation) (1.5.3)\n",
            "Requirement already satisfied: pyarrow<11,>=10 in /usr/local/lib/python3.10/dist-packages (from tensorflow_data_validation) (10.0.1)\n",
            "Requirement already satisfied: pyfarmhash<0.4,>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow_data_validation) (0.3.2)\n",
            "Requirement already satisfied: six<2,>=1.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow_data_validation) (1.16.0)\n",
            "Requirement already satisfied: tensorflow<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow_data_validation) (2.15.1)\n",
            "Requirement already satisfied: tensorflow-metadata<1.16,>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_data_validation) (1.15.0)\n",
            "Requirement already satisfied: tfx-bsl<1.16,>=1.15.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow_data_validation) (1.15.1)\n",
            "Requirement already satisfied: apache-beam[gcp]<3,>=2.47 in /usr/local/lib/python3.10/dist-packages (from tensorflow_data_validation) (2.56.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow_data_validation) (3.20.3)\n",
            "Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (1.7)\n",
            "Requirement already satisfied: orjson<4,>=3.9.7 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (3.10.5)\n",
            "Requirement already satisfied: dill<0.3.2,>=0.3.1.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.3.1.1)\n",
            "Requirement already satisfied: cloudpickle~=2.2.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.2.1)\n",
            "Requirement already satisfied: fastavro<2,>=0.23.6 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (1.9.4)\n",
            "Requirement already satisfied: fasteners<1.0,>=0.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.19)\n",
            "Requirement already satisfied: grpcio!=1.48.0,!=1.59.*,!=1.60.*,!=1.61.*,!=1.62.0,!=1.62.1,<2,>=1.33.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (1.64.1)\n",
            "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.7.3)\n",
            "Requirement already satisfied: httplib2<0.23.0,>=0.8 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.22.0)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (4.19.2)\n",
            "Requirement already satisfied: jsonpickle<4.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (3.2.2)\n",
            "Requirement already satisfied: objsize<0.8.0,>=0.6.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.7.0)\n",
            "Requirement already satisfied: packaging>=22.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (24.1)\n",
            "Requirement already satisfied: pymongo<5.0.0,>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (4.7.3)\n",
            "Requirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (1.24.0)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2018.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2023.4)\n",
            "Requirement already satisfied: redis<6,>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (5.0.7)\n",
            "Requirement already satisfied: regex>=2020.6.8 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2024.5.15)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (4.12.2)\n",
            "Requirement already satisfied: zstandard<1,>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.22.0)\n",
            "Requirement already satisfied: pyarrow-hotfix<1 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.6)\n",
            "Requirement already satisfied: js2py<1,>=0.74 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.74)\n",
            "Requirement already satisfied: cachetools<6,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (5.3.3)\n",
            "Requirement already satisfied: google-api-core<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.19.1)\n",
            "Requirement already satisfied: google-apitools<0.5.32,>=0.5.31 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.5.31)\n",
            "Requirement already satisfied: google-auth<3,>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.27.0)\n",
            "Requirement already satisfied: google-auth-httplib2<0.3.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.1.1)\n",
            "Requirement already satisfied: google-cloud-datastore<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.15.2)\n",
            "Requirement already satisfied: google-cloud-pubsub<3,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.21.5)\n",
            "Requirement already satisfied: google-cloud-pubsublite<2,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (1.10.0)\n",
            "Requirement already satisfied: google-cloud-storage<3,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.17.0)\n",
            "Requirement already satisfied: google-cloud-bigquery<4,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (3.21.0)\n",
            "Requirement already satisfied: google-cloud-bigquery-storage<3,>=2.6.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.25.0)\n",
            "Requirement already satisfied: google-cloud-core<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.3.3)\n",
            "Requirement already satisfied: google-cloud-bigtable<3,>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.24.0)\n",
            "Requirement already satisfied: google-cloud-spanner<4,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (3.47.0)\n",
            "Requirement already satisfied: google-cloud-dlp<4,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (3.18.0)\n",
            "Requirement already satisfied: google-cloud-language<3,>=2.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.13.3)\n",
            "Requirement already satisfied: google-cloud-videointelligence<3,>=2.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.13.3)\n",
            "Requirement already satisfied: google-cloud-vision<4,>=2 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (3.7.2)\n",
            "Requirement already satisfied: google-cloud-recommendations-ai<0.11.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.10.10)\n",
            "Requirement already satisfied: google-cloud-aiplatform<2.0,>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (1.56.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tensorflow_data_validation) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tensorflow_data_validation) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tensorflow_data_validation) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tensorflow_data_validation) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tensorflow_data_validation) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tensorflow_data_validation) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tensorflow_data_validation) (0.3.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tensorflow_data_validation) (3.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tensorflow_data_validation) (67.7.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tensorflow_data_validation) (2.4.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tensorflow_data_validation) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tensorflow_data_validation) (0.37.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tensorflow_data_validation) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tensorflow_data_validation) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tensorflow_data_validation) (2.15.0)\n",
            "Requirement already satisfied: google-api-python-client<2,>=1.7.11 in /usr/local/lib/python3.10/dist-packages (from tfx-bsl<1.16,>=1.15.1->tensorflow_data_validation) (1.12.11)\n",
            "Requirement already satisfied: tensorflow-serving-api<3,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tfx-bsl<1.16,>=1.15.1->tensorflow_data_validation) (2.15.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.16,>=2.15->tensorflow_data_validation) (0.43.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3,>=2.0.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (1.63.1)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client<2,>=1.7.11->tfx-bsl<1.16,>=1.15.1->tensorflow_data_validation) (3.0.1)\n",
            "Requirement already satisfied: oauth2client>=1.4.12 in /usr/local/lib/python3.10/dist-packages (from google-apitools<0.5.32,>=0.5.31->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (4.1.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.18.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.18.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (4.9)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0,>=1.26.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (1.12.3)\n",
            "Requirement already satisfied: shapely<3.0.0dev in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0,>=1.26.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.0.4)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0,>=1.26.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.7.4)\n",
            "Requirement already satisfied: docstring-parser<1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0,>=1.26.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.16)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery<4,>=2.0.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.7.1)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigtable<3,>=2.19.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.13.0)\n",
            "Requirement already satisfied: grpcio-status>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-pubsub<3,>=2.1.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (1.48.2)\n",
            "Requirement already satisfied: overrides<8.0.0,>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-pubsublite<2,>=1.2.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (7.7.0)\n",
            "Requirement already satisfied: sqlparse>=0.4.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-spanner<4,>=3.0.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.5.0)\n",
            "Requirement already satisfied: grpc-interceptor>=0.15.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-spanner<4,>=3.0.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.15.4)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage<3,>=2.14.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (1.5.0)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.10/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.6.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<0.23.0,>=0.8->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (3.1.2)\n",
            "Requirement already satisfied: tzlocal>=1.2 in /usr/local/lib/python3.10/dist-packages (from js2py<1,>=0.74->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (5.2)\n",
            "Requirement already satisfied: pyjsparser>=2.5.1 in /usr/local/lib/python3.10/dist-packages (from js2py<1,>=0.74->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.7.1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.18.1)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from pymongo<5.0.0,>=3.8.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.6.1)\n",
            "Requirement already satisfied: async-timeout>=4.0.3 in /usr/local/lib/python3.10/dist-packages (from redis<6,>=5.0.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2024.6.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tensorflow_data_validation) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tensorflow_data_validation) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tensorflow_data_validation) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tensorflow_data_validation) (3.0.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tensorflow_data_validation) (1.3.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from oauth2client>=1.4.12->google-apitools<0.5.32,>=0.5.31->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.6.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3->google-cloud-aiplatform<2.0,>=1.26.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3->google-cloud-aiplatform<2.0,>=1.26.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.18.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tensorflow_data_validation) (2.1.5)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tensorflow_data_validation) (3.2.2)\n",
            "Requirement already satisfied: tensorflow_data_validation in /usr/local/lib/python3.10/dist-packages (1.15.1)\n",
            "Requirement already satisfied: absl-py<2.0.0,>=0.9 in /usr/local/lib/python3.10/dist-packages (from tensorflow_data_validation) (1.4.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_data_validation) (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_data_validation) (1.25.2)\n",
            "Requirement already satisfied: pandas<2,>=1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_data_validation) (1.5.3)\n",
            "Requirement already satisfied: pyarrow<11,>=10 in /usr/local/lib/python3.10/dist-packages (from tensorflow_data_validation) (10.0.1)\n",
            "Requirement already satisfied: pyfarmhash<0.4,>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow_data_validation) (0.3.2)\n",
            "Requirement already satisfied: six<2,>=1.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow_data_validation) (1.16.0)\n",
            "Requirement already satisfied: tensorflow<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow_data_validation) (2.15.1)\n",
            "Requirement already satisfied: tensorflow-metadata<1.16,>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_data_validation) (1.15.0)\n",
            "Requirement already satisfied: tfx-bsl<1.16,>=1.15.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow_data_validation) (1.15.1)\n",
            "Requirement already satisfied: apache-beam[gcp]<3,>=2.47 in /usr/local/lib/python3.10/dist-packages (from tensorflow_data_validation) (2.56.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow_data_validation) (3.20.3)\n",
            "Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (1.7)\n",
            "Requirement already satisfied: orjson<4,>=3.9.7 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (3.10.5)\n",
            "Requirement already satisfied: dill<0.3.2,>=0.3.1.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.3.1.1)\n",
            "Requirement already satisfied: cloudpickle~=2.2.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.2.1)\n",
            "Requirement already satisfied: fastavro<2,>=0.23.6 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (1.9.4)\n",
            "Requirement already satisfied: fasteners<1.0,>=0.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.19)\n",
            "Requirement already satisfied: grpcio!=1.48.0,!=1.59.*,!=1.60.*,!=1.61.*,!=1.62.0,!=1.62.1,<2,>=1.33.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (1.64.1)\n",
            "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.7.3)\n",
            "Requirement already satisfied: httplib2<0.23.0,>=0.8 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.22.0)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (4.19.2)\n",
            "Requirement already satisfied: jsonpickle<4.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (3.2.2)\n",
            "Requirement already satisfied: objsize<0.8.0,>=0.6.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.7.0)\n",
            "Requirement already satisfied: packaging>=22.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (24.1)\n",
            "Requirement already satisfied: pymongo<5.0.0,>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (4.7.3)\n",
            "Requirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (1.24.0)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2018.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2023.4)\n",
            "Requirement already satisfied: redis<6,>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (5.0.7)\n",
            "Requirement already satisfied: regex>=2020.6.8 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2024.5.15)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (4.12.2)\n",
            "Requirement already satisfied: zstandard<1,>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.22.0)\n",
            "Requirement already satisfied: pyarrow-hotfix<1 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.6)\n",
            "Requirement already satisfied: js2py<1,>=0.74 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.74)\n",
            "Requirement already satisfied: cachetools<6,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (5.3.3)\n",
            "Requirement already satisfied: google-api-core<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.19.1)\n",
            "Requirement already satisfied: google-apitools<0.5.32,>=0.5.31 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.5.31)\n",
            "Requirement already satisfied: google-auth<3,>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.27.0)\n",
            "Requirement already satisfied: google-auth-httplib2<0.3.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.1.1)\n",
            "Requirement already satisfied: google-cloud-datastore<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.15.2)\n",
            "Requirement already satisfied: google-cloud-pubsub<3,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.21.5)\n",
            "Requirement already satisfied: google-cloud-pubsublite<2,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (1.10.0)\n",
            "Requirement already satisfied: google-cloud-storage<3,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.17.0)\n",
            "Requirement already satisfied: google-cloud-bigquery<4,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (3.21.0)\n",
            "Requirement already satisfied: google-cloud-bigquery-storage<3,>=2.6.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.25.0)\n",
            "Requirement already satisfied: google-cloud-core<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.3.3)\n",
            "Requirement already satisfied: google-cloud-bigtable<3,>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.24.0)\n",
            "Requirement already satisfied: google-cloud-spanner<4,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (3.47.0)\n",
            "Requirement already satisfied: google-cloud-dlp<4,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (3.18.0)\n",
            "Requirement already satisfied: google-cloud-language<3,>=2.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.13.3)\n",
            "Requirement already satisfied: google-cloud-videointelligence<3,>=2.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.13.3)\n",
            "Requirement already satisfied: google-cloud-vision<4,>=2 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (3.7.2)\n",
            "Requirement already satisfied: google-cloud-recommendations-ai<0.11.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.10.10)\n",
            "Requirement already satisfied: google-cloud-aiplatform<2.0,>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (1.56.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tensorflow_data_validation) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tensorflow_data_validation) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tensorflow_data_validation) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tensorflow_data_validation) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tensorflow_data_validation) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tensorflow_data_validation) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tensorflow_data_validation) (0.3.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tensorflow_data_validation) (3.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tensorflow_data_validation) (67.7.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tensorflow_data_validation) (2.4.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tensorflow_data_validation) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tensorflow_data_validation) (0.37.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tensorflow_data_validation) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tensorflow_data_validation) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tensorflow_data_validation) (2.15.0)\n",
            "Requirement already satisfied: google-api-python-client<2,>=1.7.11 in /usr/local/lib/python3.10/dist-packages (from tfx-bsl<1.16,>=1.15.1->tensorflow_data_validation) (1.12.11)\n",
            "Requirement already satisfied: tensorflow-serving-api<3,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tfx-bsl<1.16,>=1.15.1->tensorflow_data_validation) (2.15.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.16,>=2.15->tensorflow_data_validation) (0.43.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3,>=2.0.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (1.63.1)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client<2,>=1.7.11->tfx-bsl<1.16,>=1.15.1->tensorflow_data_validation) (3.0.1)\n",
            "Requirement already satisfied: oauth2client>=1.4.12 in /usr/local/lib/python3.10/dist-packages (from google-apitools<0.5.32,>=0.5.31->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (4.1.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.18.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.18.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (4.9)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0,>=1.26.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (1.12.3)\n",
            "Requirement already satisfied: shapely<3.0.0dev in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0,>=1.26.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.0.4)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0,>=1.26.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.7.4)\n",
            "Requirement already satisfied: docstring-parser<1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0,>=1.26.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.16)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery<4,>=2.0.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.7.1)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigtable<3,>=2.19.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.13.0)\n",
            "Requirement already satisfied: grpcio-status>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-pubsub<3,>=2.1.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (1.48.2)\n",
            "Requirement already satisfied: overrides<8.0.0,>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-pubsublite<2,>=1.2.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (7.7.0)\n",
            "Requirement already satisfied: sqlparse>=0.4.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-spanner<4,>=3.0.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.5.0)\n",
            "Requirement already satisfied: grpc-interceptor>=0.15.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-spanner<4,>=3.0.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.15.4)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage<3,>=2.14.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (1.5.0)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.10/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.6.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<0.23.0,>=0.8->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (3.1.2)\n",
            "Requirement already satisfied: tzlocal>=1.2 in /usr/local/lib/python3.10/dist-packages (from js2py<1,>=0.74->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (5.2)\n",
            "Requirement already satisfied: pyjsparser>=2.5.1 in /usr/local/lib/python3.10/dist-packages (from js2py<1,>=0.74->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.7.1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.18.1)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from pymongo<5.0.0,>=3.8.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.6.1)\n",
            "Requirement already satisfied: async-timeout>=4.0.3 in /usr/local/lib/python3.10/dist-packages (from redis<6,>=5.0.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2024.6.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tensorflow_data_validation) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tensorflow_data_validation) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tensorflow_data_validation) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tensorflow_data_validation) (3.0.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tensorflow_data_validation) (1.3.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from oauth2client>=1.4.12->google-apitools<0.5.32,>=0.5.31->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.6.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3->google-cloud-aiplatform<2.0,>=1.26.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3->google-cloud-aiplatform<2.0,>=1.26.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.18.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tensorflow_data_validation) (2.1.5)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tensorflow_data_validation) (3.2.2)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                      Type  Presence Valency Domain\n",
              "Feature name                                       \n",
              "'sepal length (cm)'  FLOAT  required              -\n",
              "'sepal width (cm)'   FLOAT  required              -\n",
              "'petal length (cm)'  FLOAT  required              -\n",
              "'petal width (cm)'   FLOAT  required              -\n",
              "'target'               INT  required              -"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3656bf71-ee78-41da-bd9c-8b31f95b7058\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Type</th>\n",
              "      <th>Presence</th>\n",
              "      <th>Valency</th>\n",
              "      <th>Domain</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feature name</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>'sepal length (cm)'</th>\n",
              "      <td>FLOAT</td>\n",
              "      <td>required</td>\n",
              "      <td></td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>'sepal width (cm)'</th>\n",
              "      <td>FLOAT</td>\n",
              "      <td>required</td>\n",
              "      <td></td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>'petal length (cm)'</th>\n",
              "      <td>FLOAT</td>\n",
              "      <td>required</td>\n",
              "      <td></td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>'petal width (cm)'</th>\n",
              "      <td>FLOAT</td>\n",
              "      <td>required</td>\n",
              "      <td></td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>'target'</th>\n",
              "      <td>INT</td>\n",
              "      <td>required</td>\n",
              "      <td></td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3656bf71-ee78-41da-bd9c-8b31f95b7058')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3656bf71-ee78-41da-bd9c-8b31f95b7058 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3656bf71-ee78-41da-bd9c-8b31f95b7058');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b2efad04-d064-4684-ab01-e2e90bd754a9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b2efad04-d064-4684-ab01-e2e90bd754a9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b2efad04-d064-4684-ab01-e2e90bd754a9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"tfdv\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Feature name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"'sepal width (cm)'\",\n          \"'target'\",\n          \"'petal length (cm)'\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"INT\",\n          \"FLOAT\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Presence\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"required\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Valency\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Domain\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"-\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                      Type  Presence Valency Domain\n",
              "Feature name                                       \n",
              "'sepal length (cm)'  FLOAT  required              -\n",
              "'sepal width (cm)'   FLOAT  required              -\n",
              "'petal length (cm)'  FLOAT  required              -\n",
              "'petal width (cm)'   FLOAT  required              -\n",
              "'target'               INT  required              -"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3b707bc8-d2ab-435a-8b41-202119be119d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Type</th>\n",
              "      <th>Presence</th>\n",
              "      <th>Valency</th>\n",
              "      <th>Domain</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feature name</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>'sepal length (cm)'</th>\n",
              "      <td>FLOAT</td>\n",
              "      <td>required</td>\n",
              "      <td></td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>'sepal width (cm)'</th>\n",
              "      <td>FLOAT</td>\n",
              "      <td>required</td>\n",
              "      <td></td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>'petal length (cm)'</th>\n",
              "      <td>FLOAT</td>\n",
              "      <td>required</td>\n",
              "      <td></td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>'petal width (cm)'</th>\n",
              "      <td>FLOAT</td>\n",
              "      <td>required</td>\n",
              "      <td></td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>'target'</th>\n",
              "      <td>INT</td>\n",
              "      <td>required</td>\n",
              "      <td></td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3b707bc8-d2ab-435a-8b41-202119be119d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3b707bc8-d2ab-435a-8b41-202119be119d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3b707bc8-d2ab-435a-8b41-202119be119d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3d8a61ee-50c2-4b66-b261-7abc29772658\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3d8a61ee-50c2-4b66-b261-7abc29772658')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3d8a61ee-50c2-4b66-b261-7abc29772658 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"tfdv\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Feature name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"'sepal width (cm)'\",\n          \"'target'\",\n          \"'petal length (cm)'\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"INT\",\n          \"FLOAT\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Presence\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"required\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Valency\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Domain\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"-\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<h4 style=\"color:green;\">No anomalies found.</h4>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Model Analysis**\n",
        "* **TensorFlow Model Analysis (TFMA):**\n",
        " * TFMA is a library for evaluating TensorFlow models. It allows you to evaluate the performance of your models in a scalable and flexible way.\n",
        "\n",
        "**Example: Using TFMA for Model Analysis**"
      ],
      "metadata": {
        "id": "jIKpoilVgi02"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install TensorFlow Model Analysis\n",
        "# !pip install tensorflow_model_analysis\n",
        "\n",
        "import tensorflow_model_analysis as tfma\n",
        "import tensorflow as tf\n",
        "\n",
        "# Convert CSV data to TFRecords\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "import tempfile\n",
        "\n",
        "# Load the iris dataset as a pandas DataFrame\n",
        "iris = load_iris()\n",
        "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
        "df['label'] = iris.target  # Use 'label' as the label key\n",
        "\n",
        "# Convert the 'label' column to integers\n",
        "df['label'] = df['label'].astype(int)\n",
        "\n",
        "# Save the DataFrame to a temporary CSV file\n",
        "temp_csv = tempfile.NamedTemporaryFile(suffix='.csv', delete=False)\n",
        "df.to_csv(temp_csv.name, index=False)\n",
        "\n",
        "# Convert CSV to TFRecords\n",
        "def to_tfrecords(csv_path, tfrecords_path):\n",
        "    with tf.io.TFRecordWriter(tfrecords_path) as writer:\n",
        "        for _, row in pd.read_csv(csv_path).iterrows():\n",
        "            example = tf.train.Example(\n",
        "                features=tf.train.Features(\n",
        "                    feature={\n",
        "                        'sepal length (cm)': tf.train.Feature(float_list=tf.train.FloatList(value=[row['sepal length (cm)']])),\n",
        "                        'sepal width (cm)': tf.train.Feature(float_list=tf.train.FloatList(value=[row['sepal width (cm)']])),\n",
        "                        'petal length (cm)': tf.train.Feature(float_list=tf.train.FloatList(value=[row['petal length (cm)']])),\n",
        "                        'petal width (cm)': tf.train.Feature(float_list=tf.train.FloatList(value=[row['petal width (cm)']])),\n",
        "                        'label': tf.train.Feature(int64_list=tf.train.Int64List(value=[int(row['label'])]))  # Cast label to int\n",
        "                    }\n",
        "                )\n",
        "            )\n",
        "            writer.write(example.SerializeToString())\n",
        "\n",
        "# Create a temporary TFRecord file\n",
        "temp_tfrecords = tempfile.NamedTemporaryFile(suffix='.tfrecords', delete=False)\n",
        "to_tfrecords(temp_csv.name, temp_tfrecords.name)\n",
        "\n",
        "# Define feature description for parsing the TFRecord file\n",
        "feature_description = {\n",
        "    'sepal length (cm)': tf.io.FixedLenFeature([], tf.float32),\n",
        "    'sepal width (cm)': tf.io.FixedLenFeature([], tf.float32),\n",
        "    'petal length (cm)': tf.io.FixedLenFeature([], tf.float32),\n",
        "    'petal width (cm)': tf.io.FixedLenFeature([], tf.float32),\n",
        "    'label': tf.io.FixedLenFeature([], tf.int64),\n",
        "}\n",
        "\n",
        "# Create a parsing function\n",
        "def _parse_function(example_proto):\n",
        "    return tf.io.parse_single_example(example_proto, feature_description)\n",
        "\n",
        "# Create a dataset from the TFRecord file\n",
        "raw_dataset = tf.data.TFRecordDataset(temp_tfrecords.name)\n",
        "parsed_dataset = raw_dataset.map(_parse_function)\n",
        "\n",
        "# Define the model\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(128, activation='relu', input_shape=(4,)),  # Use appropriate input shape\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(df[iris.feature_names].values, df['label'].values, epochs=10, validation_split=0.2)\n",
        "\n",
        "# Save the model to a temporary location\n",
        "model_location = tempfile.mkdtemp()\n",
        "model.save(model_location)\n",
        "\n",
        "# Define the evaluation configuration\n",
        "eval_config = tfma.EvalConfig(\n",
        "    model_specs=[tfma.ModelSpec(label_key='label')],\n",
        "    slicing_specs=[tfma.SlicingSpec()],\n",
        "    metrics_specs=[\n",
        "        tfma.MetricsSpec(\n",
        "            metrics=[\n",
        "                tfma.MetricConfig(class_name='ExampleCount'),\n",
        "                tfma.MetricConfig(class_name='Accuracy')\n",
        "            ]\n",
        "        )\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Modify the evaluation code to properly handle the parsed data\n",
        "def serving_input_receiver_fn():\n",
        "    feature_spec = {\n",
        "        'sepal length (cm)': tf.io.FixedLenFeature([], tf.float32),\n",
        "        'sepal width (cm)': tf.io.FixedLenFeature([], tf.float32),\n",
        "        'petal length (cm)': tf.io.FixedLenFeature([], tf.float32),\n",
        "        'petal width (cm)': tf.io.FixedLenFeature([], tf.float32)\n",
        "    }\n",
        "    serialized_tf_example = tf.compat.v1.placeholder(dtype=tf.string, shape=[None], name='input_example_tensor')\n",
        "    receiver_tensors = {'examples': serialized_tf_example}\n",
        "    features = tf.io.parse_example(serialized_tf_example, feature_spec)\n",
        "    return tf.estimator.export.ServingInputReceiver(features, receiver_tensors)\n",
        "\n",
        "# Create the eval shared model\n",
        "eval_shared_model = tfma.default_eval_shared_model(\n",
        "    eval_saved_model_path=model_location,\n",
        "    eval_config=eval_config,\n",
        "    tags=[tf.saved_model.SERVING]\n",
        ")\n",
        "\n",
        "# Run the model analysis using the TFRecord file\n",
        "eval_result = tfma.run_model_analysis(\n",
        "    eval_shared_model=eval_shared_model,\n",
        "    data_location=temp_tfrecords.name,  # Use the TFRecord file\n",
        "    eval_config=eval_config\n",
        ")\n",
        "\n",
        "# Visualize the results\n",
        "tfma.view.render_slicing_metrics(eval_result)\n",
        "\n",
        "# Clean up temporary files\n",
        "temp_csv.close()\n",
        "temp_tfrecords.close()\n",
        "import os\n",
        "os.remove(temp_csv.name)\n",
        "os.remove(temp_tfrecords.name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zogCWCXDgsuU",
        "outputId": "5f53bcaa-9d2e-4e5d-d1e6-d1f335eac390"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "4/4 [==============================] - 3s 184ms/step - loss: 1.0300 - accuracy: 0.4167 - val_loss: 1.4689 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 0.8791 - accuracy: 0.6917 - val_loss: 1.3620 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 0.7862 - accuracy: 0.8333 - val_loss: 1.1471 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 0s 52ms/step - loss: 0.7054 - accuracy: 0.8333 - val_loss: 1.1261 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 0.6302 - accuracy: 0.8333 - val_loss: 1.0930 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.5620 - accuracy: 0.8333 - val_loss: 1.0834 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 0s 73ms/step - loss: 0.5044 - accuracy: 0.8333 - val_loss: 1.0809 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 0s 67ms/step - loss: 0.4570 - accuracy: 0.8333 - val_loss: 1.1015 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 0s 72ms/step - loss: 0.4197 - accuracy: 0.8333 - val_loss: 1.0144 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 0s 63ms/step - loss: 0.3848 - accuracy: 0.8417 - val_loss: 0.9404 - val_accuracy: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Tensorflow version (2.15.1) found. Note that TFMA support for TF 2.0 is currently in beta\n",
            "WARNING:absl:Large batch_size 1 failed with error Fail to call signature func with signature_name: serving_default.\n",
            "              the inputs are:\n",
            " [b'\\n\\x8a\\x01\\n\\x1d\\n\\x11sepal length (cm)\\x12\\x08\\x12\\x06\\n\\x0433\\xa3@\\n\\x1d\\n\\x11petal length (cm)\\x12\\x08\\x12\\x06\\n\\x0433\\xb3?\\n\\x1c\\n\\x10sepal width (cm)\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00`@\\n\\x1c\\n\\x10petal width (cm)\\x12\\x08\\x12\\x06\\n\\x04\\xcd\\xccL>\\n\\x0e\\n\\x05label\\x12\\x05\\x1a\\x03\\n\\x01\\x00'].\n",
            "              The input_specs are:\n",
            " {'dense_12_input': TensorSpec(shape=(None, 4), dtype=tf.float32, name='dense_12_input')}.. Attempting to run batch through serially. Note that this will significantly affect the performance.\n",
            "ERROR:apache_beam.runners.common:Fail to call signature func with signature_name: serving_default.\n",
            "              the inputs are:\n",
            " [b'\\n\\x8a\\x01\\n\\x1d\\n\\x11sepal length (cm)\\x12\\x08\\x12\\x06\\n\\x0433\\xa3@\\n\\x1d\\n\\x11petal length (cm)\\x12\\x08\\x12\\x06\\n\\x0433\\xb3?\\n\\x1c\\n\\x10sepal width (cm)\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00`@\\n\\x1c\\n\\x10petal width (cm)\\x12\\x08\\x12\\x06\\n\\x04\\xcd\\xccL>\\n\\x0e\\n\\x05label\\x12\\x05\\x1a\\x03\\n\\x01\\x00'].\n",
            "              The input_specs are:\n",
            " {'dense_12_input': TensorSpec(shape=(None, 4), dtype=tf.float32, name='dense_12_input')}. [while running 'ExtractEvaluateAndWriteResults/ExtractAndEvaluate/ExtractPredictions/Inference']\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/function_type_utils.py\", line 442, in bind_function_inputs\n",
            "    bound_arguments = function_type.bind_with_defaults(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/core/function/polymorphism/function_type.py\", line 264, in bind_with_defaults\n",
            "    bound_arguments = self.bind(*args, **kwargs)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 3186, in bind\n",
            "    return self._bind(args, kwargs)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 3112, in _bind\n",
            "    raise TypeError(\n",
            "TypeError: too many positional arguments\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\", line 1180, in _call_impl\n",
            "    return self._call_with_structured_signature(args, kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\", line 1260, in _call_with_structured_signature\n",
            "    function_type_utils.canonicalize_function_inputs(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/function_type_utils.py\", line 422, in canonicalize_function_inputs\n",
            "    bound_arguments = bind_function_inputs(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/function_type_utils.py\", line 446, in bind_function_inputs\n",
            "    raise TypeError(\n",
            "TypeError: Binding inputs to tf.function failed due to `too many positional arguments`. Received args: (<tf.Tensor: shape=(1,), dtype=string, numpy=\n",
            "array([b'\\n\\x8a\\x01\\n\\x1d\\n\\x11sepal length (cm)\\x12\\x08\\x12\\x06\\n\\x0433\\xa3@\\n\\x1d\\n\\x11petal length (cm)\\x12\\x08\\x12\\x06\\n\\x0433\\xb3?\\n\\x1c\\n\\x10sepal width (cm)\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00`@\\n\\x1c\\n\\x10petal width (cm)\\x12\\x08\\x12\\x06\\n\\x04\\xcd\\xccL>\\n\\x0e\\n\\x05label\\x12\\x05\\x1a\\x03\\n\\x01\\x00'],\n",
            "      dtype=object)>,) and kwargs: {} for signature: (*, dense_12_input: TensorSpec(shape=(None, 4), dtype=tf.float32, name='dense_12_input')) -> Dict[['dense_14', TensorSpec(shape=(None, 3), dtype=tf.float32, name='dense_14')]].\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow_model_analysis/utils/model_util.py\", line 1032, in _batch_reducible_process\n",
            "    outputs = signature(tf.constant(inputs, dtype=tf.string))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\", line 1171, in __call__\n",
            "    return self._call_impl(args, kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\", line 1183, in _call_impl\n",
            "    return self._call_with_flat_signature(args, kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\", line 1243, in _call_with_flat_signature\n",
            "    return self._call_flat(args, self.captured_inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/saved_model/load.py\", line 146, in _call_flat\n",
            "    return super()._call_flat(args, captured_inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\", line 1323, in _call_flat\n",
            "    return self._inference_function.call_preflattened(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 216, in call_preflattened\n",
            "    flat_outputs = self.call_flat(*args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 251, in call_flat\n",
            "    outputs = self._bound_context.call_function(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\", line 1486, in call_function\n",
            "    outputs = execute.execute(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\", line 53, in quick_execute\n",
            "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
            "tensorflow.python.framework.errors_impl.InvalidArgumentError: cannot compute __inference_signature_wrapper_16943 as input #0(zero-based) was expected to be a float tensor but is a string tensor [Op:__inference_signature_wrapper_16943]\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"apache_beam/runners/common.py\", line 1435, in apache_beam.runners.common.DoFnRunner.process\n",
            "  File \"apache_beam/runners/common.py\", line 640, in apache_beam.runners.common.SimpleInvoker.invoke_process\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow_model_analysis/utils/model_util.py\", line 866, in process\n",
            "    result.extend(self._batch_reducible_process(unbatched_element))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow_model_analysis/utils/model_util.py\", line 1034, in _batch_reducible_process\n",
            "    raise ValueError(\n",
            "ValueError: Fail to call signature func with signature_name: serving_default.\n",
            "              the inputs are:\n",
            " [b'\\n\\x8a\\x01\\n\\x1d\\n\\x11sepal length (cm)\\x12\\x08\\x12\\x06\\n\\x0433\\xa3@\\n\\x1d\\n\\x11petal length (cm)\\x12\\x08\\x12\\x06\\n\\x0433\\xb3?\\n\\x1c\\n\\x10sepal width (cm)\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00`@\\n\\x1c\\n\\x10petal width (cm)\\x12\\x08\\x12\\x06\\n\\x04\\xcd\\xccL>\\n\\x0e\\n\\x05label\\x12\\x05\\x1a\\x03\\n\\x01\\x00'].\n",
            "              The input_specs are:\n",
            " {'dense_12_input': TensorSpec(shape=(None, 4), dtype=tf.float32, name='dense_12_input')}.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Fail to call signature func with signature_name: serving_default.\n              the inputs are:\n [b'\\n\\x8a\\x01\\n\\x1d\\n\\x11sepal length (cm)\\x12\\x08\\x12\\x06\\n\\x0433\\xa3@\\n\\x1d\\n\\x11petal length (cm)\\x12\\x08\\x12\\x06\\n\\x0433\\xb3?\\n\\x1c\\n\\x10sepal width (cm)\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00`@\\n\\x1c\\n\\x10petal width (cm)\\x12\\x08\\x12\\x06\\n\\x04\\xcd\\xccL>\\n\\x0e\\n\\x05label\\x12\\x05\\x1a\\x03\\n\\x01\\x00'].\n              The input_specs are:\n {'dense_12_input': TensorSpec(shape=(None, 4), dtype=tf.float32, name='dense_12_input')}. [while running 'ExtractEvaluateAndWriteResults/ExtractAndEvaluate/ExtractPredictions/Inference']",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/function_type_utils.py\u001b[0m in \u001b[0;36mbind_function_inputs\u001b[0;34m(args, kwargs, function_type, default_values)\u001b[0m\n\u001b[1;32m    441\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m     bound_arguments = function_type.bind_with_defaults(\n\u001b[0m\u001b[1;32m    443\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msanitized_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/core/function/polymorphism/function_type.py\u001b[0m in \u001b[0;36mbind_with_defaults\u001b[0;34m(self, args, kwargs, default_values)\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;34m\"\"\"Returns BoundArguments with default values filled in.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m     \u001b[0mbound_arguments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m     \u001b[0mbound_arguments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/inspect.py\u001b[0m in \u001b[0;36mbind\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3185\u001b[0m         \"\"\"\n\u001b[0;32m-> 3186\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/inspect.py\u001b[0m in \u001b[0;36m_bind\u001b[0;34m(self, args, kwargs, partial)\u001b[0m\n\u001b[1;32m   3111\u001b[0m                         \u001b[0;31m# argument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3112\u001b[0;31m                         raise TypeError(\n\u001b[0m\u001b[1;32m   3113\u001b[0m                             'too many positional arguments') from None\n",
            "\u001b[0;31mTypeError\u001b[0m: too many positional arguments",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_with_structured_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstructured_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_with_structured_signature\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1259\u001b[0m     bound_args = (\n\u001b[0;32m-> 1260\u001b[0;31m         function_type_utils.canonicalize_function_inputs(\n\u001b[0m\u001b[1;32m   1261\u001b[0m             args, kwargs, self.function_type)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/function_type_utils.py\u001b[0m in \u001b[0;36mcanonicalize_function_inputs\u001b[0;34m(args, kwargs, function_type, default_values, is_pure)\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_variables_to_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m   bound_arguments = bind_function_inputs(\n\u001b[0m\u001b[1;32m    423\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/function_type_utils.py\u001b[0m in \u001b[0;36mbind_function_inputs\u001b[0;34m(args, kwargs, function_type, default_values)\u001b[0m\n\u001b[1;32m    445\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m     raise TypeError(\n\u001b[0m\u001b[1;32m    447\u001b[0m         \u001b[0;34mf\"Binding inputs to tf.function failed due to `{e}`. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Binding inputs to tf.function failed due to `too many positional arguments`. Received args: (<tf.Tensor: shape=(1,), dtype=string, numpy=\narray([b'\\n\\x8a\\x01\\n\\x1d\\n\\x11sepal length (cm)\\x12\\x08\\x12\\x06\\n\\x0433\\xa3@\\n\\x1d\\n\\x11petal length (cm)\\x12\\x08\\x12\\x06\\n\\x0433\\xb3?\\n\\x1c\\n\\x10sepal width (cm)\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00`@\\n\\x1c\\n\\x10petal width (cm)\\x12\\x08\\x12\\x06\\n\\x04\\xcd\\xccL>\\n\\x0e\\n\\x05label\\x12\\x05\\x1a\\x03\\n\\x01\\x00'],\n      dtype=object)>,) and kwargs: {} for signature: (*, dense_12_input: TensorSpec(shape=(None, 4), dtype=tf.float32, name='dense_12_input')) -> Dict[['dense_14', TensorSpec(shape=(None, 3), dtype=tf.float32, name='dense_14')]].",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_model_analysis/utils/model_util.py\u001b[0m in \u001b[0;36m_batch_reducible_process\u001b[0;34m(self, batched_extract)\u001b[0m\n\u001b[1;32m   1031\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1033\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1170\u001b[0m     \"\"\"\n\u001b[0;32m-> 1171\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1182\u001b[0m           \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_with_flat_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mflat_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_with_flat_signature\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1242\u001b[0m                         f\"got {type(arg).__name__} ({arg}).\")\n\u001b[0;32m-> 1243\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m       \u001b[0mcaptured_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_unused_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: cannot compute __inference_signature_wrapper_16943 as input #0(zero-based) was expected to be a float tensor but is a string tensor [Op:__inference_signature_wrapper_16943]",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.SimpleInvoker.invoke_process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_model_analysis/utils/model_util.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, element)\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_size\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 866\u001b[0;31m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_reducible_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munbatched_element\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    867\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_instances\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_model_analysis/utils/model_util.py\u001b[0m in \u001b[0;36m_batch_reducible_process\u001b[0;34m(self, batched_extract)\u001b[0m\n\u001b[1;32m   1033\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m           raise ValueError(\n\u001b[0m\u001b[1;32m   1035\u001b[0m               \"\"\"Fail to call signature func with signature_name: {}.\n",
            "\u001b[0;31mValueError\u001b[0m: Fail to call signature func with signature_name: serving_default.\n              the inputs are:\n [b'\\n\\x8a\\x01\\n\\x1d\\n\\x11sepal length (cm)\\x12\\x08\\x12\\x06\\n\\x0433\\xa3@\\n\\x1d\\n\\x11petal length (cm)\\x12\\x08\\x12\\x06\\n\\x0433\\xb3?\\n\\x1c\\n\\x10sepal width (cm)\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00`@\\n\\x1c\\n\\x10petal width (cm)\\x12\\x08\\x12\\x06\\n\\x04\\xcd\\xccL>\\n\\x0e\\n\\x05label\\x12\\x05\\x1a\\x03\\n\\x01\\x00'].\n              The input_specs are:\n {'dense_12_input': TensorSpec(shape=(None, 4), dtype=tf.float32, name='dense_12_input')}.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-a108733d2b1c>\u001b[0m in \u001b[0;36m<cell line: 114>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;31m# Run the model analysis using the TFRecord file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m eval_result = tfma.run_model_analysis(\n\u001b[0m\u001b[1;32m    115\u001b[0m     \u001b[0meval_shared_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_shared_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0mdata_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtemp_tfrecords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Use the TFRecord file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_model_analysis/api/model_eval_lib.py\u001b[0m in \u001b[0;36mrun_model_analysis\u001b[0;34m(eval_shared_model, eval_config, data_location, file_format, output_path, extractors, evaluators, writers, pipeline_options, slice_spec, write_config, compute_confidence_intervals, min_slice_size, random_seed_for_testing, schema)\u001b[0m\n\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m   \u001b[0mtensor_adapter_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1305\u001b[0;31m   \u001b[0;32mwith\u001b[0m \u001b[0mbeam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpipeline_options\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1306\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfile_format\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tfrecords'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mis_batched_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_shared_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig_version\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/pipeline.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    611\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mexc_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 613\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    614\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_until_finish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/pipeline.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, test_runner_api)\u001b[0m\n\u001b[1;32m    585\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m           \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmpdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 587\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    588\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_in_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/direct/direct_runner.py\u001b[0m in \u001b[0;36mrun_pipeline\u001b[0;34m(self, pipeline, options)\u001b[0m\n\u001b[1;32m    126\u001b[0m       \u001b[0mrunner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBundleBasedDirectRunner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/portability/fn_api_runner/fn_runner.py\u001b[0m in \u001b[0;36mrun_pipeline\u001b[0;34m(self, pipeline, options)\u001b[0m\n\u001b[1;32m    202\u001b[0m         options.view_as(pipeline_options.ProfilingOptions))\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m     self._latest_run_result = self.run_via_runner_api(\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_runner_api\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_environment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_environment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         options)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/portability/fn_api_runner/fn_runner.py\u001b[0m in \u001b[0;36mrun_via_runner_api\u001b[0;34m(self, pipeline_proto, options)\u001b[0m\n\u001b[1;32m    226\u001b[0m         self.resolve_any_environments(pipeline_proto))\n\u001b[1;32m    227\u001b[0m     \u001b[0mstage_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_stages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline_proto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_stages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstage_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0membed_default_docker_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpipeline_proto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/portability/fn_api_runner/fn_runner.py\u001b[0m in \u001b[0;36mrun_stages\u001b[0;34m(self, stage_context, stages)\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m           \u001b[0mbundle_counter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m           bundle_results = self._execute_bundle(\n\u001b[0m\u001b[1;32m    484\u001b[0m               runner_execution_context, bundle_context_manager, bundle_input)\n\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/portability/fn_api_runner/fn_runner.py\u001b[0m in \u001b[0;36m_execute_bundle\u001b[0;34m(self, runner_execution_context, bundle_context_manager, bundle_input)\u001b[0m\n\u001b[1;32m    809\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m     last_result, deferred_inputs, newly_set_timers, watermark_updates = (\n\u001b[0;32m--> 811\u001b[0;31m         self._run_bundle(\n\u001b[0m\u001b[1;32m    812\u001b[0m             \u001b[0mrunner_execution_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m             \u001b[0mbundle_context_manager\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/portability/fn_api_runner/fn_runner.py\u001b[0m in \u001b[0;36m_run_bundle\u001b[0;34m(self, runner_execution_context, bundle_context_manager, bundle_input, data_output, expected_timer_output, bundle_manager)\u001b[0m\n\u001b[1;32m   1046\u001b[0m         expected_timer_output)\n\u001b[1;32m   1047\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1048\u001b[0;31m     result, splits = bundle_manager.process_bundle(\n\u001b[0m\u001b[1;32m   1049\u001b[0m         data_input, data_output, input_timers, expected_timer_output)\n\u001b[1;32m   1050\u001b[0m     \u001b[0;31m# Now we collect all the deferred inputs remaining from bundle execution.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/portability/fn_api_runner/fn_runner.py\u001b[0m in \u001b[0;36mprocess_bundle\u001b[0;34m(self, inputs, expected_outputs, fired_timers, expected_output_timers, dry_run)\u001b[0m\n\u001b[1;32m   1382\u001b[0m             \u001b[0mprocess_bundle_descriptor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m             cache_tokens=[next(self._cache_token_generator)]))\n\u001b[0;32m-> 1384\u001b[0;31m     \u001b[0mresult_future\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_worker_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_conn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_bundle_req\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m     \u001b[0msplit_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# type: List[beam_fn_api_pb2.ProcessBundleSplitResponse]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/portability/fn_api_runner/worker_handlers.py\u001b[0m in \u001b[0;36mpush\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    382\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uid_counter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m       \u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstruction_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'control_%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uid_counter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_instruction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mControlFuture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstruction_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/sdk_worker.py\u001b[0m in \u001b[0;36mdo_instruction\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    654\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrequest_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m       \u001b[0;31m# E.g. if register is set, this will call self.register(request.register))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 656\u001b[0;31m       return getattr(self, request_type)(\n\u001b[0m\u001b[1;32m    657\u001b[0m           getattr(request, request_type), request.instruction_id)\n\u001b[1;32m    658\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/sdk_worker.py\u001b[0m in \u001b[0;36mprocess_bundle\u001b[0;34m(self, request, instruction_id)\u001b[0m\n\u001b[1;32m    692\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_profile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstruction_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m           delayed_applications, requests_finalization = (\n\u001b[0;32m--> 694\u001b[0;31m               bundle_processor.process_bundle(instruction_id))\n\u001b[0m\u001b[1;32m    695\u001b[0m           \u001b[0mmonitoring_infos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbundle_processor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonitoring_infos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m           response = beam_fn_api_pb2.InstructionResponse(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/bundle_processor.py\u001b[0m in \u001b[0;36mprocess_bundle\u001b[0;34m(self, instruction_id)\u001b[0m\n\u001b[1;32m   1111\u001b[0m                   element.timer_family_id, timer_data)\n\u001b[1;32m   1112\u001b[0m           \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam_fn_api_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mElements\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1113\u001b[0;31m             input_op_by_transform_id[element.transform_id].process_encoded(\n\u001b[0m\u001b[1;32m   1114\u001b[0m                 element.data)\n\u001b[1;32m   1115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/bundle_processor.py\u001b[0m in \u001b[0;36mprocess_encoded\u001b[0;34m(self, encoded_windowed_values)\u001b[0m\n\u001b[1;32m    235\u001b[0m             \u001b[0;34m\"Error decoding input stream with coder \"\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             str(self.windowed_coder)) from exn\n\u001b[0;32m--> 237\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoded_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mmonitoring_infos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag_to_pcollection_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.Operation.output\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.Operation.output\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.SingletonElementConsumerSet.receive\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.SingletonElementConsumerSet.receive\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.SdfProcessSizedElements.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.SdfProcessSizedElements.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner.process_with_sized_restriction\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.PerWindowInvoker.invoke_process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.PerWindowInvoker._invoke_process_per_window\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common._OutputHandler.handle_process_outputs\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common._OutputHandler._write_value_to_tag\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.SingletonElementConsumerSet.receive\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.FlattenOperation.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.FlattenOperation.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.Operation.output\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.SingletonElementConsumerSet.receive\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.SingletonElementConsumerSet.receive\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.DoOperation.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.DoOperation.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner._reraise_augmented\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.SimpleInvoker.invoke_process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common._OutputHandler.handle_process_outputs\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common._OutputHandler._write_value_to_tag\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.SingletonElementConsumerSet.receive\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.DoOperation.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.DoOperation.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner._reraise_augmented\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.SimpleInvoker.invoke_process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common._OutputHandler.handle_process_outputs\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common._OutputHandler._write_value_to_tag\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.SingletonElementConsumerSet.receive\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.DoOperation.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.DoOperation.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner._reraise_augmented\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.SimpleInvoker.invoke_process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common._OutputHandler.handle_process_outputs\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common._OutputHandler._write_value_to_tag\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.SingletonElementConsumerSet.receive\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.DoOperation.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.DoOperation.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner._reraise_augmented\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.SimpleInvoker.invoke_process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common._OutputHandler.handle_process_outputs\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common._OutputHandler._write_value_to_tag\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.SingletonElementConsumerSet.receive\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.DoOperation.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.DoOperation.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner._reraise_augmented\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.SimpleInvoker.invoke_process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common._OutputHandler.handle_process_outputs\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common._OutputHandler._write_value_to_tag\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.GeneralPurposeConsumerSet.receive\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.DoOperation.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.DoOperation.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.DoOperation.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner._reraise_augmented\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.SimpleInvoker.invoke_process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common._OutputHandler.handle_process_outputs\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common._OutputHandler._write_value_to_tag\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.SingletonElementConsumerSet.receive\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.DoOperation.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.DoOperation.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner._reraise_augmented\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.SimpleInvoker.invoke_process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common._OutputHandler.handle_process_outputs\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common._OutputHandler._write_value_to_tag\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.SingletonElementConsumerSet.receive\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.DoOperation.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.DoOperation.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner._reraise_augmented\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.SimpleInvoker.invoke_process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common._OutputHandler.handle_process_outputs\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common._OutputHandler._write_value_to_tag\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.SingletonElementConsumerSet.receive\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.DoOperation.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.DoOperation.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner._reraise_augmented\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.SimpleInvoker.invoke_process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common._OutputHandler.handle_process_outputs\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common._OutputHandler._write_value_to_tag\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.SingletonElementConsumerSet.receive\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.DoOperation.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.DoOperation.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner._reraise_augmented\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.SimpleInvoker.invoke_process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_model_analysis/utils/model_util.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, element)\u001b[0m\n\u001b[1;32m    864\u001b[0m           element, keep_batch_dim=True):\n\u001b[1;32m    865\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_size\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 866\u001b[0;31m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_reducible_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munbatched_element\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    867\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_instances\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_model_analysis/utils/model_util.py\u001b[0m in \u001b[0;36m_batch_reducible_process\u001b[0;34m(self, batched_extract)\u001b[0m\n\u001b[1;32m   1032\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m           raise ValueError(\n\u001b[0m\u001b[1;32m   1035\u001b[0m               \"\"\"Fail to call signature func with signature_name: {}.\n\u001b[1;32m   1036\u001b[0m               \u001b[0mthe\u001b[0m \u001b[0minputs\u001b[0m \u001b[0mare\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Fail to call signature func with signature_name: serving_default.\n              the inputs are:\n [b'\\n\\x8a\\x01\\n\\x1d\\n\\x11sepal length (cm)\\x12\\x08\\x12\\x06\\n\\x0433\\xa3@\\n\\x1d\\n\\x11petal length (cm)\\x12\\x08\\x12\\x06\\n\\x0433\\xb3?\\n\\x1c\\n\\x10sepal width (cm)\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00`@\\n\\x1c\\n\\x10petal width (cm)\\x12\\x08\\x12\\x06\\n\\x04\\xcd\\xccL>\\n\\x0e\\n\\x05label\\x12\\x05\\x1a\\x03\\n\\x01\\x00'].\n              The input_specs are:\n {'dense_12_input': TensorSpec(shape=(None, 4), dtype=tf.float32, name='dense_12_input')}. [while running 'ExtractEvaluateAndWriteResults/ExtractAndEvaluate/ExtractPredictions/Inference']"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Model Serving**\n",
        "**TensorFlow Serving:**\n",
        "* TensorFlow Serving is a flexible, high-performance serving system for machine learning models designed for production environments.\n",
        "\n",
        "**Example: Serving a TensorFlow Model**"
      ],
      "metadata": {
        "id": "CiEFR8zGgwb-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1-Save the Model in the SavedModel Format:"
      ],
      "metadata": {
        "id": "0hyU8H7Mg6BQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define and train a model\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(128, activation='relu', input_shape=(784,)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n",
        "\n",
        "# Save the model in the SavedModel format\n",
        "model.save('saved_model/my_model')\n"
      ],
      "metadata": {
        "id": "zc8faLBjg2pQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2-Start TensorFlow Serving:"
      ],
      "metadata": {
        "id": "YhtGBs6Cg-d4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "docker pull tensorflow/serving\n",
        "docker run -p 8501:8501 --name=tf_serving --mount type=bind,source=$(pwd)/saved_model,target=/models/my_model -e MODEL_NAME=my_model -t tensorflow/serving\n"
      ],
      "metadata": {
        "id": "ist3WNTQhBM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3-Make Predictions Using the REST API:"
      ],
      "metadata": {
        "id": "6yqZpNKohC3K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "import numpy as np\n",
        "\n",
        "data = json.dumps({\"signature_name\": \"serving_default\", \"instances\": x_test[:5].tolist()})\n",
        "headers = {\"content-type\": \"application/json\"}\n",
        "json_response = requests.post('http://localhost:8501/v1/models/my_model:predict', data=data, headers=headers)\n",
        "predictions = np.array(json.loads(json_response.text)[\"predictions\"])\n",
        "print(predictions)\n"
      ],
      "metadata": {
        "id": "irGERVZbhFW3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}