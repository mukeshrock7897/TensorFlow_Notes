{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNsyDFhIwzo0dpJ0gi+JoRm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mukeshrock7897/TensorFlow_Notes/blob/main/Advanced_Level.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Transfer Learning**\n",
        "* Transfer learning involves using a pre-trained model on a new task, which saves training time and leverages learned features from large datasets.\n",
        "\n",
        "**Example:** Fine-tuning a pre-trained model on a new dataset\n",
        "\n"
      ],
      "metadata": {
        "id": "9Nhw34tGx1gP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "VHzp7x8PL-7U"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the pre-trained VGG16 model\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze the layers of the base model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add custom layers on top of the base model\n",
        "x = base_model.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "predictions = Dense(10, activation='softmax')(x)\n",
        "\n",
        "# Create the full model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "train_datagen = ImageDataGenerator(rescale=0.5)\n",
        "\n",
        "# **Update with the correct path to your training data**\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/content/train_data',  # Replace with the actual path\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_generator, epochs=10)\n",
        "\n",
        "# Plot accuracy and loss during training\n",
        "history = model.fit(train_generator, epochs=10)\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Generative Adversarial Networks (GANs)**\n",
        "* GANs consist of two networks, a generator and a discriminator, that compete against each other. The generator creates data, while the discriminator evaluates it. real or fake\n",
        "\n",
        "**Example:** Simple GAN for generating MNIST digits\n",
        "\n"
      ],
      "metadata": {
        "id": "yKaz3saTykmC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Reshape, Flatten, BatchNormalization, LeakyReLU\n",
        "from tensorflow.keras.models import Sequential\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Define the generator\n",
        "def build_generator():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(256, input_dim=100))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(Dense(512))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(Dense(1024))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(Dense(28 * 28 * 1, activation='tanh'))\n",
        "    model.add(Reshape((28, 28, 1)))\n",
        "    return model\n",
        "\n",
        "# Define the discriminator\n",
        "def build_discriminator():\n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape=(28, 28, 1)))\n",
        "    model.add(Dense(512))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dense(256))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    return model\n",
        "\n",
        "# Build and compile the discriminator\n",
        "discriminator = build_discriminator()\n",
        "discriminator.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Build the generator\n",
        "generator = build_generator()\n",
        "\n",
        "# Define the combined GAN model\n",
        "z = tf.keras.Input(shape=(100,))\n",
        "img = generator(z)\n",
        "discriminator.trainable = False\n",
        "valid = discriminator(img)\n",
        "combined = tf.keras.Model(z, valid)\n",
        "combined.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "\n",
        "# Training the GAN\n",
        "(X_train, _), (_, _) = tf.keras.datasets.mnist.load_data()\n",
        "X_train = X_train / 127.5 - 1.0\n",
        "X_train = np.expand_dims(X_train, axis=3)\n",
        "batch_size = 64\n",
        "epochs = 100\n",
        "half_batch = batch_size // 2\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    # Train Discriminator\n",
        "    idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
        "    imgs = X_train[idx]\n",
        "    noise = np.random.normal(0, 1, (half_batch, 100))\n",
        "    gen_imgs = generator.predict(noise)\n",
        "    d_loss_real = discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n",
        "    d_loss_fake = discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n",
        "    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "    # Train Generator\n",
        "    noise = np.random.normal(0, 1, (batch_size, 100))\n",
        "    valid_y = np.array([1] * batch_size)\n",
        "    g_loss = combined.train_on_batch(noise, valid_y)\n",
        "\n",
        "    if epoch % 1000 == 0:\n",
        "        print(f\"{epoch} [D loss: {d_loss[0]}] [G loss: {g_loss}]\")\n",
        "\n",
        "\n",
        "def plot_generated_images(epoch, generator, examples=10, dim=(1, 10), figsize=(10, 1)):\n",
        "    noise = np.random.normal(0, 1, (examples, 100))\n",
        "    generated_images = generator.predict(noise)\n",
        "    generated_images = generated_images.reshape(examples, 28, 28)\n",
        "    plt.figure(figsize=figsize)\n",
        "    for i in range(examples):\n",
        "        plt.subplot(dim[0], dim[1], i+1)\n",
        "        plt.imshow(generated_images[i], interpolation='nearest', cmap='gray')\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'gan_generated_image_epoch_{epoch}.png')\n",
        "    plt.show()\n",
        "\n",
        "plot_generated_images(epochs, generator)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8k0j7ubDyAJN",
        "outputId": "f71bea97-2912-45a8-9924-17ce172b9282"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 120ms/step\n",
            "0 [D loss: 1.1080616116523743] [G loss: 0.8168544769287109]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 107ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x100 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Autoencoders and Variational Autoencoders (VAEs)**\n",
        "* Autoencoders compress data into a latent space and reconstruct it. VAEs add a probabilistic approach, ensuring a continuous latent space.\n",
        "\n",
        "**Example:** Basic autoencoder for MNIST"
      ],
      "metadata": {
        "id": "ZhpBPMvzy2uN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Define the encoder\n",
        "input_img = Input(shape=(784,))\n",
        "encoded = Dense(128, activation='relu')(input_img)\n",
        "encoded = Dense(64, activation='relu')(encoded)\n",
        "encoded = Dense(32, activation='relu')(encoded)\n",
        "\n",
        "# Define the decoder\n",
        "decoded = Dense(64, activation='relu')(encoded)\n",
        "decoded = Dense(128, activation='relu')(decoded)\n",
        "decoded = Dense(784, activation='sigmoid')(decoded)\n",
        "\n",
        "# Combine encoder and decoder into an autoencoder model\n",
        "autoencoder = Model(input_img, decoded)\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "# Create the encoder model\n",
        "encoder = Model(input_img, encoded) # Create the encoder model\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "(X_train, _), (X_test, _) = tf.keras.datasets.mnist.load_data()\n",
        "X_train = X_train.astype('float32') / 255.0\n",
        "X_test = X_test.astype('float32') / 255.0\n",
        "X_train = X_train.reshape((len(X_train), np.prod(X_train.shape[1:])))\n",
        "X_test = X_test.reshape((len(X_test), np.prod(X_test.shape[1:])))\n",
        "\n",
        "# Train the autoencoder\n",
        "autoencoder.fit(X_train, X_train, epochs=50, batch_size=256, shuffle=True, validation_data=(X_test, X_test))\n",
        "\n",
        "encoded_imgs = encoder.predict(X_test) # Now you can use the encoder model\n",
        "decoded_imgs = autoencoder.predict(X_test)\n",
        "\n",
        "n = 10  # Number of digits to display\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "    # Display original\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(X_test[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.axis('off')\n",
        "\n",
        "    # Display reconstruction\n",
        "    ax = plt.subplot(2, n, i + 1 + n)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "De_AZUUvyxcN",
        "outputId": "06d688de-fb6b-42c0-b2d5-8e607ceb33ea"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "235/235 [==============================] - 3s 6ms/step - loss: 0.2437 - val_loss: 0.1669\n",
            "Epoch 2/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.1499 - val_loss: 0.1360\n",
            "Epoch 3/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.1313 - val_loss: 0.1253\n",
            "Epoch 4/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.1232 - val_loss: 0.1193\n",
            "Epoch 5/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.1173 - val_loss: 0.1132\n",
            "Epoch 6/50\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 0.1123 - val_loss: 0.1092\n",
            "Epoch 7/50\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 0.1088 - val_loss: 0.1061\n",
            "Epoch 8/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.1065 - val_loss: 0.1041\n",
            "Epoch 9/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.1047 - val_loss: 0.1025\n",
            "Epoch 10/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.1032 - val_loss: 0.1009\n",
            "Epoch 11/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.1015 - val_loss: 0.0999\n",
            "Epoch 12/50\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 0.1002 - val_loss: 0.0982\n",
            "Epoch 13/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0989 - val_loss: 0.0975\n",
            "Epoch 14/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0978 - val_loss: 0.0963\n",
            "Epoch 15/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0970 - val_loss: 0.0956\n",
            "Epoch 16/50\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 0.0960 - val_loss: 0.0947\n",
            "Epoch 17/50\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.0952 - val_loss: 0.0938\n",
            "Epoch 18/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0944 - val_loss: 0.0936\n",
            "Epoch 19/50\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 0.0938 - val_loss: 0.0927\n",
            "Epoch 20/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0931 - val_loss: 0.0921\n",
            "Epoch 21/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0927 - val_loss: 0.0918\n",
            "Epoch 22/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0922 - val_loss: 0.0916\n",
            "Epoch 23/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0917 - val_loss: 0.0913\n",
            "Epoch 24/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0913 - val_loss: 0.0902\n",
            "Epoch 25/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0909 - val_loss: 0.0900\n",
            "Epoch 26/50\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 0.0905 - val_loss: 0.0901\n",
            "Epoch 27/50\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 0.0902 - val_loss: 0.0894\n",
            "Epoch 28/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0898 - val_loss: 0.0889\n",
            "Epoch 29/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0895 - val_loss: 0.0887\n",
            "Epoch 30/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0893 - val_loss: 0.0885\n",
            "Epoch 31/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0890 - val_loss: 0.0884\n",
            "Epoch 32/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0888 - val_loss: 0.0880\n",
            "Epoch 33/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0885 - val_loss: 0.0876\n",
            "Epoch 34/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0883 - val_loss: 0.0880\n",
            "Epoch 35/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0881 - val_loss: 0.0875\n",
            "Epoch 36/50\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 0.0880 - val_loss: 0.0873\n",
            "Epoch 37/50\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 0.0878 - val_loss: 0.0872\n",
            "Epoch 38/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0876 - val_loss: 0.0868\n",
            "Epoch 39/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0874 - val_loss: 0.0869\n",
            "Epoch 40/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0873 - val_loss: 0.0868\n",
            "Epoch 41/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0871 - val_loss: 0.0869\n",
            "Epoch 42/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0870 - val_loss: 0.0871\n",
            "Epoch 43/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0869 - val_loss: 0.0864\n",
            "Epoch 44/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0867 - val_loss: 0.0861\n",
            "Epoch 45/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0866 - val_loss: 0.0862\n",
            "Epoch 46/50\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 0.0865 - val_loss: 0.0859\n",
            "Epoch 47/50\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 0.0863 - val_loss: 0.0859\n",
            "Epoch 48/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0862 - val_loss: 0.0857\n",
            "Epoch 49/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0860 - val_loss: 0.0854\n",
            "Epoch 50/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0858 - val_loss: 0.0853\n",
            "313/313 [==============================] - 0s 1ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x400 with 20 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Variational Autoencoder Example:**\n",
        "\n"
      ],
      "metadata": {
        "id": "OVqvRGeJzITu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Lambda\n",
        "from tensorflow.keras import backend as K\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Define the sampling function\n",
        "def sampling(args):\n",
        "    z_mean, z_log_var = args\n",
        "    batch = K.shape(z_mean)[0]\n",
        "    dim = K.int_shape(z_mean)[1]\n",
        "    epsilon = K.random_normal(shape=(batch, dim))\n",
        "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "# Define the encoder\n",
        "input_img = Input(shape=(784,))\n",
        "h = Dense(128, activation='relu')(input_img)\n",
        "z_mean = Dense(2)(h)\n",
        "z_log_var = Dense(2)(h)\n",
        "\n",
        "z = Lambda(sampling, output_shape=(2,))([z_mean, z_log_var])\n",
        "\n",
        "# Define the decoder\n",
        "decoder_h = Dense(128, activation='relu')\n",
        "decoder_mean = Dense(784, activation='sigmoid')\n",
        "h_decoded = decoder_h(z)\n",
        "x_decoded_mean = decoder_mean(h_decoded)\n",
        "\n",
        "# Define the VAE model\n",
        "vae = Model(input_img, x_decoded_mean)\n",
        "\n",
        "# Define the loss\n",
        "def vae_loss(x, x_decoded_mean):\n",
        "    xent_loss = tf.keras.backend.binary_crossentropy(x, x_decoded_mean) # Use tf.keras.backend.binary_crossentropy\n",
        "    kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
        "    return K.mean(xent_loss + kl_loss) # Calculate mean of the sum of losses\n",
        "\n",
        "vae.compile(optimizer='adam', loss=vae_loss)\n",
        "\n",
        "# Train the VAE\n",
        "# vae.fit(X_train, X_train, epochs=50, batch_size=256, shuffle=True, validation_data=(X_test, X_test))\n"
      ],
      "metadata": {
        "id": "jxJ8Y9yDzOf9"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Attention Mechanism**\n",
        "* Attention mechanisms allow models to focus on relevant parts of the input sequence, crucial in tasks like machine translation.\n",
        "\n",
        "**Example:** Attention in Seq2Seq model"
      ],
      "metadata": {
        "id": "HqSjCttJzSLS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Attention\n",
        "\n",
        "# Define the encoder\n",
        "encoder_inputs = Input(shape=(None, 128))\n",
        "encoder_lstm = LSTM(128, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
        "\n",
        "# Define the decoder with attention\n",
        "decoder_inputs = Input(shape=(None, 128))\n",
        "decoder_lstm = LSTM(128, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=[state_h, state_c])\n",
        "\n",
        "# Apply attention\n",
        "attention = Attention()([decoder_outputs, encoder_outputs])\n",
        "decoder_concat_input = tf.keras.layers.Concatenate(axis=-1)([decoder_outputs, attention])\n",
        "\n",
        "# Define the output layer\n",
        "decoder_dense = Dense(128, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_concat_input)\n",
        "\n",
        "# Define the full model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "# model.fit([encoder_input_data, decoder_input_data], decoder_target_data, epochs=100)\n"
      ],
      "metadata": {
        "id": "IhqXoWxjzYdL"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Transformer**\n",
        "* Transformers are a type of model architecture that relies entirely on self-attention mechanisms and is widely used in NLP tasks.\n",
        "\n",
        "**Example:** Transformer for text classification"
      ],
      "metadata": {
        "id": "Uxq-mmjZzdre"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Embedding, Dense, Dropout, LayerNormalization, MultiHeadAttention, GlobalAveragePooling1D\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Define the transformer block\n",
        "def transformer_block(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
        "    attn_output = MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(inputs, inputs)\n",
        "    attn_output = LayerNormalization(epsilon=1e-6)(attn_output + inputs)\n",
        "    ffn_output = Dense(ff_dim, activation='relu')(attn_output)\n",
        "    ffn_output = Dense(inputs.shape[-1])(ffn_output)\n",
        "    ffn_output = LayerNormalization(epsilon=1e-6)(ffn_output + attn_output)\n",
        "    return ffn_output\n",
        "\n",
        "# Define the transformer model\n",
        "inputs = Input(shape=(None,))\n",
        "x = Embedding(input_dim=20000, output_dim=128)(inputs)\n",
        "x = transformer_block(x, head_size=128, num_heads=4, ff_dim=128, dropout=0.1)\n",
        "x = GlobalAveragePooling1D()(x)\n",
        "x = Dropout(0.1)(x)\n",
        "outputs = Dense(20, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs, outputs)\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Create some dummy data for demonstration purposes\n",
        "import numpy as np\n",
        "x_train = np.random.randint(20000, size=(100, 10))  # Replace with your actual training data\n",
        "y_train = np.random.randint(20, size=(100,))  # Replace with your actual training labels\n",
        "x_val = np.random.randint(20000, size=(20, 10))    # Replace with your actual validation data\n",
        "y_val = np.random.randint(20, size=(20,))      # Replace with your actual validation labels\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_val, y_val))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming 'history' is obtained from model.fit()\n",
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0, 1])\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        },
        "id": "nRTAdt4Qzi8R",
        "outputId": "b3051824-7b99-4ddf-dfc0-dc9867cf735a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "4/4 [==============================] - 6s 203ms/step - loss: 3.2088 - accuracy: 0.0700 - val_loss: 3.3486 - val_accuracy: 0.0500\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 2.0984 - accuracy: 0.3800 - val_loss: 3.2762 - val_accuracy: 0.1000\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 1.3016 - accuracy: 0.8800 - val_loss: 3.3743 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.7105 - accuracy: 1.0000 - val_loss: 3.4198 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.3351 - accuracy: 1.0000 - val_loss: 3.3805 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.1404 - accuracy: 1.0000 - val_loss: 3.3309 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 0.0705 - accuracy: 1.0000 - val_loss: 3.3001 - val_accuracy: 0.0500\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 0.0383 - accuracy: 1.0000 - val_loss: 3.2902 - val_accuracy: 0.0500\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0264 - accuracy: 1.0000 - val_loss: 3.2836 - val_accuracy: 0.1000\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 3.2816 - val_accuracy: 0.1000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Distributed Training**\n",
        "* Distributed training refers to training deep learning models across multiple devices (GPUs, TPUs) or machines. This approach helps in reducing training time by distributing the computation load.\n",
        "\n",
        "**Key Points:**\n",
        "\n",
        "* Enhances training efficiency and scalability.\n",
        "* Two main strategies: Data Parallelism and Model Parallelism.\n",
        "* TensorFlow 2.0 provides tf.distribute API to simplify distributed training.\n",
        "\n",
        "# **Using TensorFlow tf.distribute API**\n",
        "* The tf.distribute API in TensorFlow 2.0 provides a high-level interface for distributed training, making it easier to distribute models and training across multiple devices and machines.\n",
        "\n",
        "\n",
        "**Key Points:**\n",
        "\n",
        "* tf.distribute.Strategy is the main class.\n",
        "* Common strategies include MirroredStrategy, TPUStrategy, MultiWorkerMirroredStrategy, and CentralStorageStrategy.\n",
        "* Simplifies the implementation of both data and model parallelism.\n",
        "\n",
        "\n",
        "# **Data Parallelism**\n",
        "* Data parallelism involves splitting the training data across multiple devices and each device trains a copy of the model on a subset of the data. Gradients are then averaged and updated synchronously.\n",
        "\n",
        "**Key Points:**\n",
        "\n",
        "* Each device processes a different portion of the data.\n",
        "* Common approach for multi-GPU training.\n",
        "* Synchronization of gradients is crucial to ensure model consistency.\n",
        "\n",
        "\n",
        "**Example: Using tf.distribute.MirroredStrategy for data parallelism**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XskxblYc_Dlt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Create a MirroredStrategy\n",
        "strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "# Define the model inside the strategy scope\n",
        "with strategy.scope():\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Dense(128, activation='relu', input_shape=(784,)),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Load dataset\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Create a distributed dataset\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(64)\n",
        "train_dist_dataset = strategy.experimental_distribute_dataset(train_dataset)\n",
        "\n",
        "# Define the training step function\n",
        "@tf.function\n",
        "def train_step(inputs):\n",
        "    def step_fn(inputs):\n",
        "        images, labels = inputs\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = model(images, training=True)\n",
        "            loss = tf.keras.losses.sparse_categorical_crossentropy(labels, predictions)\n",
        "        gradients = tape.gradient(loss, model.trainable_variables)\n",
        "        model.optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "        return loss\n",
        "    per_replica_losses = strategy.run(step_fn, args=(inputs,))\n",
        "    return strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses, axis=None)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(10):\n",
        "    total_loss = 0.0\n",
        "    num_batches = 0\n",
        "    for batch in train_dist_dataset:\n",
        "        total_loss += train_step(batch)\n",
        "        num_batches += 1\n",
        "    train_loss = total_loss / num_batches\n",
        "    print(f'Epoch {epoch + 1}, Loss: {train_loss}')\n"
      ],
      "metadata": {
        "id": "mYKEXEyy4CwI"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Parallelism**\n",
        "* Model parallelism involves splitting the model itself across multiple devices, where different layers or operations run on different devices. This is beneficial for very large models that cannot fit into the memory of a single device.\n",
        "\n",
        "**Key Points:**\n",
        "\n",
        "* Useful for very large models.\n",
        "* Requires careful design to manage dependencies between model parts.\n",
        "* Can be more complex to implement compared to data parallelism.\n",
        "\n",
        "**Example: Manual model parallelism**"
      ],
      "metadata": {
        "id": "7yaKofnHAmaw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Manually assign different parts of the model to different devices\n",
        "with tf.device('/GPU:0'):\n",
        "    input_layer = tf.keras.layers.Input(shape=(28,28)) # Change input shape to (28,28)\n",
        "    flatten = tf.keras.layers.Flatten()(input_layer) # Add a Flatten layer\n",
        "    dense_1 = tf.keras.layers.Dense(128, activation='relu')(flatten)\n",
        "\n",
        "with tf.device('/GPU:1'):\n",
        "    dense_2 = tf.keras.layers.Dense(64, activation='relu')(dense_1)\n",
        "    output_layer = tf.keras.layers.Dense(10, activation='softmax')(dense_2)\n",
        "\n",
        "model = tf.keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Load dataset\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rO8f-38AEIX",
        "outputId": "d0c262c4-bf62-4c26-f22e-4e70ff9cecfa"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "938/938 [==============================] - 5s 3ms/step - loss: 0.2793 - accuracy: 0.9179\n",
            "Epoch 2/10\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 0.1147 - accuracy: 0.9658\n",
            "Epoch 3/10\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 0.0801 - accuracy: 0.9751\n",
            "Epoch 4/10\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 0.0597 - accuracy: 0.9814\n",
            "Epoch 5/10\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 0.0470 - accuracy: 0.9850\n",
            "Epoch 6/10\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 0.0388 - accuracy: 0.9875\n",
            "Epoch 7/10\n",
            "938/938 [==============================] - 3s 4ms/step - loss: 0.0320 - accuracy: 0.9900\n",
            "Epoch 8/10\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 0.0258 - accuracy: 0.9918\n",
            "Epoch 9/10\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 0.0221 - accuracy: 0.9926\n",
            "Epoch 10/10\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 0.0174 - accuracy: 0.9943\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d160073f430>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Optimization and Deployment in TensorFlow 2.0**\n",
        "\n",
        "**Model Optimization:**\n",
        "* Model optimization refers to techniques used to enhance the performance of a machine learning model, making it more efficient in terms of speed, memory usage, and power consumption.\n",
        "\n",
        "**Deployment:**\n",
        "* Model deployment is the process of making a trained machine learning model available for use in a production environment."
      ],
      "metadata": {
        "id": "pe4W5jxNV-lC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Optimization and Deployment Techniques**\n",
        "\n",
        "**Key Techniques:**\n",
        "\n",
        "* **Quantization:** Reducing the precision of the model's weights and activations.\n",
        "* **Pruning:** Removing unnecessary weights from the model.\n",
        "* **Mixed Precision Training:** Using both 16-bit and 32-bit floating-point types during training.\n",
        "* **Weight Clustering:** Grouping weights into clusters to reduce the number of unique weight values."
      ],
      "metadata": {
        "id": "nJChi_iHWNr8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example: Combining techniques**"
      ],
      "metadata": {
        "id": "s99f0quoW5aF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_model_optimization\n",
        "import tensorflow as tf\n",
        "from tensorflow_model_optimization.sparsity import keras as sparsity\n",
        "\n",
        "# Define a model\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(128, activation='relu', input_shape=(784,)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Quantization-aware training\n",
        "quant_aware_model = tf.keras.models.clone_model(model)\n",
        "quant_aware_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Pruning parameters\n",
        "pruning_params = {\n",
        "    'pruning_schedule': sparsity.PolynomialDecay(initial_sparsity=0.50, final_sparsity=0.90, begin_step=0, end_step=1000)\n",
        "}\n",
        "pruned_model = sparsity.prune_low_magnitude(model, **pruning_params)\n",
        "pruned_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Load dataset  # Load the MNIST dataset here\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train = x_train.reshape(-1, 784).astype('float32') / 255.0  # Reshape and normalize\n",
        "x_test = x_test.reshape(-1, 784).astype('float32') / 255.0    # Reshape and normalize\n",
        "\n",
        "# Train and save pruned model\n",
        "callbacks = [sparsity.UpdatePruningStep()]\n",
        "pruned_model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test), callbacks=callbacks)\n",
        "model_stripped = sparsity.strip_pruning(pruned_model)\n",
        "model_stripped.save('optimized_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7JQZpHYA1Xb",
        "outputId": "838b043a-4b93-46b4-a805-a680bec62376"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow_model_optimization in /usr/local/lib/python3.10/dist-packages (0.8.0)\n",
            "Requirement already satisfied: absl-py~=1.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow_model_optimization) (1.4.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow_model_optimization) (0.1.8)\n",
            "Requirement already satisfied: numpy~=1.23 in /usr/local/lib/python3.10/dist-packages (from tensorflow_model_optimization) (1.25.2)\n",
            "Requirement already satisfied: six~=1.14 in /usr/local/lib/python3.10/dist-packages (from tensorflow_model_optimization) (1.16.0)\n",
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 17s 7ms/step - loss: 0.3940 - accuracy: 0.8904 - val_loss: 0.2296 - val_accuracy: 0.9330\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.2097 - accuracy: 0.9385 - val_loss: 0.1796 - val_accuracy: 0.9437\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 13s 7ms/step - loss: 0.1703 - accuracy: 0.9498 - val_loss: 0.1545 - val_accuracy: 0.9517\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 13s 7ms/step - loss: 0.1453 - accuracy: 0.9572 - val_loss: 0.1412 - val_accuracy: 0.9573\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 18s 10ms/step - loss: 0.1272 - accuracy: 0.9618 - val_loss: 0.1284 - val_accuracy: 0.9616\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.1133 - accuracy: 0.9653 - val_loss: 0.1220 - val_accuracy: 0.9620\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 13s 7ms/step - loss: 0.1022 - accuracy: 0.9690 - val_loss: 0.1145 - val_accuracy: 0.9640\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0937 - accuracy: 0.9718 - val_loss: 0.1108 - val_accuracy: 0.9677\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0864 - accuracy: 0.9739 - val_loss: 0.1079 - val_accuracy: 0.9665\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0800 - accuracy: 0.9757 - val_loss: 0.1055 - val_accuracy: 0.9686\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py:3098: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Pruning**\n",
        "\n",
        "* Pruning involves removing less important weights from a neural network, reducing the model's complexity without significantly impacting accuracy.\n",
        "\n",
        "**Example: Pruning with TensorFlow Model Optimization Toolkit**"
      ],
      "metadata": {
        "id": "lxrtZQL4inMb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_model_optimization\n",
        "import tensorflow as tf\n",
        "from tensorflow_model_optimization.sparsity import keras as sparsity\n",
        "\n",
        "# Define a model\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(128, activation='relu', input_shape=(784,)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Define pruning parameters\n",
        "pruning_params = {\n",
        "    'pruning_schedule': sparsity.PolynomialDecay(initial_sparsity=0.30, final_sparsity=0.70, begin_step=2000, end_step=6000)\n",
        "}\n",
        "\n",
        "# Apply pruning\n",
        "pruned_model = sparsity.prune_low_magnitude(model, **pruning_params)\n",
        "pruned_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Load dataset  # Load the MNIST dataset here\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train = x_train.reshape(-1, 784).astype('float32') / 255.0  # Reshape and normalize\n",
        "x_test = x_test.reshape(-1, 784).astype('float32') / 255.0    # Reshape and normalize\n",
        "\n",
        "# Train and save the pruned model\n",
        "callbacks = [sparsity.UpdatePruningStep()]  # Add the callback here\n",
        "pruned_model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test), callbacks=callbacks)\n",
        "model_stripped = sparsity.strip_pruning(pruned_model)\n",
        "model_stripped.save('pruned_model.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQ_Hv2pYX8sF",
        "outputId": "2fb02972-4db5-4b20-ccaf-eb2b901f51a1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow_model_optimization in /usr/local/lib/python3.10/dist-packages (0.8.0)\n",
            "Requirement already satisfied: absl-py~=1.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow_model_optimization) (1.4.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow_model_optimization) (0.1.8)\n",
            "Requirement already satisfied: numpy~=1.23 in /usr/local/lib/python3.10/dist-packages (from tensorflow_model_optimization) (1.25.2)\n",
            "Requirement already satisfied: six~=1.14 in /usr/local/lib/python3.10/dist-packages (from tensorflow_model_optimization) (1.16.0)\n",
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 12s 5ms/step - loss: 0.2325 - accuracy: 0.9316 - val_loss: 0.1141 - val_accuracy: 0.9640\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0933 - accuracy: 0.9720 - val_loss: 0.0821 - val_accuracy: 0.9752\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0640 - accuracy: 0.9806 - val_loss: 0.0666 - val_accuracy: 0.9793\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0453 - accuracy: 0.9863 - val_loss: 0.0645 - val_accuracy: 0.9805\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0366 - accuracy: 0.9883 - val_loss: 0.0682 - val_accuracy: 0.9795\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0301 - accuracy: 0.9911 - val_loss: 0.0662 - val_accuracy: 0.9801\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0253 - accuracy: 0.9922 - val_loss: 0.0685 - val_accuracy: 0.9801\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0213 - accuracy: 0.9938 - val_loss: 0.0720 - val_accuracy: 0.9796\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0180 - accuracy: 0.9945 - val_loss: 0.0714 - val_accuracy: 0.9798\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0150 - accuracy: 0.9957 - val_loss: 0.0767 - val_accuracy: 0.9790\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py:3098: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Mixed Precision Training**\n",
        "* Mixed precision training uses both 16-bit (half precision) and 32-bit (single precision) floating-point types during model training. This can significantly speed up training and reduce memory usage on compatible hardware (like NVIDIA GPUs with Tensor Cores).\n",
        "\n",
        "**Example: Mixed precision training with TensorFlow**"
      ],
      "metadata": {
        "id": "-ZFNPIdU_HAm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Enable mixed precision\n",
        "policy = tf.keras.mixed_precision.Policy('mixed_float16')\n",
        "tf.keras.mixed_precision.set_global_policy(policy)\n",
        "\n",
        "# Define a model\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(128, activation='relu', input_shape=(784,)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax', dtype='float32')  # Use float32 for final layer\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyXxoC6d_Dtv",
        "outputId": "e190a3b4-7dfb-4255-c1ce-3753b0053870"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Mixed precision compatibility check (mixed_float16): WARNING\n",
            "The dtype policy mixed_float16 may run slowly because this machine does not have a GPU. Only Nvidia GPUs with compute capability of at least 7.0 run quickly with mixed_float16.\n",
            "If you will use compatible GPU(s) not attached to this host, e.g. by running a multi-worker model, you can ignore this warning. This message will only be logged once\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function create_autocast_variable at 0x7d5e777f9e10> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: <gast.gast.Expr object at 0x7d5e67a3ca90>\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function create_autocast_variable at 0x7d5e777f9e10> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: <gast.gast.Expr object at 0x7d5e67a3ca90>\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "1875/1875 [==============================] - 112s 55ms/step - loss: 0.2451 - accuracy: 0.9284 - val_loss: 0.1237 - val_accuracy: 0.9613\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 98s 52ms/step - loss: 0.1043 - accuracy: 0.9687 - val_loss: 0.0958 - val_accuracy: 0.9699\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 93s 49ms/step - loss: 0.0740 - accuracy: 0.9770 - val_loss: 0.0833 - val_accuracy: 0.9732\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 94s 50ms/step - loss: 0.0537 - accuracy: 0.9836 - val_loss: 0.0961 - val_accuracy: 0.9717\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 95s 51ms/step - loss: 0.0438 - accuracy: 0.9857 - val_loss: 0.0762 - val_accuracy: 0.9768\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 97s 52ms/step - loss: 0.0365 - accuracy: 0.9874 - val_loss: 0.0882 - val_accuracy: 0.9757\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 96s 51ms/step - loss: 0.0296 - accuracy: 0.9903 - val_loss: 0.1003 - val_accuracy: 0.9735\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 92s 49ms/step - loss: 0.0253 - accuracy: 0.9918 - val_loss: 0.0802 - val_accuracy: 0.9783\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 96s 51ms/step - loss: 0.0229 - accuracy: 0.9924 - val_loss: 0.0862 - val_accuracy: 0.9770\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 112s 60ms/step - loss: 0.0201 - accuracy: 0.9934 - val_loss: 0.0873 - val_accuracy: 0.9786\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf_keras.src.callbacks.History at 0x7d5e67e7a740>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TensorFlow Serving for Model Deployment**\n",
        "* TensorFlow Serving is a flexible, high-performance serving system for machine learning models designed for production environments.\n",
        "\n"
      ],
      "metadata": {
        "id": "Jx0D1lru_bJl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example: Serving a TensorFlow model**"
      ],
      "metadata": {
        "id": "xxOCF7SOA7mI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1-Save the model in the SavedModel format:**"
      ],
      "metadata": {
        "id": "EIj0LLeyA_df"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('saved_model/1/')"
      ],
      "metadata": {
        "id": "eAMlhT2r_fCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2-Start TensorFlow Serving:**"
      ],
      "metadata": {
        "id": "zDFLenmHBD7L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "docker pull tensorflow/serving\n",
        "docker run -p 8501:8501 --name=tf_serving --mount type=bind,source=$(pwd)/saved_model,target=/models/my_model -e MODEL_NAME=my_model -t tensorflow/serving"
      ],
      "metadata": {
        "id": "DuvQsDjiBHHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3-Make predictions using the REST API:**"
      ],
      "metadata": {
        "id": "U0uNidU5BJLI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "import numpy as np\n",
        "\n",
        "data = json.dumps({\"signature_name\": \"serving_default\", \"instances\": x_test[:5].tolist()})\n",
        "headers = {\"content-type\": \"application/json\"}\n",
        "json_response = requests.post('http://localhost:8501/v1/models/my_model:predict', data=data, headers=headers)\n",
        "predictions = np.array(json.loads(json_response.text)[\"predictions\"])\n",
        "print(predictions)\n"
      ],
      "metadata": {
        "id": "rwNSzJR2BL_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. What is a Custom Layer?**\n",
        "\n",
        "* A custom layer in TensorFlow is a user-defined layer that extends the base functionality provided by TensorFlow's existing layers. Custom layers allow you to implement and encapsulate specific operations or logic that are not available in the standard library.\n",
        "\n",
        "# **2. Writing Custom Layers**\n",
        "* To write a custom layer in TensorFlow, you need to subclass the tf.keras.layers.Layer class and implement the build and call methods.\n",
        "\n",
        "**Example: Creating a Custom Layer**\n",
        "\n",
        "* This example demonstrates creating a custom dense layer with a custom activation function."
      ],
      "metadata": {
        "id": "IJQuKwV3eNve"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class CustomDenseLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, units=32, activation=None):\n",
        "        super(CustomDenseLayer, self).__init__()\n",
        "        self.units = units\n",
        "        self.activation = tf.keras.activations.get(activation)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.w = self.add_weight(shape=(input_shape[-1], self.units),\n",
        "                                 initializer='random_normal',\n",
        "                                 trainable=True)\n",
        "        self.b = self.add_weight(shape=(self.units,),\n",
        "                                 initializer='zeros',\n",
        "                                 trainable=True)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        z = tf.matmul(inputs, self.w) + self.b\n",
        "        if self.activation is not None:\n",
        "            return self.activation(z)\n",
        "        return z\n",
        "\n",
        "# Usage example\n",
        "model = tf.keras.Sequential([\n",
        "    CustomDenseLayer(64, activation='relu'),\n",
        "    CustomDenseLayer(10)\n",
        "])\n",
        "\n",
        "# Compile and train the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "ZL4yIdMnebNw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Writing Custom Models**\n",
        "* To create a custom model, you need to subclass the tf.keras.Model class and define the __init__ and call methods.\n",
        "\n",
        "**Example: Creating a Custom Model**\n",
        "\n",
        "* This example demonstrates creating a custom model that uses the custom dense layer defined above.\n",
        "\n"
      ],
      "metadata": {
        "id": "zLNBQB2tecL7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomModel(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(CustomModel, self).__init__()\n",
        "        self.layer1 = CustomDenseLayer(64, activation='relu')\n",
        "        self.layer2 = CustomDenseLayer(10)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.layer1(inputs)\n",
        "        return self.layer2(x)\n",
        "\n",
        "# Usage example\n",
        "model = CustomModel()\n",
        "\n",
        "# Compile and train the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "LNpwYtD0ekl5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Custom Training Loops with tf.GradientTape**\n",
        "* TensorFlow 2.0 provides the tf.GradientTape API for more control over the training loop, allowing for custom training workflows.\n",
        "\n",
        "**Example: Custom Training Loop**\n",
        "\n",
        "* This example demonstrates a custom training loop using tf.GradientTape."
      ],
      "metadata": {
        "id": "kSS-YmDtelsm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class CustomDenseLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, units=32, activation=None):\n",
        "        super(CustomDenseLayer, self).__init__()\n",
        "        self.units = units\n",
        "        self.activation = tf.keras.activations.get(activation)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.w = self.add_weight(shape=(input_shape[-1], self.units),\n",
        "                                 initializer='random_normal',\n",
        "                                 trainable=True)\n",
        "        self.b = self.add_weight(shape=(self.units,),\n",
        "                                 initializer='zeros',\n",
        "                                 trainable=True)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        z = tf.matmul(inputs, self.w) + self.b\n",
        "        if self.activation is not None:\n",
        "            return self.activation(z)\n",
        "        return z\n",
        "\n",
        "class CustomModel(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(CustomModel, self).__init__()\n",
        "        self.layer1 = CustomDenseLayer(64, activation='relu')\n",
        "        self.layer2 = CustomDenseLayer(10)\n",
        "        # Add a flattening layer to reshape the input\n",
        "        self.flatten = tf.keras.layers.Flatten()\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.flatten(inputs) # Flatten the input before passing to dense layers\n",
        "        x = self.layer1(x)\n",
        "        return self.layer2(x)\n",
        "\n",
        "# Usage example\n",
        "model = CustomModel()\n",
        "\n",
        "# Compile and train the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "# Define metrics to track loss and accuracy\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
        "\n",
        "@tf.function\n",
        "def train_step(inputs, labels):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(inputs, training=True)\n",
        "        loss = loss_object(labels, predictions)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "    train_loss(loss)\n",
        "    train_accuracy(labels, predictions)\n",
        "\n",
        "# Load and preprocess data\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(60000).batch(32)\n",
        "\n",
        "# Training loop\n",
        "EPOCHS = 5\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    for images, labels in train_dataset:\n",
        "        train_step(images, labels)\n",
        "\n",
        "    print(f'Epoch {epoch + 1}, Loss: {train_loss.result()}, Accuracy: {train_accuracy.result() * 100}')\n",
        "    train_loss.reset_states()\n",
        "    train_accuracy.reset_states()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9M8nl_DeuTr",
        "outputId": "9c7d13cb-2aa3-4581-fcce-acc5ce5a2649"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: nan, Accuracy: 10.336666107177734\n",
            "Epoch 2, Loss: nan, Accuracy: 9.87166690826416\n",
            "Epoch 3, Loss: nan, Accuracy: 9.87166690826416\n",
            "Epoch 4, Loss: nan, Accuracy: 9.87166690826416\n",
            "Epoch 5, Loss: nan, Accuracy: 9.87166690826416\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Introduction to TFX (TensorFlow Extended)**\n",
        "\n",
        "* TensorFlow Extended (TFX) is an end-to-end platform for deploying production machine learning (ML) pipelines. It provides a comprehensive set of components and libraries to integrate all the steps in the ML lifecycle, from data ingestion, data validation, and model training to model evaluation, model analysis, and model serving.\n",
        "\n",
        "**Components of TFX:**\n",
        "\n",
        "* **TensorFlow Data Validation (TFDV):** For data validation.\n",
        "* **TensorFlow Transform (TFT):** For data preprocessing.\n",
        "* **TensorFlow Model Analysis (TFMA):** For model evaluation.\n",
        "* **TensorFlow Serving:** For model deployment.\n",
        "\n",
        "# **2. Data Validation**\n",
        "* **TensorFlow Data Validation (TFDV):**\n",
        "* TFDV is a library for exploring and validating machine learning data. It allows you to understand the characteristics of your data and ensure it meets the requirements of your ML pipeline.\n",
        "\n",
        "**Example: Using TFDV for Data Validation**"
      ],
      "metadata": {
        "id": "XhM__zLQgLB7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_data_validation\n",
        "import tensorflow_data_validation as tfdv\n",
        "\n",
        "!pip install tensorflow_data_validation\n",
        "import tensorflow_data_validation as tfdv\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Load the iris dataset as a pandas DataFrame\n",
        "iris = load_iris()\n",
        "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
        "df['target'] = iris.target\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "df.to_csv('iris_data.csv', index=False)\n",
        "\n",
        "# Generate statistics from the CSV file\n",
        "stats = tfdv.generate_statistics_from_csv(data_location='iris_data.csv')\n",
        "\n",
        "# Infer schema from statistics\n",
        "schema = tfdv.infer_schema(stats)\n",
        "\n",
        "# Display the schema\n",
        "tfdv.display_schema(schema)\n",
        "\n",
        "# Generate statistics from data\n",
        "stats = tfdv.generate_statistics_from_csv(data_location='iris_data.csv')\n",
        "\n",
        "# Infer schema from statistics\n",
        "schema = tfdv.infer_schema(stats)\n",
        "\n",
        "# Display the schema\n",
        "tfdv.display_schema(schema)\n",
        "\n",
        "# Validate statistics against the schema\n",
        "anomalies = tfdv.validate_statistics(stats, schema)\n",
        "\n",
        "# Display anomalies\n",
        "tfdv.display_anomalies(anomalies)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UtZ5Ekyje9J-",
        "outputId": "bc1f4881-ef9e-4c1c-b25e-67a531291537"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow_data_validation in /usr/local/lib/python3.10/dist-packages (1.15.1)\n",
            "Requirement already satisfied: absl-py<2.0.0,>=0.9 in /usr/local/lib/python3.10/dist-packages (from tensorflow_data_validation) (1.4.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_data_validation) (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_data_validation) (1.25.2)\n",
            "Requirement already satisfied: pandas<2,>=1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_data_validation) (1.5.3)\n",
            "Requirement already satisfied: pyarrow<11,>=10 in /usr/local/lib/python3.10/dist-packages (from tensorflow_data_validation) (10.0.1)\n",
            "Requirement already satisfied: pyfarmhash<0.4,>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow_data_validation) (0.3.2)\n",
            "Requirement already satisfied: six<2,>=1.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow_data_validation) (1.16.0)\n",
            "Requirement already satisfied: tensorflow<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow_data_validation) (2.15.1)\n",
            "Requirement already satisfied: tensorflow-metadata<1.16,>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_data_validation) (1.15.0)\n",
            "Requirement already satisfied: tfx-bsl<1.16,>=1.15.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow_data_validation) (1.15.1)\n",
            "Requirement already satisfied: apache-beam[gcp]<3,>=2.47 in /usr/local/lib/python3.10/dist-packages (from tensorflow_data_validation) (2.56.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow_data_validation) (3.20.3)\n",
            "Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (1.7)\n",
            "Requirement already satisfied: orjson<4,>=3.9.7 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (3.10.5)\n",
            "Requirement already satisfied: dill<0.3.2,>=0.3.1.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.3.1.1)\n",
            "Requirement already satisfied: cloudpickle~=2.2.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.2.1)\n",
            "Requirement already satisfied: fastavro<2,>=0.23.6 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (1.9.4)\n",
            "Requirement already satisfied: fasteners<1.0,>=0.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.19)\n",
            "Requirement already satisfied: grpcio!=1.48.0,!=1.59.*,!=1.60.*,!=1.61.*,!=1.62.0,!=1.62.1,<2,>=1.33.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (1.64.1)\n",
            "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.7.3)\n",
            "Requirement already satisfied: httplib2<0.23.0,>=0.8 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.22.0)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (4.19.2)\n",
            "Requirement already satisfied: jsonpickle<4.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (3.2.2)\n",
            "Requirement already satisfied: objsize<0.8.0,>=0.6.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.7.0)\n",
            "Requirement already satisfied: packaging>=22.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (24.1)\n",
            "Requirement already satisfied: pymongo<5.0.0,>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (4.7.3)\n",
            "Requirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (1.24.0)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2018.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2023.4)\n",
            "Requirement already satisfied: redis<6,>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (5.0.7)\n",
            "Requirement already satisfied: regex>=2020.6.8 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2024.5.15)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (4.12.2)\n",
            "Requirement already satisfied: zstandard<1,>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.22.0)\n",
            "Requirement already satisfied: pyarrow-hotfix<1 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.6)\n",
            "Requirement already satisfied: js2py<1,>=0.74 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.74)\n",
            "Requirement already satisfied: cachetools<6,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (5.3.3)\n",
            "Requirement already satisfied: google-api-core<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.19.1)\n",
            "Requirement already satisfied: google-apitools<0.5.32,>=0.5.31 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.5.31)\n",
            "Requirement already satisfied: google-auth<3,>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.27.0)\n",
            "Requirement already satisfied: google-auth-httplib2<0.3.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.1.1)\n",
            "Requirement already satisfied: google-cloud-datastore<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.15.2)\n",
            "Requirement already satisfied: google-cloud-pubsub<3,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.21.5)\n",
            "Requirement already satisfied: google-cloud-pubsublite<2,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (1.10.0)\n",
            "Requirement already satisfied: google-cloud-storage<3,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.17.0)\n",
            "Requirement already satisfied: google-cloud-bigquery<4,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (3.21.0)\n",
            "Requirement already satisfied: google-cloud-bigquery-storage<3,>=2.6.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.25.0)\n",
            "Requirement already satisfied: google-cloud-core<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.3.3)\n",
            "Requirement already satisfied: google-cloud-bigtable<3,>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.24.0)\n",
            "Requirement already satisfied: google-cloud-spanner<4,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (3.47.0)\n",
            "Requirement already satisfied: google-cloud-dlp<4,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (3.18.0)\n",
            "Requirement already satisfied: google-cloud-language<3,>=2.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.13.3)\n",
            "Requirement already satisfied: google-cloud-videointelligence<3,>=2.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.13.3)\n",
            "Requirement already satisfied: google-cloud-vision<4,>=2 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (3.7.2)\n",
            "Requirement already satisfied: google-cloud-recommendations-ai<0.11.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.10.10)\n",
            "Requirement already satisfied: google-cloud-aiplatform<2.0,>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (1.56.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tensorflow_data_validation) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tensorflow_data_validation) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tensorflow_data_validation) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tensorflow_data_validation) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tensorflow_data_validation) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tensorflow_data_validation) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tensorflow_data_validation) (0.3.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tensorflow_data_validation) (3.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tensorflow_data_validation) (67.7.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tensorflow_data_validation) (2.4.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tensorflow_data_validation) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tensorflow_data_validation) (0.37.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tensorflow_data_validation) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tensorflow_data_validation) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tensorflow_data_validation) (2.15.0)\n",
            "Requirement already satisfied: google-api-python-client<2,>=1.7.11 in /usr/local/lib/python3.10/dist-packages (from tfx-bsl<1.16,>=1.15.1->tensorflow_data_validation) (1.12.11)\n",
            "Requirement already satisfied: tensorflow-serving-api<3,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tfx-bsl<1.16,>=1.15.1->tensorflow_data_validation) (2.15.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.16,>=2.15->tensorflow_data_validation) (0.43.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3,>=2.0.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (1.63.1)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client<2,>=1.7.11->tfx-bsl<1.16,>=1.15.1->tensorflow_data_validation) (3.0.1)\n",
            "Requirement already satisfied: oauth2client>=1.4.12 in /usr/local/lib/python3.10/dist-packages (from google-apitools<0.5.32,>=0.5.31->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (4.1.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.18.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.18.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (4.9)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0,>=1.26.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (1.12.3)\n",
            "Requirement already satisfied: shapely<3.0.0dev in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0,>=1.26.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.0.4)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0,>=1.26.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.7.4)\n",
            "Requirement already satisfied: docstring-parser<1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0,>=1.26.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.16)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery<4,>=2.0.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.7.1)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigtable<3,>=2.19.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.13.0)\n",
            "Requirement already satisfied: grpcio-status>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-pubsub<3,>=2.1.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (1.48.2)\n",
            "Requirement already satisfied: overrides<8.0.0,>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-pubsublite<2,>=1.2.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (7.7.0)\n",
            "Requirement already satisfied: sqlparse>=0.4.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-spanner<4,>=3.0.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.5.0)\n",
            "Requirement already satisfied: grpc-interceptor>=0.15.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-spanner<4,>=3.0.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.15.4)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage<3,>=2.14.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (1.5.0)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.10/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.6.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<0.23.0,>=0.8->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (3.1.2)\n",
            "Requirement already satisfied: tzlocal>=1.2 in /usr/local/lib/python3.10/dist-packages (from js2py<1,>=0.74->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (5.2)\n",
            "Requirement already satisfied: pyjsparser>=2.5.1 in /usr/local/lib/python3.10/dist-packages (from js2py<1,>=0.74->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.7.1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.18.1)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from pymongo<5.0.0,>=3.8.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.6.1)\n",
            "Requirement already satisfied: async-timeout>=4.0.3 in /usr/local/lib/python3.10/dist-packages (from redis<6,>=5.0.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2024.6.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tensorflow_data_validation) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tensorflow_data_validation) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tensorflow_data_validation) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tensorflow_data_validation) (3.0.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tensorflow_data_validation) (1.3.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from oauth2client>=1.4.12->google-apitools<0.5.32,>=0.5.31->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.6.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3->google-cloud-aiplatform<2.0,>=1.26.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3->google-cloud-aiplatform<2.0,>=1.26.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.18.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tensorflow_data_validation) (2.1.5)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tensorflow_data_validation) (3.2.2)\n",
            "Requirement already satisfied: tensorflow_data_validation in /usr/local/lib/python3.10/dist-packages (1.15.1)\n",
            "Requirement already satisfied: absl-py<2.0.0,>=0.9 in /usr/local/lib/python3.10/dist-packages (from tensorflow_data_validation) (1.4.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_data_validation) (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_data_validation) (1.25.2)\n",
            "Requirement already satisfied: pandas<2,>=1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_data_validation) (1.5.3)\n",
            "Requirement already satisfied: pyarrow<11,>=10 in /usr/local/lib/python3.10/dist-packages (from tensorflow_data_validation) (10.0.1)\n",
            "Requirement already satisfied: pyfarmhash<0.4,>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow_data_validation) (0.3.2)\n",
            "Requirement already satisfied: six<2,>=1.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow_data_validation) (1.16.0)\n",
            "Requirement already satisfied: tensorflow<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow_data_validation) (2.15.1)\n",
            "Requirement already satisfied: tensorflow-metadata<1.16,>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_data_validation) (1.15.0)\n",
            "Requirement already satisfied: tfx-bsl<1.16,>=1.15.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow_data_validation) (1.15.1)\n",
            "Requirement already satisfied: apache-beam[gcp]<3,>=2.47 in /usr/local/lib/python3.10/dist-packages (from tensorflow_data_validation) (2.56.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow_data_validation) (3.20.3)\n",
            "Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (1.7)\n",
            "Requirement already satisfied: orjson<4,>=3.9.7 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (3.10.5)\n",
            "Requirement already satisfied: dill<0.3.2,>=0.3.1.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.3.1.1)\n",
            "Requirement already satisfied: cloudpickle~=2.2.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.2.1)\n",
            "Requirement already satisfied: fastavro<2,>=0.23.6 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (1.9.4)\n",
            "Requirement already satisfied: fasteners<1.0,>=0.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.19)\n",
            "Requirement already satisfied: grpcio!=1.48.0,!=1.59.*,!=1.60.*,!=1.61.*,!=1.62.0,!=1.62.1,<2,>=1.33.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (1.64.1)\n",
            "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.7.3)\n",
            "Requirement already satisfied: httplib2<0.23.0,>=0.8 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.22.0)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (4.19.2)\n",
            "Requirement already satisfied: jsonpickle<4.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (3.2.2)\n",
            "Requirement already satisfied: objsize<0.8.0,>=0.6.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.7.0)\n",
            "Requirement already satisfied: packaging>=22.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (24.1)\n",
            "Requirement already satisfied: pymongo<5.0.0,>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (4.7.3)\n",
            "Requirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (1.24.0)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2018.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2023.4)\n",
            "Requirement already satisfied: redis<6,>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (5.0.7)\n",
            "Requirement already satisfied: regex>=2020.6.8 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2024.5.15)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (4.12.2)\n",
            "Requirement already satisfied: zstandard<1,>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.22.0)\n",
            "Requirement already satisfied: pyarrow-hotfix<1 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.6)\n",
            "Requirement already satisfied: js2py<1,>=0.74 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.74)\n",
            "Requirement already satisfied: cachetools<6,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (5.3.3)\n",
            "Requirement already satisfied: google-api-core<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.19.1)\n",
            "Requirement already satisfied: google-apitools<0.5.32,>=0.5.31 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.5.31)\n",
            "Requirement already satisfied: google-auth<3,>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.27.0)\n",
            "Requirement already satisfied: google-auth-httplib2<0.3.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.1.1)\n",
            "Requirement already satisfied: google-cloud-datastore<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.15.2)\n",
            "Requirement already satisfied: google-cloud-pubsub<3,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.21.5)\n",
            "Requirement already satisfied: google-cloud-pubsublite<2,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (1.10.0)\n",
            "Requirement already satisfied: google-cloud-storage<3,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.17.0)\n",
            "Requirement already satisfied: google-cloud-bigquery<4,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (3.21.0)\n",
            "Requirement already satisfied: google-cloud-bigquery-storage<3,>=2.6.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.25.0)\n",
            "Requirement already satisfied: google-cloud-core<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.3.3)\n",
            "Requirement already satisfied: google-cloud-bigtable<3,>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.24.0)\n",
            "Requirement already satisfied: google-cloud-spanner<4,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (3.47.0)\n",
            "Requirement already satisfied: google-cloud-dlp<4,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (3.18.0)\n",
            "Requirement already satisfied: google-cloud-language<3,>=2.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.13.3)\n",
            "Requirement already satisfied: google-cloud-videointelligence<3,>=2.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.13.3)\n",
            "Requirement already satisfied: google-cloud-vision<4,>=2 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (3.7.2)\n",
            "Requirement already satisfied: google-cloud-recommendations-ai<0.11.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.10.10)\n",
            "Requirement already satisfied: google-cloud-aiplatform<2.0,>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (1.56.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tensorflow_data_validation) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tensorflow_data_validation) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tensorflow_data_validation) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tensorflow_data_validation) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tensorflow_data_validation) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tensorflow_data_validation) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tensorflow_data_validation) (0.3.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tensorflow_data_validation) (3.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tensorflow_data_validation) (67.7.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tensorflow_data_validation) (2.4.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tensorflow_data_validation) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tensorflow_data_validation) (0.37.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tensorflow_data_validation) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tensorflow_data_validation) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tensorflow_data_validation) (2.15.0)\n",
            "Requirement already satisfied: google-api-python-client<2,>=1.7.11 in /usr/local/lib/python3.10/dist-packages (from tfx-bsl<1.16,>=1.15.1->tensorflow_data_validation) (1.12.11)\n",
            "Requirement already satisfied: tensorflow-serving-api<3,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tfx-bsl<1.16,>=1.15.1->tensorflow_data_validation) (2.15.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.16,>=2.15->tensorflow_data_validation) (0.43.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3,>=2.0.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (1.63.1)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client<2,>=1.7.11->tfx-bsl<1.16,>=1.15.1->tensorflow_data_validation) (3.0.1)\n",
            "Requirement already satisfied: oauth2client>=1.4.12 in /usr/local/lib/python3.10/dist-packages (from google-apitools<0.5.32,>=0.5.31->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (4.1.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.18.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.18.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (4.9)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0,>=1.26.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (1.12.3)\n",
            "Requirement already satisfied: shapely<3.0.0dev in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0,>=1.26.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.0.4)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0,>=1.26.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.7.4)\n",
            "Requirement already satisfied: docstring-parser<1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0,>=1.26.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.16)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery<4,>=2.0.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.7.1)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigtable<3,>=2.19.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.13.0)\n",
            "Requirement already satisfied: grpcio-status>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-pubsub<3,>=2.1.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (1.48.2)\n",
            "Requirement already satisfied: overrides<8.0.0,>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-pubsublite<2,>=1.2.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (7.7.0)\n",
            "Requirement already satisfied: sqlparse>=0.4.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-spanner<4,>=3.0.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.5.0)\n",
            "Requirement already satisfied: grpc-interceptor>=0.15.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-spanner<4,>=3.0.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.15.4)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage<3,>=2.14.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (1.5.0)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.10/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.6.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<0.23.0,>=0.8->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (3.1.2)\n",
            "Requirement already satisfied: tzlocal>=1.2 in /usr/local/lib/python3.10/dist-packages (from js2py<1,>=0.74->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (5.2)\n",
            "Requirement already satisfied: pyjsparser>=2.5.1 in /usr/local/lib/python3.10/dist-packages (from js2py<1,>=0.74->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.7.1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.18.1)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from pymongo<5.0.0,>=3.8.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.6.1)\n",
            "Requirement already satisfied: async-timeout>=4.0.3 in /usr/local/lib/python3.10/dist-packages (from redis<6,>=5.0.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2024.6.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tensorflow_data_validation) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tensorflow_data_validation) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tensorflow_data_validation) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tensorflow_data_validation) (3.0.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tensorflow_data_validation) (1.3.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from oauth2client>=1.4.12->google-apitools<0.5.32,>=0.5.31->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.6.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3->google-cloud-aiplatform<2.0,>=1.26.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3->google-cloud-aiplatform<2.0,>=1.26.0->apache-beam[gcp]<3,>=2.47->tensorflow_data_validation) (2.18.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tensorflow_data_validation) (2.1.5)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tensorflow_data_validation) (3.2.2)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                      Type  Presence Valency Domain\n",
              "Feature name                                       \n",
              "'sepal length (cm)'  FLOAT  required              -\n",
              "'sepal width (cm)'   FLOAT  required              -\n",
              "'petal length (cm)'  FLOAT  required              -\n",
              "'petal width (cm)'   FLOAT  required              -\n",
              "'target'               INT  required              -"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3656bf71-ee78-41da-bd9c-8b31f95b7058\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Type</th>\n",
              "      <th>Presence</th>\n",
              "      <th>Valency</th>\n",
              "      <th>Domain</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feature name</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>'sepal length (cm)'</th>\n",
              "      <td>FLOAT</td>\n",
              "      <td>required</td>\n",
              "      <td></td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>'sepal width (cm)'</th>\n",
              "      <td>FLOAT</td>\n",
              "      <td>required</td>\n",
              "      <td></td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>'petal length (cm)'</th>\n",
              "      <td>FLOAT</td>\n",
              "      <td>required</td>\n",
              "      <td></td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>'petal width (cm)'</th>\n",
              "      <td>FLOAT</td>\n",
              "      <td>required</td>\n",
              "      <td></td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>'target'</th>\n",
              "      <td>INT</td>\n",
              "      <td>required</td>\n",
              "      <td></td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3656bf71-ee78-41da-bd9c-8b31f95b7058')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3656bf71-ee78-41da-bd9c-8b31f95b7058 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3656bf71-ee78-41da-bd9c-8b31f95b7058');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b2efad04-d064-4684-ab01-e2e90bd754a9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b2efad04-d064-4684-ab01-e2e90bd754a9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b2efad04-d064-4684-ab01-e2e90bd754a9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"tfdv\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Feature name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"'sepal width (cm)'\",\n          \"'target'\",\n          \"'petal length (cm)'\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"INT\",\n          \"FLOAT\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Presence\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"required\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Valency\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Domain\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"-\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                      Type  Presence Valency Domain\n",
              "Feature name                                       \n",
              "'sepal length (cm)'  FLOAT  required              -\n",
              "'sepal width (cm)'   FLOAT  required              -\n",
              "'petal length (cm)'  FLOAT  required              -\n",
              "'petal width (cm)'   FLOAT  required              -\n",
              "'target'               INT  required              -"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3b707bc8-d2ab-435a-8b41-202119be119d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Type</th>\n",
              "      <th>Presence</th>\n",
              "      <th>Valency</th>\n",
              "      <th>Domain</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feature name</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>'sepal length (cm)'</th>\n",
              "      <td>FLOAT</td>\n",
              "      <td>required</td>\n",
              "      <td></td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>'sepal width (cm)'</th>\n",
              "      <td>FLOAT</td>\n",
              "      <td>required</td>\n",
              "      <td></td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>'petal length (cm)'</th>\n",
              "      <td>FLOAT</td>\n",
              "      <td>required</td>\n",
              "      <td></td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>'petal width (cm)'</th>\n",
              "      <td>FLOAT</td>\n",
              "      <td>required</td>\n",
              "      <td></td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>'target'</th>\n",
              "      <td>INT</td>\n",
              "      <td>required</td>\n",
              "      <td></td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3b707bc8-d2ab-435a-8b41-202119be119d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3b707bc8-d2ab-435a-8b41-202119be119d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3b707bc8-d2ab-435a-8b41-202119be119d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3d8a61ee-50c2-4b66-b261-7abc29772658\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3d8a61ee-50c2-4b66-b261-7abc29772658')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3d8a61ee-50c2-4b66-b261-7abc29772658 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"tfdv\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Feature name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"'sepal width (cm)'\",\n          \"'target'\",\n          \"'petal length (cm)'\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"INT\",\n          \"FLOAT\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Presence\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"required\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Valency\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Domain\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"-\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<h4 style=\"color:green;\">No anomalies found.</h4>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Model Analysis**\n",
        "* **TensorFlow Model Analysis (TFMA):**\n",
        " * TFMA is a library for evaluating TensorFlow models. It allows you to evaluate the performance of your models in a scalable and flexible way.\n",
        "\n",
        "**Example: Using TFMA for Model Analysis**"
      ],
      "metadata": {
        "id": "jIKpoilVgi02"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install TensorFlow Model Analysis\n",
        "# !pip install tensorflow_model_analysis\n",
        "\n",
        "import tensorflow_model_analysis as tfma\n",
        "import tensorflow as tf\n",
        "\n",
        "# Convert CSV data to TFRecords\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "import tempfile\n",
        "\n",
        "# Load the iris dataset as a pandas DataFrame\n",
        "iris = load_iris()\n",
        "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
        "df['label'] = iris.target  # Use 'label' as the label key\n",
        "\n",
        "# Convert the 'label' column to integers\n",
        "df['label'] = df['label'].astype(int)\n",
        "\n",
        "# Save the DataFrame to a temporary CSV file\n",
        "temp_csv = tempfile.NamedTemporaryFile(suffix='.csv', delete=False)\n",
        "df.to_csv(temp_csv.name, index=False)\n",
        "\n",
        "# Convert CSV to TFRecords\n",
        "def to_tfrecords(csv_path, tfrecords_path):\n",
        "    with tf.io.TFRecordWriter(tfrecords_path) as writer:\n",
        "        for _, row in pd.read_csv(csv_path).iterrows():\n",
        "            example = tf.train.Example(\n",
        "                features=tf.train.Features(\n",
        "                    feature={\n",
        "                        'sepal length (cm)': tf.train.Feature(float_list=tf.train.FloatList(value=[row['sepal length (cm)']])),\n",
        "                        'sepal width (cm)': tf.train.Feature(float_list=tf.train.FloatList(value=[row['sepal width (cm)']])),\n",
        "                        'petal length (cm)': tf.train.Feature(float_list=tf.train.FloatList(value=[row['petal length (cm)']])),\n",
        "                        'petal width (cm)': tf.train.Feature(float_list=tf.train.FloatList(value=[row['petal width (cm)']])),\n",
        "                        'label': tf.train.Feature(int64_list=tf.train.Int64List(value=[int(row['label'])]))  # Cast label to int\n",
        "                    }\n",
        "                )\n",
        "            )\n",
        "            writer.write(example.SerializeToString())\n",
        "\n",
        "# Create a temporary TFRecord file\n",
        "temp_tfrecords = tempfile.NamedTemporaryFile(suffix='.tfrecords', delete=False)\n",
        "to_tfrecords(temp_csv.name, temp_tfrecords.name)\n",
        "\n",
        "# Define feature description for parsing the TFRecord file\n",
        "feature_description = {\n",
        "    'sepal length (cm)': tf.io.FixedLenFeature([], tf.float32),\n",
        "    'sepal width (cm)': tf.io.FixedLenFeature([], tf.float32),\n",
        "    'petal length (cm)': tf.io.FixedLenFeature([], tf.float32),\n",
        "    'petal width (cm)': tf.io.FixedLenFeature([], tf.float32),\n",
        "    'label': tf.io.FixedLenFeature([], tf.int64),\n",
        "}\n",
        "\n",
        "# Create a parsing function\n",
        "def _parse_function(example_proto):\n",
        "    return tf.io.parse_single_example(example_proto, feature_description)\n",
        "\n",
        "# Create a dataset from the TFRecord file\n",
        "raw_dataset = tf.data.TFRecordDataset(temp_tfrecords.name)\n",
        "parsed_dataset = raw_dataset.map(_parse_function)\n",
        "\n",
        "# Define the model\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(128, activation='relu', input_shape=(4,)),  # Use appropriate input shape\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(df[iris.feature_names].values, df['label'].values, epochs=10, validation_split=0.2)\n",
        "\n",
        "# Save the model to a temporary location\n",
        "model_location = tempfile.mkdtemp()\n",
        "model.save(model_location)\n",
        "\n",
        "# Define the evaluation configuration\n",
        "eval_config = tfma.EvalConfig(\n",
        "    model_specs=[tfma.ModelSpec(label_key='label')],\n",
        "    slicing_specs=[tfma.SlicingSpec()],\n",
        "    metrics_specs=[\n",
        "        tfma.MetricsSpec(\n",
        "            metrics=[\n",
        "                tfma.MetricConfig(class_name='ExampleCount'),\n",
        "                tfma.MetricConfig(class_name='Accuracy')\n",
        "            ]\n",
        "        )\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Modify the evaluation code to properly handle the parsed data\n",
        "def serving_input_receiver_fn():\n",
        "    feature_spec = {\n",
        "        'sepal length (cm)': tf.io.FixedLenFeature([], tf.float32),\n",
        "        'sepal width (cm)': tf.io.FixedLenFeature([], tf.float32),\n",
        "        'petal length (cm)': tf.io.FixedLenFeature([], tf.float32),\n",
        "        'petal width (cm)': tf.io.FixedLenFeature([], tf.float32)\n",
        "    }\n",
        "    serialized_tf_example = tf.compat.v1.placeholder(dtype=tf.string, shape=[None], name='input_example_tensor')\n",
        "    receiver_tensors = {'examples': serialized_tf_example}\n",
        "    features = tf.io.parse_example(serialized_tf_example, feature_spec)\n",
        "    return tf.estimator.export.ServingInputReceiver(features, receiver_tensors)\n",
        "\n",
        "# Create the eval shared model\n",
        "eval_shared_model = tfma.default_eval_shared_model(\n",
        "    eval_saved_model_path=model_location,\n",
        "    eval_config=eval_config,\n",
        "    tags=[tf.saved_model.SERVING]\n",
        ")\n",
        "\n",
        "# Run the model analysis using the TFRecord file\n",
        "eval_result = tfma.run_model_analysis(\n",
        "    eval_shared_model=eval_shared_model,\n",
        "    data_location=temp_tfrecords.name,  # Use the TFRecord file\n",
        "    eval_config=eval_config\n",
        ")\n",
        "\n",
        "# Visualize the results\n",
        "tfma.view.render_slicing_metrics(eval_result)\n",
        "\n",
        "# Clean up temporary files\n",
        "temp_csv.close()\n",
        "temp_tfrecords.close()\n",
        "import os\n",
        "os.remove(temp_csv.name)\n",
        "os.remove(temp_tfrecords.name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zogCWCXDgsuU",
        "outputId": "5f53bcaa-9d2e-4e5d-d1e6-d1f335eac390"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "4/4 [==============================] - 3s 184ms/step - loss: 1.0300 - accuracy: 0.4167 - val_loss: 1.4689 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 0.8791 - accuracy: 0.6917 - val_loss: 1.3620 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 0.7862 - accuracy: 0.8333 - val_loss: 1.1471 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 0s 52ms/step - loss: 0.7054 - accuracy: 0.8333 - val_loss: 1.1261 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 0.6302 - accuracy: 0.8333 - val_loss: 1.0930 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.5620 - accuracy: 0.8333 - val_loss: 1.0834 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 0s 73ms/step - loss: 0.5044 - accuracy: 0.8333 - val_loss: 1.0809 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 0s 67ms/step - loss: 0.4570 - accuracy: 0.8333 - val_loss: 1.1015 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 0s 72ms/step - loss: 0.4197 - accuracy: 0.8333 - val_loss: 1.0144 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 0s 63ms/step - loss: 0.3848 - accuracy: 0.8417 - val_loss: 0.9404 - val_accuracy: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Tensorflow version (2.15.1) found. Note that TFMA support for TF 2.0 is currently in beta\n",
            "WARNING:absl:Large batch_size 1 failed with error Fail to call signature func with signature_name: serving_default.\n",
            "              the inputs are:\n",
            " [b'\\n\\x8a\\x01\\n\\x1d\\n\\x11sepal length (cm)\\x12\\x08\\x12\\x06\\n\\x0433\\xa3@\\n\\x1d\\n\\x11petal length (cm)\\x12\\x08\\x12\\x06\\n\\x0433\\xb3?\\n\\x1c\\n\\x10sepal width (cm)\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00`@\\n\\x1c\\n\\x10petal width (cm)\\x12\\x08\\x12\\x06\\n\\x04\\xcd\\xccL>\\n\\x0e\\n\\x05label\\x12\\x05\\x1a\\x03\\n\\x01\\x00'].\n",
            "              The input_specs are:\n",
            " {'dense_12_input': TensorSpec(shape=(None, 4), dtype=tf.float32, name='dense_12_input')}.. Attempting to run batch through serially. Note that this will significantly affect the performance.\n",
            "ERROR:apache_beam.runners.common:Fail to call signature func with signature_name: serving_default.\n",
            "              the inputs are:\n",
            " [b'\\n\\x8a\\x01\\n\\x1d\\n\\x11sepal length (cm)\\x12\\x08\\x12\\x06\\n\\x0433\\xa3@\\n\\x1d\\n\\x11petal length (cm)\\x12\\x08\\x12\\x06\\n\\x0433\\xb3?\\n\\x1c\\n\\x10sepal width (cm)\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00`@\\n\\x1c\\n\\x10petal width (cm)\\x12\\x08\\x12\\x06\\n\\x04\\xcd\\xccL>\\n\\x0e\\n\\x05label\\x12\\x05\\x1a\\x03\\n\\x01\\x00'].\n",
            "              The input_specs are:\n",
            " {'dense_12_input': TensorSpec(shape=(None, 4), dtype=tf.float32, name='dense_12_input')}. [while running 'ExtractEvaluateAndWriteResults/ExtractAndEvaluate/ExtractPredictions/Inference']\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/function_type_utils.py\", line 442, in bind_function_inputs\n",
            "    bound_arguments = function_type.bind_with_defaults(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/core/function/polymorphism/function_type.py\", line 264, in bind_with_defaults\n",
            "    bound_arguments = self.bind(*args, **kwargs)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 3186, in bind\n",
            "    return self._bind(args, kwargs)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 3112, in _bind\n",
            "    raise TypeError(\n",
            "TypeError: too many positional arguments\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\", line 1180, in _call_impl\n",
            "    return self._call_with_structured_signature(args, kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\", line 1260, in _call_with_structured_signature\n",
            "    function_type_utils.canonicalize_function_inputs(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/function_type_utils.py\", line 422, in canonicalize_function_inputs\n",
            "    bound_arguments = bind_function_inputs(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/function_type_utils.py\", line 446, in bind_function_inputs\n",
            "    raise TypeError(\n",
            "TypeError: Binding inputs to tf.function failed due to `too many positional arguments`. Received args: (<tf.Tensor: shape=(1,), dtype=string, numpy=\n",
            "array([b'\\n\\x8a\\x01\\n\\x1d\\n\\x11sepal length (cm)\\x12\\x08\\x12\\x06\\n\\x0433\\xa3@\\n\\x1d\\n\\x11petal length (cm)\\x12\\x08\\x12\\x06\\n\\x0433\\xb3?\\n\\x1c\\n\\x10sepal width (cm)\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00`@\\n\\x1c\\n\\x10petal width (cm)\\x12\\x08\\x12\\x06\\n\\x04\\xcd\\xccL>\\n\\x0e\\n\\x05label\\x12\\x05\\x1a\\x03\\n\\x01\\x00'],\n",
            "      dtype=object)>,) and kwargs: {} for signature: (*, dense_12_input: TensorSpec(shape=(None, 4), dtype=tf.float32, name='dense_12_input')) -> Dict[['dense_14', TensorSpec(shape=(None, 3), dtype=tf.float32, name='dense_14')]].\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow_model_analysis/utils/model_util.py\", line 1032, in _batch_reducible_process\n",
            "    outputs = signature(tf.constant(inputs, dtype=tf.string))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\", line 1171, in __call__\n",
            "    return self._call_impl(args, kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\", line 1183, in _call_impl\n",
            "    return self._call_with_flat_signature(args, kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\", line 1243, in _call_with_flat_signature\n",
            "    return self._call_flat(args, self.captured_inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/saved_model/load.py\", line 146, in _call_flat\n",
            "    return super()._call_flat(args, captured_inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\", line 1323, in _call_flat\n",
            "    return self._inference_function.call_preflattened(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 216, in call_preflattened\n",
            "    flat_outputs = self.call_flat(*args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 251, in call_flat\n",
            "    outputs = self._bound_context.call_function(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\", line 1486, in call_function\n",
            "    outputs = execute.execute(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\", line 53, in quick_execute\n",
            "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
            "tensorflow.python.framework.errors_impl.InvalidArgumentError: cannot compute __inference_signature_wrapper_16943 as input #0(zero-based) was expected to be a float tensor but is a string tensor [Op:__inference_signature_wrapper_16943]\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"apache_beam/runners/common.py\", line 1435, in apache_beam.runners.common.DoFnRunner.process\n",
            "  File \"apache_beam/runners/common.py\", line 640, in apache_beam.runners.common.SimpleInvoker.invoke_process\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow_model_analysis/utils/model_util.py\", line 866, in process\n",
            "    result.extend(self._batch_reducible_process(unbatched_element))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow_model_analysis/utils/model_util.py\", line 1034, in _batch_reducible_process\n",
            "    raise ValueError(\n",
            "ValueError: Fail to call signature func with signature_name: serving_default.\n",
            "              the inputs are:\n",
            " [b'\\n\\x8a\\x01\\n\\x1d\\n\\x11sepal length (cm)\\x12\\x08\\x12\\x06\\n\\x0433\\xa3@\\n\\x1d\\n\\x11petal length (cm)\\x12\\x08\\x12\\x06\\n\\x0433\\xb3?\\n\\x1c\\n\\x10sepal width (cm)\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00`@\\n\\x1c\\n\\x10petal width (cm)\\x12\\x08\\x12\\x06\\n\\x04\\xcd\\xccL>\\n\\x0e\\n\\x05label\\x12\\x05\\x1a\\x03\\n\\x01\\x00'].\n",
            "              The input_specs are:\n",
            " {'dense_12_input': TensorSpec(shape=(None, 4), dtype=tf.float32, name='dense_12_input')}.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Fail to call signature func with signature_name: serving_default.\n              the inputs are:\n [b'\\n\\x8a\\x01\\n\\x1d\\n\\x11sepal length (cm)\\x12\\x08\\x12\\x06\\n\\x0433\\xa3@\\n\\x1d\\n\\x11petal length (cm)\\x12\\x08\\x12\\x06\\n\\x0433\\xb3?\\n\\x1c\\n\\x10sepal width (cm)\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00`@\\n\\x1c\\n\\x10petal width (cm)\\x12\\x08\\x12\\x06\\n\\x04\\xcd\\xccL>\\n\\x0e\\n\\x05label\\x12\\x05\\x1a\\x03\\n\\x01\\x00'].\n              The input_specs are:\n {'dense_12_input': TensorSpec(shape=(None, 4), dtype=tf.float32, name='dense_12_input')}. [while running 'ExtractEvaluateAndWriteResults/ExtractAndEvaluate/ExtractPredictions/Inference']",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/function_type_utils.py\u001b[0m in \u001b[0;36mbind_function_inputs\u001b[0;34m(args, kwargs, function_type, default_values)\u001b[0m\n\u001b[1;32m    441\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m     bound_arguments = function_type.bind_with_defaults(\n\u001b[0m\u001b[1;32m    443\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msanitized_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/core/function/polymorphism/function_type.py\u001b[0m in \u001b[0;36mbind_with_defaults\u001b[0;34m(self, args, kwargs, default_values)\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;34m\"\"\"Returns BoundArguments with default values filled in.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m     \u001b[0mbound_arguments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m     \u001b[0mbound_arguments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/inspect.py\u001b[0m in \u001b[0;36mbind\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3185\u001b[0m         \"\"\"\n\u001b[0;32m-> 3186\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/inspect.py\u001b[0m in \u001b[0;36m_bind\u001b[0;34m(self, args, kwargs, partial)\u001b[0m\n\u001b[1;32m   3111\u001b[0m                         \u001b[0;31m# argument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3112\u001b[0;31m                         raise TypeError(\n\u001b[0m\u001b[1;32m   3113\u001b[0m                             'too many positional arguments') from None\n",
            "\u001b[0;31mTypeError\u001b[0m: too many positional arguments",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_with_structured_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstructured_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_with_structured_signature\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1259\u001b[0m     bound_args = (\n\u001b[0;32m-> 1260\u001b[0;31m         function_type_utils.canonicalize_function_inputs(\n\u001b[0m\u001b[1;32m   1261\u001b[0m             args, kwargs, self.function_type)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/function_type_utils.py\u001b[0m in \u001b[0;36mcanonicalize_function_inputs\u001b[0;34m(args, kwargs, function_type, default_values, is_pure)\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_variables_to_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m   bound_arguments = bind_function_inputs(\n\u001b[0m\u001b[1;32m    423\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/function_type_utils.py\u001b[0m in \u001b[0;36mbind_function_inputs\u001b[0;34m(args, kwargs, function_type, default_values)\u001b[0m\n\u001b[1;32m    445\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m     raise TypeError(\n\u001b[0m\u001b[1;32m    447\u001b[0m         \u001b[0;34mf\"Binding inputs to tf.function failed due to `{e}`. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Binding inputs to tf.function failed due to `too many positional arguments`. Received args: (<tf.Tensor: shape=(1,), dtype=string, numpy=\narray([b'\\n\\x8a\\x01\\n\\x1d\\n\\x11sepal length (cm)\\x12\\x08\\x12\\x06\\n\\x0433\\xa3@\\n\\x1d\\n\\x11petal length (cm)\\x12\\x08\\x12\\x06\\n\\x0433\\xb3?\\n\\x1c\\n\\x10sepal width (cm)\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00`@\\n\\x1c\\n\\x10petal width (cm)\\x12\\x08\\x12\\x06\\n\\x04\\xcd\\xccL>\\n\\x0e\\n\\x05label\\x12\\x05\\x1a\\x03\\n\\x01\\x00'],\n      dtype=object)>,) and kwargs: {} for signature: (*, dense_12_input: TensorSpec(shape=(None, 4), dtype=tf.float32, name='dense_12_input')) -> Dict[['dense_14', TensorSpec(shape=(None, 3), dtype=tf.float32, name='dense_14')]].",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_model_analysis/utils/model_util.py\u001b[0m in \u001b[0;36m_batch_reducible_process\u001b[0;34m(self, batched_extract)\u001b[0m\n\u001b[1;32m   1031\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1033\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1170\u001b[0m     \"\"\"\n\u001b[0;32m-> 1171\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1182\u001b[0m           \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_with_flat_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mflat_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_with_flat_signature\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1242\u001b[0m                         f\"got {type(arg).__name__} ({arg}).\")\n\u001b[0;32m-> 1243\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m       \u001b[0mcaptured_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_unused_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: cannot compute __inference_signature_wrapper_16943 as input #0(zero-based) was expected to be a float tensor but is a string tensor [Op:__inference_signature_wrapper_16943]",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.SimpleInvoker.invoke_process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_model_analysis/utils/model_util.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, element)\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_size\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 866\u001b[0;31m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_reducible_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munbatched_element\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    867\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_instances\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_model_analysis/utils/model_util.py\u001b[0m in \u001b[0;36m_batch_reducible_process\u001b[0;34m(self, batched_extract)\u001b[0m\n\u001b[1;32m   1033\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m           raise ValueError(\n\u001b[0m\u001b[1;32m   1035\u001b[0m               \"\"\"Fail to call signature func with signature_name: {}.\n",
            "\u001b[0;31mValueError\u001b[0m: Fail to call signature func with signature_name: serving_default.\n              the inputs are:\n [b'\\n\\x8a\\x01\\n\\x1d\\n\\x11sepal length (cm)\\x12\\x08\\x12\\x06\\n\\x0433\\xa3@\\n\\x1d\\n\\x11petal length (cm)\\x12\\x08\\x12\\x06\\n\\x0433\\xb3?\\n\\x1c\\n\\x10sepal width (cm)\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00`@\\n\\x1c\\n\\x10petal width (cm)\\x12\\x08\\x12\\x06\\n\\x04\\xcd\\xccL>\\n\\x0e\\n\\x05label\\x12\\x05\\x1a\\x03\\n\\x01\\x00'].\n              The input_specs are:\n {'dense_12_input': TensorSpec(shape=(None, 4), dtype=tf.float32, name='dense_12_input')}.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-a108733d2b1c>\u001b[0m in \u001b[0;36m<cell line: 114>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;31m# Run the model analysis using the TFRecord file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m eval_result = tfma.run_model_analysis(\n\u001b[0m\u001b[1;32m    115\u001b[0m     \u001b[0meval_shared_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_shared_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0mdata_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtemp_tfrecords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Use the TFRecord file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_model_analysis/api/model_eval_lib.py\u001b[0m in \u001b[0;36mrun_model_analysis\u001b[0;34m(eval_shared_model, eval_config, data_location, file_format, output_path, extractors, evaluators, writers, pipeline_options, slice_spec, write_config, compute_confidence_intervals, min_slice_size, random_seed_for_testing, schema)\u001b[0m\n\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m   \u001b[0mtensor_adapter_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1305\u001b[0;31m   \u001b[0;32mwith\u001b[0m \u001b[0mbeam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpipeline_options\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1306\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfile_format\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tfrecords'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mis_batched_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_shared_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig_version\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/pipeline.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    611\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mexc_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 613\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    614\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_until_finish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/pipeline.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, test_runner_api)\u001b[0m\n\u001b[1;32m    585\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m           \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmpdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 587\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    588\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_in_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/direct/direct_runner.py\u001b[0m in \u001b[0;36mrun_pipeline\u001b[0;34m(self, pipeline, options)\u001b[0m\n\u001b[1;32m    126\u001b[0m       \u001b[0mrunner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBundleBasedDirectRunner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/portability/fn_api_runner/fn_runner.py\u001b[0m in \u001b[0;36mrun_pipeline\u001b[0;34m(self, pipeline, options)\u001b[0m\n\u001b[1;32m    202\u001b[0m         options.view_as(pipeline_options.ProfilingOptions))\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m     self._latest_run_result = self.run_via_runner_api(\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_runner_api\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_environment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_environment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         options)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/portability/fn_api_runner/fn_runner.py\u001b[0m in \u001b[0;36mrun_via_runner_api\u001b[0;34m(self, pipeline_proto, options)\u001b[0m\n\u001b[1;32m    226\u001b[0m         self.resolve_any_environments(pipeline_proto))\n\u001b[1;32m    227\u001b[0m     \u001b[0mstage_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_stages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline_proto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_stages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstage_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0membed_default_docker_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpipeline_proto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/portability/fn_api_runner/fn_runner.py\u001b[0m in \u001b[0;36mrun_stages\u001b[0;34m(self, stage_context, stages)\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m           \u001b[0mbundle_counter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m           bundle_results = self._execute_bundle(\n\u001b[0m\u001b[1;32m    484\u001b[0m               runner_execution_context, bundle_context_manager, bundle_input)\n\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/portability/fn_api_runner/fn_runner.py\u001b[0m in \u001b[0;36m_execute_bundle\u001b[0;34m(self, runner_execution_context, bundle_context_manager, bundle_input)\u001b[0m\n\u001b[1;32m    809\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m     last_result, deferred_inputs, newly_set_timers, watermark_updates = (\n\u001b[0;32m--> 811\u001b[0;31m         self._run_bundle(\n\u001b[0m\u001b[1;32m    812\u001b[0m             \u001b[0mrunner_execution_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m             \u001b[0mbundle_context_manager\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/portability/fn_api_runner/fn_runner.py\u001b[0m in \u001b[0;36m_run_bundle\u001b[0;34m(self, runner_execution_context, bundle_context_manager, bundle_input, data_output, expected_timer_output, bundle_manager)\u001b[0m\n\u001b[1;32m   1046\u001b[0m         expected_timer_output)\n\u001b[1;32m   1047\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1048\u001b[0;31m     result, splits = bundle_manager.process_bundle(\n\u001b[0m\u001b[1;32m   1049\u001b[0m         data_input, data_output, input_timers, expected_timer_output)\n\u001b[1;32m   1050\u001b[0m     \u001b[0;31m# Now we collect all the deferred inputs remaining from bundle execution.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/portability/fn_api_runner/fn_runner.py\u001b[0m in \u001b[0;36mprocess_bundle\u001b[0;34m(self, inputs, expected_outputs, fired_timers, expected_output_timers, dry_run)\u001b[0m\n\u001b[1;32m   1382\u001b[0m             \u001b[0mprocess_bundle_descriptor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m             cache_tokens=[next(self._cache_token_generator)]))\n\u001b[0;32m-> 1384\u001b[0;31m     \u001b[0mresult_future\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_worker_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_conn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_bundle_req\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m     \u001b[0msplit_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# type: List[beam_fn_api_pb2.ProcessBundleSplitResponse]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/portability/fn_api_runner/worker_handlers.py\u001b[0m in \u001b[0;36mpush\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    382\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uid_counter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m       \u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstruction_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'control_%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uid_counter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_instruction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mControlFuture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstruction_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/sdk_worker.py\u001b[0m in \u001b[0;36mdo_instruction\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    654\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrequest_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m       \u001b[0;31m# E.g. if register is set, this will call self.register(request.register))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 656\u001b[0;31m       return getattr(self, request_type)(\n\u001b[0m\u001b[1;32m    657\u001b[0m           getattr(request, request_type), request.instruction_id)\n\u001b[1;32m    658\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/sdk_worker.py\u001b[0m in \u001b[0;36mprocess_bundle\u001b[0;34m(self, request, instruction_id)\u001b[0m\n\u001b[1;32m    692\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_profile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstruction_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m           delayed_applications, requests_finalization = (\n\u001b[0;32m--> 694\u001b[0;31m               bundle_processor.process_bundle(instruction_id))\n\u001b[0m\u001b[1;32m    695\u001b[0m           \u001b[0mmonitoring_infos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbundle_processor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonitoring_infos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m           response = beam_fn_api_pb2.InstructionResponse(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/bundle_processor.py\u001b[0m in \u001b[0;36mprocess_bundle\u001b[0;34m(self, instruction_id)\u001b[0m\n\u001b[1;32m   1111\u001b[0m                   element.timer_family_id, timer_data)\n\u001b[1;32m   1112\u001b[0m           \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam_fn_api_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mElements\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1113\u001b[0;31m             input_op_by_transform_id[element.transform_id].process_encoded(\n\u001b[0m\u001b[1;32m   1114\u001b[0m                 element.data)\n\u001b[1;32m   1115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/bundle_processor.py\u001b[0m in \u001b[0;36mprocess_encoded\u001b[0;34m(self, encoded_windowed_values)\u001b[0m\n\u001b[1;32m    235\u001b[0m             \u001b[0;34m\"Error decoding input stream with coder \"\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             str(self.windowed_coder)) from exn\n\u001b[0;32m--> 237\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoded_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mmonitoring_infos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag_to_pcollection_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.Operation.output\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.Operation.output\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.SingletonElementConsumerSet.receive\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.SingletonElementConsumerSet.receive\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.SdfProcessSizedElements.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.SdfProcessSizedElements.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner.process_with_sized_restriction\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.PerWindowInvoker.invoke_process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.PerWindowInvoker._invoke_process_per_window\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common._OutputHandler.handle_process_outputs\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common._OutputHandler._write_value_to_tag\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.SingletonElementConsumerSet.receive\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.FlattenOperation.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.FlattenOperation.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.Operation.output\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.SingletonElementConsumerSet.receive\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.SingletonElementConsumerSet.receive\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.DoOperation.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.DoOperation.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner._reraise_augmented\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.SimpleInvoker.invoke_process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common._OutputHandler.handle_process_outputs\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common._OutputHandler._write_value_to_tag\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.SingletonElementConsumerSet.receive\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.DoOperation.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.DoOperation.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner._reraise_augmented\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.SimpleInvoker.invoke_process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common._OutputHandler.handle_process_outputs\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common._OutputHandler._write_value_to_tag\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.SingletonElementConsumerSet.receive\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.DoOperation.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.DoOperation.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner._reraise_augmented\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.SimpleInvoker.invoke_process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common._OutputHandler.handle_process_outputs\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common._OutputHandler._write_value_to_tag\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.SingletonElementConsumerSet.receive\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.DoOperation.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.DoOperation.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner._reraise_augmented\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.SimpleInvoker.invoke_process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common._OutputHandler.handle_process_outputs\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common._OutputHandler._write_value_to_tag\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.SingletonElementConsumerSet.receive\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.DoOperation.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.DoOperation.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner._reraise_augmented\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.SimpleInvoker.invoke_process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common._OutputHandler.handle_process_outputs\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common._OutputHandler._write_value_to_tag\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.GeneralPurposeConsumerSet.receive\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.DoOperation.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.DoOperation.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.DoOperation.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner._reraise_augmented\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.SimpleInvoker.invoke_process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common._OutputHandler.handle_process_outputs\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common._OutputHandler._write_value_to_tag\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.SingletonElementConsumerSet.receive\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.DoOperation.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.DoOperation.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner._reraise_augmented\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.SimpleInvoker.invoke_process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common._OutputHandler.handle_process_outputs\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common._OutputHandler._write_value_to_tag\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.SingletonElementConsumerSet.receive\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.DoOperation.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.DoOperation.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner._reraise_augmented\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.SimpleInvoker.invoke_process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common._OutputHandler.handle_process_outputs\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common._OutputHandler._write_value_to_tag\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.SingletonElementConsumerSet.receive\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.DoOperation.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.DoOperation.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner._reraise_augmented\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.SimpleInvoker.invoke_process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common._OutputHandler.handle_process_outputs\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common._OutputHandler._write_value_to_tag\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.SingletonElementConsumerSet.receive\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.DoOperation.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/operations.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.DoOperation.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner._reraise_augmented\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.DoFnRunner.process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/apache_beam/runners/common.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mapache_beam.runners.common.SimpleInvoker.invoke_process\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_model_analysis/utils/model_util.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, element)\u001b[0m\n\u001b[1;32m    864\u001b[0m           element, keep_batch_dim=True):\n\u001b[1;32m    865\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_size\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 866\u001b[0;31m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_reducible_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munbatched_element\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    867\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_instances\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_model_analysis/utils/model_util.py\u001b[0m in \u001b[0;36m_batch_reducible_process\u001b[0;34m(self, batched_extract)\u001b[0m\n\u001b[1;32m   1032\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m           raise ValueError(\n\u001b[0m\u001b[1;32m   1035\u001b[0m               \"\"\"Fail to call signature func with signature_name: {}.\n\u001b[1;32m   1036\u001b[0m               \u001b[0mthe\u001b[0m \u001b[0minputs\u001b[0m \u001b[0mare\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Fail to call signature func with signature_name: serving_default.\n              the inputs are:\n [b'\\n\\x8a\\x01\\n\\x1d\\n\\x11sepal length (cm)\\x12\\x08\\x12\\x06\\n\\x0433\\xa3@\\n\\x1d\\n\\x11petal length (cm)\\x12\\x08\\x12\\x06\\n\\x0433\\xb3?\\n\\x1c\\n\\x10sepal width (cm)\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00`@\\n\\x1c\\n\\x10petal width (cm)\\x12\\x08\\x12\\x06\\n\\x04\\xcd\\xccL>\\n\\x0e\\n\\x05label\\x12\\x05\\x1a\\x03\\n\\x01\\x00'].\n              The input_specs are:\n {'dense_12_input': TensorSpec(shape=(None, 4), dtype=tf.float32, name='dense_12_input')}. [while running 'ExtractEvaluateAndWriteResults/ExtractAndEvaluate/ExtractPredictions/Inference']"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Model Serving**\n",
        "**TensorFlow Serving:**\n",
        "* TensorFlow Serving is a flexible, high-performance serving system for machine learning models designed for production environments.\n",
        "\n",
        "**Example: Serving a TensorFlow Model**"
      ],
      "metadata": {
        "id": "CiEFR8zGgwb-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1-Save the Model in the SavedModel Format:"
      ],
      "metadata": {
        "id": "0hyU8H7Mg6BQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define and train a model\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(128, activation='relu', input_shape=(784,)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n",
        "\n",
        "# Save the model in the SavedModel format\n",
        "model.save('saved_model/my_model')\n"
      ],
      "metadata": {
        "id": "zc8faLBjg2pQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2-Start TensorFlow Serving:"
      ],
      "metadata": {
        "id": "YhtGBs6Cg-d4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "docker pull tensorflow/serving\n",
        "docker run -p 8501:8501 --name=tf_serving --mount type=bind,source=$(pwd)/saved_model,target=/models/my_model -e MODEL_NAME=my_model -t tensorflow/serving\n"
      ],
      "metadata": {
        "id": "ist3WNTQhBM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3-Make Predictions Using the REST API:"
      ],
      "metadata": {
        "id": "6yqZpNKohC3K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "import numpy as np\n",
        "\n",
        "data = json.dumps({\"signature_name\": \"serving_default\", \"instances\": x_test[:5].tolist()})\n",
        "headers = {\"content-type\": \"application/json\"}\n",
        "json_response = requests.post('http://localhost:8501/v1/models/my_model:predict', data=data, headers=headers)\n",
        "predictions = np.array(json.loads(json_response.text)[\"predictions\"])\n",
        "print(predictions)\n"
      ],
      "metadata": {
        "id": "irGERVZbhFW3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. TensorFlow Hub**\n",
        "* TensorFlow Hub is a library for the publication, discovery, and consumption of reusable parts of machine learning models. These parts can be pre-trained models, model weights, and other assets. TensorFlow Hub allows you to use these pre-trained models in your TensorFlow projects to save time and resources.\n",
        "\n",
        "**Example of using TensorFlow Hub**"
      ],
      "metadata": {
        "id": "iTCz1Ux0vyTX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load a pre-trained model from TensorFlow Hub\n",
        "model_url = \"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/5\"\n",
        "model = tf.keras.Sequential([\n",
        "    hub.KerasLayer(model_url, input_shape=(224, 224, 3))\n",
        "])\n",
        "\n",
        "# Load and preprocess an image\n",
        "image_url = \"https://www.tensorflow.org/static/hub/tutorials/image_classification_files/output_o2rMsr4CgET2_1.png\"\n",
        "image_path = tf.keras.utils.get_file(\"image.jpg\", image_url)\n",
        "image = tf.keras.preprocessing.image.load_img(image_path, target_size=(224, 224))\n",
        "image = tf.keras.preprocessing.image.img_to_array(image) / 255.0\n",
        "image = np.expand_dims(image, axis=0)\n",
        "\n",
        "# Make a prediction\n",
        "predictions = model.predict(image)\n",
        "predicted_class = np.argmax(predictions[0], axis=-1)\n",
        "print(f\"Predicted class: {predicted_class}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OwJbUjrv4-e",
        "outputId": "5b8fef21-4a8c-47e8-92b8-3b52a3d2ace9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.tensorflow.org/static/hub/tutorials/image_classification_files/output_o2rMsr4CgET2_1.png\n",
            "316847/316847 [==============================] - 0s 1us/step\n",
            "1/1 [==============================] - 1s 767ms/step\n",
            "Predicted class: 35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. TensorFlow.js**\n",
        "* TensorFlow.js is an open-source library that allows you to define, train, and run machine learning models entirely in the browser using JavaScript and a high-level layer API. This is particularly useful for deploying models to web applications.\n",
        "\n",
        "# **3. Using Pre-trained Models from TensorFlow.js**\n",
        "* TensorFlow.js provides a collection of pre-trained models that can be easily used in your web applications.\n",
        "\n",
        "**Example of using a pre-trained model in TensorFlow.js**"
      ],
      "metadata": {
        "id": "kI96n_pav9Lu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# index.html file in web browser and choose image any dogs cats images to know the prediction name which one is this"
      ],
      "metadata": {
        "id": "KdXphe5LwIMp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Running TensorFlow Models in the Browser with TensorFlow.js**\n",
        "* You can run your TensorFlow models in the browser using TensorFlow.js by converting your models to a format that TensorFlow.js can use.\n",
        "\n",
        "**Example of converting a TensorFlow model and using it in the browser**\n",
        " * First, convert your TensorFlow model to TensorFlow.js format:"
      ],
      "metadata": {
        "id": "p1xXWrfAwOMd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the TensorFlow.js converter\n",
        "pip install tensorflowjs\n",
        "\n",
        "# Convert the TensorFlow model to TensorFlow.js format\n",
        "tensorflowjs_converter --input_format=tf_saved_model --output_node_names='output_node' /path/to/saved_model /path/to/web_model\n"
      ],
      "metadata": {
        "id": "OE6ofKf_wVYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, use the converted model in a web application:"
      ],
      "metadata": {
        "id": "t0ssX__rwXB4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "<!DOCTYPE html>\n",
        "<html lang=\"en\">\n",
        "<head>\n",
        "  <meta charset=\"UTF-8\">\n",
        "  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "  <title>TensorFlow.js Model</title>\n",
        "  <script src=\"https://cdn.jsdelivr.net/npm/@tensorflow/tfjs\"></script>\n",
        "</head>\n",
        "<body>\n",
        "  <h1>Run TensorFlow Model in Browser</h1>\n",
        "  <input type=\"file\" id=\"imageUpload\" accept=\"image/*\">\n",
        "  <img id=\"image\" width=\"224\" height=\"224\">\n",
        "  <p id=\"prediction\"></p>\n",
        "  <script>\n",
        "    async function runModel() {\n",
        "      const model = await tf.loadLayersModel('path/to/web_model/model.json');\n",
        "      const image = document.getElementById('image');\n",
        "\n",
        "      const tensor = tf.browser.fromPixels(image)\n",
        "        .resizeNearestNeighbor([224, 224])\n",
        "        .toFloat()\n",
        "        .expandDims();\n",
        "\n",
        "      const prediction = model.predict(tensor);\n",
        "      const predictedClass = prediction.argMax(-1).dataSync()[0];\n",
        "\n",
        "      document.getElementById('prediction').innerText = `Predicted class: ${predictedClass}`;\n",
        "    }\n",
        "\n",
        "    document.getElementById('imageUpload').addEventListener('change', (event) => {\n",
        "      const image = document.getElementById('image');\n",
        "      image.src = URL.createObjectURL(event.target.files[0]);\n",
        "      image.onload = runModel;\n",
        "    });\n",
        "  </script>\n",
        "</body>\n",
        "</html>\n"
      ],
      "metadata": {
        "id": "Mja_y4wLwZn0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Reinforcement Learning with TensorFlow 2.0**\n",
        "* Reinforcement Learning (RL) is a type of machine learning where an agent learns to make decisions by performing actions in an environment to maximize some notion of cumulative reward. Unlike supervised learning, where the model learns from a labeled dataset, RL relies on the agent exploring the environment and receiving feedback in the form of rewards or penalties.\n",
        "\n",
        "**Types:**\n",
        "\n",
        "* **Value-Based Methods:** The agent learns to estimate the value of different states or state-action pairs.\n",
        " **Example:Q-learning**\n",
        "\n",
        "* **Policy-Based Methods:** The agent directly learns a policy that maps states to actions without the need for a value function.\n",
        " **Example: REINFORCE algorithm.**\n",
        "\n",
        "* **Actor-Critic Methods:** Combines both value-based and policy-based methods. **Example: Advantage Actor-Critic (A2C).**\n",
        "\n",
        "\n",
        "**Example:** Implementing a simple Q-learning algorithm using TensorFlow 2.0 to solve the CartPole environment from OpenAI Gym."
      ],
      "metadata": {
        "id": "FM6_lSeA01hz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "env = gym.make('CartPole-v1')\n",
        "\n",
        "num_actions = env.action_space.n\n",
        "state_shape = env.observation_space.shape\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    layers.Dense(24, activation='relu', input_shape=state_shape),\n",
        "    layers.Dense(24, activation='relu'),\n",
        "    layers.Dense(num_actions, activation='linear')\n",
        "])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "loss_function = tf.keras.losses.Huber()\n",
        "\n",
        "gamma = 0.99  # Discount factor\n",
        "\n",
        "def get_action(state, epsilon):\n",
        "    if np.random.rand() < epsilon:\n",
        "        return np.random.choice(num_actions)\n",
        "    q_values = model.predict(state[np.newaxis])\n",
        "    return np.argmax(q_values[0])\n",
        "\n",
        "def update_model(state, action, reward, next_state, done):\n",
        "    q_values = model.predict(state[np.newaxis])\n",
        "    next_q_values = model.predict(next_state[np.newaxis])\n",
        "    target = reward + (1 - done) * gamma * np.amax(next_q_values[0])\n",
        "    q_values[0][action] = target\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        q_values_pred = model(state[np.newaxis])\n",
        "        loss = loss_function(q_values_pred, q_values)\n",
        "\n",
        "    grads = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "episodes = 50\n",
        "epsilon = 1.0\n",
        "epsilon_decay = 0.995\n",
        "min_epsilon = 0.01\n",
        "\n",
        "rewards = []\n",
        "\n",
        "for episode in range(episodes):\n",
        "    state = env.reset()\n",
        "    total_reward = 0\n",
        "\n",
        "    for _ in range(200):\n",
        "        action = get_action(state, epsilon)\n",
        "        next_state, reward, done, _ = env.step(action)\n",
        "        update_model(state, action, reward, next_state, done)\n",
        "\n",
        "        state = next_state\n",
        "        total_reward += reward\n",
        "\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    epsilon = max(min_epsilon, epsilon * epsilon_decay)\n",
        "    rewards.append(total_reward)\n",
        "    print(f'Episode: {episode + 1}, Total Reward: {total_reward}')\n",
        "\n",
        "plt.plot(rewards)\n",
        "plt.xlabel('Episode')\n",
        "plt.ylabel('Total Reward')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RlmbTN1l1LCP",
        "outputId": "afec9ba6-6f06-4d30-f055-42869f1ff7b4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Episode: 1, Total Reward: 59.0\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Episode: 2, Total Reward: 14.0\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Episode: 3, Total Reward: 17.0\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Episode: 4, Total Reward: 26.0\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Episode: 5, Total Reward: 28.0\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "Episode: 6, Total Reward: 28.0\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Episode: 7, Total Reward: 31.0\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Episode: 8, Total Reward: 23.0\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Episode: 9, Total Reward: 34.0\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "Episode: 10, Total Reward: 30.0\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Episode: 11, Total Reward: 13.0\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Episode: 12, Total Reward: 15.0\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Episode: 13, Total Reward: 28.0\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Episode: 14, Total Reward: 16.0\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Episode: 15, Total Reward: 18.0\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Episode: 16, Total Reward: 13.0\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Episode: 17, Total Reward: 11.0\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Episode: 18, Total Reward: 19.0\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "Episode: 19, Total Reward: 15.0\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "Episode: 20, Total Reward: 28.0\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Episode: 21, Total Reward: 12.0\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Episode: 22, Total Reward: 23.0\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Episode: 23, Total Reward: 23.0\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Episode: 24, Total Reward: 14.0\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Episode: 25, Total Reward: 34.0\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Episode: 26, Total Reward: 25.0\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Episode: 27, Total Reward: 13.0\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Episode: 28, Total Reward: 25.0\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Episode: 29, Total Reward: 43.0\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Episode: 30, Total Reward: 14.0\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Episode: 31, Total Reward: 24.0\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Episode: 32, Total Reward: 20.0\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Episode: 33, Total Reward: 35.0\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "Episode: 34, Total Reward: 16.0\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Episode: 35, Total Reward: 35.0\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Episode: 36, Total Reward: 12.0\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Episode: 37, Total Reward: 16.0\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Episode: 38, Total Reward: 23.0\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Episode: 39, Total Reward: 13.0\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Episode: 40, Total Reward: 67.0\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "Episode: 41, Total Reward: 12.0\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Episode: 42, Total Reward: 15.0\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Episode: 43, Total Reward: 17.0\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Episode: 44, Total Reward: 14.0\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Episode: 45, Total Reward: 12.0\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Episode: 46, Total Reward: 27.0\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Episode: 47, Total Reward: 63.0\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Episode: 48, Total Reward: 40.0\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "Episode: 49, Total Reward: 33.0\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Episode: 50, Total Reward: 34.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Quantum Machine Learning with TensorFlow Quantum**\n",
        "\n",
        "* Quantum Machine Learning (QML) is an emerging field that combines quantum computing with machine learning techniques. TensorFlow Quantum (TFQ) is a library for hybrid quantum-classical machine learning, providing tools to build quantum data structures, quantum circuits, and integrate these with TensorFlow.\n",
        "\n",
        "**Example: Implementing a basic quantum neural network using TensorFlow Quantum.**"
      ],
      "metadata": {
        "id": "mlvyxaAq175_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_quantum as tfq\n",
        "import cirq\n",
        "import sympy\n",
        "\n",
        "\n",
        "# Create a quantum data source\n",
        "qubits = [cirq.GridQubit(0, 0)]\n",
        "readout_op = cirq.Z(qubits[0])\n",
        "\n",
        "# Create a simple quantum circuit\n",
        "circuit = cirq.Circuit(cirq.H(qubits[0]), cirq.measure(qubits[0]))\n",
        "\n",
        "# Convert the circuit to a TensorFlow Quantum circuit\n",
        "quantum_circuit = tfq.convert_to_tensor([circuit])\n",
        "\n",
        "# Define a quantum layer\n",
        "class QuantumLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self):\n",
        "        super(QuantumLayer, self).__init__()\n",
        "        self.readout = cirq.Z(cirq.GridQubit(0, 0))\n",
        "        # Initialize the weights in the constructor\n",
        "        self.w = self.add_weight(\n",
        "            name='circuit_learnable_parameters',\n",
        "            shape=(1,),  # Adjust shape if needed, this should be (1,) for a single symbol\n",
        "            initializer=tf.keras.initializers.RandomUniform()\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Reshape the weights to be (batch_size, 1)\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "        symbol_values = tf.tile(tf.expand_dims(self.w, axis=0), [batch_size, 1]) # Tile the weights to match batch size\n",
        "        return tfq.layers.Expectation()(inputs, operators=self.readout, symbol_names=['theta'], symbol_values=symbol_values)\n",
        "\n",
        "# Create a hybrid model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(), dtype=tf.string),\n",
        "    QuantumLayer()\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(), loss='mse')\n",
        "\n",
        "# Generate some dummy data\n",
        "quantum_data = tfq.convert_to_tensor([cirq.Circuit(cirq.X(qubits[0])), cirq.Circuit(cirq.I(qubits[0]))])\n",
        "labels = tf.constant([[1.0], [0.0]])\n",
        "\n",
        "# Train the model\n",
        "model.fit(quantum_data, labels, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZ0uD7oM2Fgk",
        "outputId": "d0224802-c7fa-4bbb-bf64-dbfc907b033f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 456ms/step - loss: 2.5000\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.5000\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.5000\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.5000\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.5000\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.5000\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.5000\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.5000\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.5000\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.5000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7aaafa427070>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Advanced NLP with TensorFlow 2.0**\n",
        "\n",
        "* Natural Language Processing (NLP) involves the interaction between computers and humans through natural language. Advanced NLP techniques involve deep learning models for tasks like text generation, translation, sentiment analysis, and more. TensorFlow 2.0 provides powerful tools for building and training such models.\n",
        "\n",
        "**Example: Implementing a Transformer model for text classification using TensorFlow 2.0.**"
      ],
      "metadata": {
        "id": "kjk4zu2E2Hvh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install --upgrade tensorflow\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Embedding, Input, GlobalAveragePooling1D\n",
        "from tensorflow.keras.models import Model\n",
        "# Import the necessary module for TransformerBlock\n",
        "from tensorflow.keras.layers import MultiHeadAttention, LayerNormalization, Dropout, Add\n",
        "\n",
        "# Define the Transformer model\n",
        "def build_transformer_model(vocab_size, embed_dim, num_heads, ff_dim):\n",
        "    inputs = Input(shape=(None,), dtype=\"int64\")\n",
        "    embedding_layer = Embedding(vocab_size, embed_dim)(inputs)\n",
        "\n",
        "    # Implement TransformerBlock using existing layers\n",
        "    attention_output = MultiHeadAttention(num_heads, embed_dim)(embedding_layer, embedding_layer)\n",
        "    attention_output = Dropout(0.1)(attention_output)\n",
        "    attention_output = LayerNormalization(epsilon=1e-6)(Add()([embedding_layer, attention_output]))\n",
        "\n",
        "    ffn_output = Dense(ff_dim, activation=\"relu\")(attention_output)\n",
        "    ffn_output = Dense(embed_dim)(ffn_output)\n",
        "    ffn_output = Dropout(0.1)(ffn_output)\n",
        "    transformer_block = LayerNormalization(epsilon=1e-6)(Add()([attention_output, ffn_output]))\n",
        "\n",
        "    pooling_layer = GlobalAveragePooling1D()(transformer_block)\n",
        "    outputs = Dense(1, activation=\"sigmoid\")(pooling_layer)\n",
        "    model = Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "# Hyperparameters\n",
        "vocab_size = 20000  # Adjust based on your vocabulary size\n",
        "embed_dim = 128  # Embedding size for each token\n",
        "num_heads = 2  # Number of attention heads\n",
        "ff_dim = 32  # Hidden layer size in feed-forward network\n",
        "\n",
        "# Build the model\n",
        "model = build_transformer_model(vocab_size, embed_dim, num_heads, ff_dim)\n",
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Prepare dummy data\n",
        "import numpy as np\n",
        "x_train = np.random.randint(0, vocab_size, size=(1000, 100))  # 1000 samples, 100 tokens each\n",
        "y_train = np.random.randint(0, 2, size=(1000, 1))  # Binary labels\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=3, batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5xYzArD2SJ7",
        "outputId": "421ea020-e454-49e7-8d04-86d4bb5eb4df"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 333ms/step - accuracy: 0.5167 - loss: 0.7253\n",
            "Epoch 2/3\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 265ms/step - accuracy: 0.9770 - loss: 0.2835\n",
            "Epoch 3/3\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 154ms/step - accuracy: 1.0000 - loss: 1.5869e-04\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f80dc47f880>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Latest Research and Advancements with TensorFlow 2.0**\n",
        "\n",
        "* TensorFlow 2.0 is a flexible and powerful deep learning library that supports the latest advancements in machine learning research. This includes support for new architectures, optimization techniques, and deployment strategies. The library is continually updated to incorporate state-of-the-art methods.\n",
        "\n",
        "**Recent Advancements:**\n",
        "\n",
        "* Neural Architecture Search (NAS): Automated searching for optimal neural network architectures.\n",
        "* Federated Learning: Training models on decentralized data across multiple devices.\n",
        "* TensorFlow Hub: Reusable modules for transfer learning and research reproducibility.\n",
        "* TensorFlow Probability: Tools for probabilistic modeling and statistical analysis.\n",
        "**Example: Using TensorFlow Hub to perform transfer learning with a pre-trained model for image classification.**"
      ],
      "metadata": {
        "id": "T5SEa-r72TNj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade tensorflow\n",
        "!pip install --upgrade tensorflow-hub\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load a pre-trained model from TensorFlow Hub\n",
        "model = tf.keras.Sequential([\n",
        "    hub.KerasLayer(\"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4\",\n",
        "                   output_shape=[1001], trainable=False)\n",
        "])\n",
        "\n",
        "# Load and preprocess an image\n",
        "image = tf.keras.preprocessing.image.load_img('path_to_image.jpg', target_size=(224, 224))\n",
        "image = tf.keras.preprocessing.image.img_to_array(image) / 255.0\n",
        "image = np.expand_dims(image, axis=0)\n",
        "\n",
        "# Make a prediction\n",
        "predictions = model.predict(image)\n",
        "predicted_class = np.argmax(predictions[0])\n",
        "\n",
        "# Load the labels\n",
        "labels_path = tf.keras.utils.get_file('ImageNetLabels.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt')\n",
        "with open(labels_path) as f:\n",
        "    labels = f.read().splitlines()\n",
        "\n",
        "# Display the prediction\n",
        "print(\"Predicted class:\", labels[predicted_class])\n",
        "plt.imshow(image[0])\n",
        "plt.title(labels[predicted_class])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "enObOloh2iJp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "43Xf3Qcu54fY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}